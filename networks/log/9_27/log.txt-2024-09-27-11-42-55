layer 23 cls + batchsize=16 + BCEloss

Set Seed: 0
----------------- Options ---------------
                     arch: CLIP:ViT-L/14                 	[default: res50]
               batch_size: 16                            	[default: 256]
                    beta1: 0.9                           
                blur_prob: 0.5                           
                 blur_sig: 0.0, 2.0                      
          checkpoints_dir: ./checkpoints                 
                class_bal: None                          
                 cropSize: 224                           
                 data_aug: False                         
               data_label: train                         
                data_mode: ours                          
          earlystop_epoch: 3                             
              epoch_count: 1                             
           fake_list_path: /home/data/szk/our_dataset/1_fake	[default: None]
             fix_backbone: True                          	[default: False]
                focalloss: False                         
                  gpu_ids: 6                             	[default: 0]
                init_gain: 0.02                          
                init_type: normal                        
                  isTrain: True                          	[default: None]
               jpg_method: cv2,pil                       
                 jpg_prob: 0.5                           
                 jpg_qual: 30, 100                       
               last_epoch: -1                            
                 loadSize: 224                           
                loss_freq: 400                           
                       lr: 0.0001                        
                     mode: binary                        
                     name: clip_vitl14-2024-09-27-11-42-55	[default: experiment_name]
                    niter: 100                           
                  no_crop: False                         
                  no_flip: False                         
              num_threads: 4                             
                    optim: adam                          
           real_list_path: /home/data/szk/our_dataset/0_real	[default: None]
           resize_or_crop: scale_and_crop                
                rz_interp: bilinear                      
          save_epoch_freq: 1                             
           serial_batches: False                         
                   suffix: time                          	[default: ]
              train_split: train                         
                val_split: val                           
       wang2020_data_path: None                          
             weight_decay: 0.0                           
----------------- End -------------------
Directory ./checkpoints/clip_vitl14-2024-09-27-11-42-55 is created.
Choose layer: 23 for cls embedding
Use BCELoss!
Use RandomHorizontalFlip
mean and std stats are from:  clip
using Official CLIP's normalization
Resize image to (224,224)
mean and std stats are from:  clip
using Official CLIP's normalization
Length of data loader: 421
Train loss: 0.3796935975551605 at step: 400
Iter time:  0.13677393794059753
saving the model at the end of epoch 0
Length of dataset: 47

(Val @ epoch 0) acc: 0.8475935828877005; ap: 0.9037618683106098
Validation accuracy increased (-inf --> 0.847594).  Saving model ...
Train loss: 0.40924686193466187 at step: 800
Iter time:  0.14671757012605668
saving the model at the end of epoch 1
Length of dataset: 47

(Val @ epoch 1) acc: 0.8649732620320856; ap: 0.9254648578356961
Validation accuracy increased (0.847594 --> 0.864973).  Saving model ...
Train loss: 0.3152778148651123 at step: 1200
Iter time:  0.15019111653168996
saving the model at the end of epoch 2
Length of dataset: 47

(Val @ epoch 2) acc: 0.8796791443850267; ap: 0.9276378102350017
Validation accuracy increased (0.864973 --> 0.879679).  Saving model ...
Train loss: 0.23503053188323975 at step: 1600
Iter time:  0.15215203389525414
saving the model at the end of epoch 3
Length of dataset: 47

(Val @ epoch 3) acc: 0.8850267379679144; ap: 0.937560097818937
Validation accuracy increased (0.879679 --> 0.885027).  Saving model ...
Train loss: 0.3230314254760742 at step: 2000
Iter time:  0.15331882429122926
saving the model at the end of epoch 4
Length of dataset: 47

(Val @ epoch 4) acc: 0.9010695187165776; ap: 0.9405548090628764
Validation accuracy increased (0.885027 --> 0.901070).  Saving model ...
Train loss: 0.28221607208251953 at step: 2400
Iter time:  0.1541355745991071
saving the model at the end of epoch 5
Length of dataset: 47

(Val @ epoch 5) acc: 0.8997326203208557; ap: 0.9478223813306166
EarlyStopping counter: 1 out of 3
Train loss: 0.211110919713974 at step: 2800
Iter time:  0.15465910809380667
saving the model at the end of epoch 6
Length of dataset: 47

(Val @ epoch 6) acc: 0.9050802139037433; ap: 0.9444284067567936
Validation accuracy increased (0.901070 --> 0.905080).  Saving model ...
Train loss: 0.17044681310653687 at step: 3200
Iter time:  0.15505078099668027
saving the model at the end of epoch 7
Length of dataset: 47

(Val @ epoch 7) acc: 0.8917112299465241; ap: 0.9437628505403799
EarlyStopping counter: 1 out of 3
Train loss: 0.21373474597930908 at step: 3600
Iter time:  0.1554318501551946
saving the model at the end of epoch 8
Length of dataset: 47

(Val @ epoch 8) acc: 0.9064171122994652; ap: 0.9508610320419995
Validation accuracy increased (0.905080 --> 0.906417).  Saving model ...
Train loss: 0.39121440052986145 at step: 4000
Iter time:  0.1556790847182274
saving the model at the end of epoch 9
Length of dataset: 47

(Val @ epoch 9) acc: 0.9050802139037433; ap: 0.9512040556904051
EarlyStopping counter: 1 out of 3
Train loss: 0.13761425018310547 at step: 4400
Iter time:  0.1558833995732394
saving the model at the end of epoch 10
Length of dataset: 47

(Val @ epoch 10) acc: 0.9037433155080213; ap: 0.9512534656991716
EarlyStopping counter: 2 out of 3
Train loss: 0.18717622756958008 at step: 4800
Iter time:  0.15604349970817566
saving the model at the end of epoch 11
Length of dataset: 47

(Val @ epoch 11) acc: 0.9010695187165776; ap: 0.9566283157680431
EarlyStopping counter: 3 out of 3
Learning rate dropped by 10, continue training...
Train loss: 0.17527322471141815 at step: 5200
Iter time:  0.15622059024297275
saving the model at the end of epoch 12
Length of dataset: 47

(Val @ epoch 12) acc: 0.9037433155080213; ap: 0.9586269393892849
Validation accuracy increased (-inf --> 0.903743).  Saving model ...
Train loss: 0.10386629402637482 at step: 5600
Iter time:  0.15641345279557364
saving the model at the end of epoch 13
Length of dataset: 47

(Val @ epoch 13) acc: 0.910427807486631; ap: 0.9591273856261833
Validation accuracy increased (0.903743 --> 0.910428).  Saving model ...
Train loss: 0.06509967148303986 at step: 6000
Iter time:  0.15651270087560018
saving the model at the end of epoch 14
Length of dataset: 47

(Val @ epoch 14) acc: 0.9090909090909091; ap: 0.9549833021379737
EarlyStopping counter: 1 out of 3
Train loss: 0.134181410074234 at step: 6400
Iter time:  0.156636320091784
saving the model at the end of epoch 15
Length of dataset: 47

(Val @ epoch 15) acc: 0.9064171122994652; ap: 0.9528610149082283
EarlyStopping counter: 2 out of 3
Train loss: 0.19661755859851837 at step: 6800
Iter time:  0.1567568408391055
saving the model at the end of epoch 16
Length of dataset: 47

(Val @ epoch 16) acc: 0.9010695187165776; ap: 0.9511145621410869
EarlyStopping counter: 3 out of 3
Learning rate dropped by 10, continue training...
Train loss: 0.11347921192646027 at step: 7200
Iter time:  0.15688084734810723
saving the model at the end of epoch 17
Length of dataset: 47

(Val @ epoch 17) acc: 0.9117647058823529; ap: 0.9550186496179969
Validation accuracy increased (-inf --> 0.911765).  Saving model ...
Train loss: 0.22818134725093842 at step: 7600
Iter time:  0.1569815221899434
saving the model at the end of epoch 18
Length of dataset: 47

(Val @ epoch 18) acc: 0.9037433155080213; ap: 0.9558319070883549
EarlyStopping counter: 1 out of 3
Train loss: 0.12409229576587677 at step: 8000
Iter time:  0.15707416781783104
Train loss: 0.38425952196121216 at step: 8400
Iter time:  0.15610293771539416
saving the model at the end of epoch 19
Length of dataset: 47

(Val @ epoch 19) acc: 0.9064171122994652; ap: 0.9545219161598798
EarlyStopping counter: 2 out of 3
Train loss: 0.3005032241344452 at step: 8800
Iter time:  0.15617367665876042
saving the model at the end of epoch 20
Length of dataset: 47

(Val @ epoch 20) acc: 0.9131016042780749; ap: 0.9610732113350723
EarlyStopping counter: 3 out of 3
Early stopping.
Training completed in 23 minutes and 7 seconds.
