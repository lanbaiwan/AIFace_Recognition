layer 23 cls+ batchsize=16+BCEloss+Gaussian noise std=0.01

Set Seed: 0
----------------- Options ---------------
                     arch: CLIP:ViT-L/14                 	[default: res50]
               batch_size: 16                            	[default: 256]
                    beta1: 0.9                           
                blur_prob: 0.5                           
                 blur_sig: 0.0, 2.0                      
          checkpoints_dir: ./checkpoints                 
                class_bal: None                          
                 cropSize: 224                           
                 data_aug: False                         
               data_label: train                         
                data_mode: ours                          
          earlystop_epoch: 3                             
              epoch_count: 1                             
           fake_list_path: /home/data/szk/our_dataset/1_fake	[default: None]
             fix_backbone: True                          	[default: False]
                focalloss: False                         
                  gpu_ids: 6                             	[default: 0]
                init_gain: 0.02                          
                init_type: normal                        
                  isTrain: True                          	[default: None]
               jpg_method: cv2,pil                       
                 jpg_prob: 0.5                           
                 jpg_qual: 30, 100                       
               last_epoch: -1                            
                 loadSize: 224                           
                loss_freq: 400                           
                       lr: 0.0001                        
                     mode: binary                        
                     name: clip_vitl14-2024-09-27-20-10-59	[default: experiment_name]
                    niter: 100                           
                  no_crop: False                         
                  no_flip: False                         
              num_threads: 4                             
                    optim: adam                          
           real_list_path: /home/data/szk/our_dataset/0_real	[default: None]
           resize_or_crop: scale_and_crop                
                rz_interp: bilinear                      
          save_epoch_freq: 1                             
           serial_batches: False                         
                   suffix: time                          	[default: ]
              train_split: train                         
                val_split: val                           
       wang2020_data_path: None                          
             weight_decay: 0.0                           
----------------- End -------------------
Directory ./checkpoints/clip_vitl14-2024-09-27-20-10-59 is created.
Choose layer: 23 for cls embedding
Add Gaussian noise to the feature embedding
Use BCELoss!
Use CenterCrop
Use RandomHorizontalFlip
mean and std stats are from:  clip
using Official CLIP's normalization
Do not use crop
Resize image to (224,224)
mean and std stats are from:  clip
using Official CLIP's normalization
Length of data loader: 421
Train loss: 0.3807357847690582 at step: 400
Iter time:  0.1374921542406082
saving the model at the end of epoch 0
Length of dataset: 47

(Val @ epoch 0) acc: 0.8475935828877005; ap: 0.9031873462528757
Validation accuracy increased (-inf --> 0.847594).  Saving model ...
Train loss: 0.4086320102214813 at step: 800
Iter time:  0.14714160919189453
saving the model at the end of epoch 1
Length of dataset: 47

(Val @ epoch 1) acc: 0.8649732620320856; ap: 0.9253652035901735
Validation accuracy increased (0.847594 --> 0.864973).  Saving model ...
Train loss: 0.3153298497200012 at step: 1200
Iter time:  0.15040745596090951
saving the model at the end of epoch 2
Length of dataset: 47

(Val @ epoch 2) acc: 0.8796791443850267; ap: 0.9277708716842273
Validation accuracy increased (0.864973 --> 0.879679).  Saving model ...
Train loss: 0.23535650968551636 at step: 1600
Iter time:  0.1521034488081932
saving the model at the end of epoch 3
Length of dataset: 47

(Val @ epoch 3) acc: 0.8850267379679144; ap: 0.9373374334987806
Validation accuracy increased (0.879679 --> 0.885027).  Saving model ...
Train loss: 0.3233843445777893 at step: 2000
Iter time:  0.1531024603843689
saving the model at the end of epoch 4
Length of dataset: 47

(Val @ epoch 4) acc: 0.9024064171122995; ap: 0.9402448948267222
Validation accuracy increased (0.885027 --> 0.902406).  Saving model ...
Train loss: 0.2828451097011566 at step: 2400
Iter time:  0.15375196894009907
saving the model at the end of epoch 5
Length of dataset: 47

(Val @ epoch 5) acc: 0.8970588235294118; ap: 0.947822053320378
EarlyStopping counter: 1 out of 3
Train loss: 0.21019785106182098 at step: 2800
Iter time:  0.1541925596339362
saving the model at the end of epoch 6
Length of dataset: 47

(Val @ epoch 6) acc: 0.9050802139037433; ap: 0.944433367355489
Validation accuracy increased (0.902406 --> 0.905080).  Saving model ...
Train loss: 0.1705540418624878 at step: 3200
Iter time:  0.15454892501235007
saving the model at the end of epoch 7
Length of dataset: 47

(Val @ epoch 7) acc: 0.8917112299465241; ap: 0.9441302639241343
EarlyStopping counter: 1 out of 3
Train loss: 0.21544238924980164 at step: 3600
Iter time:  0.15500969098673925
saving the model at the end of epoch 8
Length of dataset: 47

(Val @ epoch 8) acc: 0.9077540106951871; ap: 0.9511786342635556
Validation accuracy increased (0.905080 --> 0.907754).  Saving model ...
Train loss: 0.39227163791656494 at step: 4000
Iter time:  0.1552539290189743
saving the model at the end of epoch 9
Length of dataset: 47

(Val @ epoch 9) acc: 0.9064171122994652; ap: 0.9510982695195576
EarlyStopping counter: 1 out of 3
Train loss: 0.13818854093551636 at step: 4400
Iter time:  0.1554319286888296
saving the model at the end of epoch 10
Length of dataset: 47

(Val @ epoch 10) acc: 0.9037433155080213; ap: 0.9512049956606201
EarlyStopping counter: 2 out of 3
Train loss: 0.18866713345050812 at step: 4800
Iter time:  0.15558329860369363
saving the model at the end of epoch 11
Length of dataset: 47

(Val @ epoch 11) acc: 0.9037433155080213; ap: 0.9565510810205612
EarlyStopping counter: 3 out of 3
Learning rate dropped by 10, continue training...
Train loss: 0.17683188617229462 at step: 5200
Iter time:  0.15575844668425046
saving the model at the end of epoch 12
Length of dataset: 47

(Val @ epoch 12) acc: 0.9037433155080213; ap: 0.9581877429356894
Validation accuracy increased (-inf --> 0.903743).  Saving model ...
Train loss: 0.10433828830718994 at step: 5600
Iter time:  0.1558932650940759
saving the model at the end of epoch 13
Length of dataset: 47

(Val @ epoch 13) acc: 0.910427807486631; ap: 0.9590398353241906
Validation accuracy increased (0.903743 --> 0.910428).  Saving model ...
Train loss: 0.06511647254228592 at step: 6000
Iter time:  0.1560108070373535
saving the model at the end of epoch 14
Length of dataset: 47

(Val @ epoch 14) acc: 0.910427807486631; ap: 0.954954666271318
EarlyStopping counter: 1 out of 3
Train loss: 0.1345544159412384 at step: 6400
Iter time:  0.15613799791783095
saving the model at the end of epoch 15
Length of dataset: 47

(Val @ epoch 15) acc: 0.9077540106951871; ap: 0.9530473198332311
EarlyStopping counter: 2 out of 3
Train loss: 0.1962670087814331 at step: 6800
Iter time:  0.1562343022402595
saving the model at the end of epoch 16
Length of dataset: 47

(Val @ epoch 16) acc: 0.9010695187165776; ap: 0.9511059295203547
EarlyStopping counter: 3 out of 3
Learning rate dropped by 10, continue training...
Train loss: 0.11350187659263611 at step: 7200
Iter time:  0.1563408148288727
saving the model at the end of epoch 17
Length of dataset: 47

(Val @ epoch 17) acc: 0.910427807486631; ap: 0.9552978558352232
Validation accuracy increased (-inf --> 0.910428).  Saving model ...
Train loss: 0.22839558124542236 at step: 7600
Iter time:  0.15642780532962397
saving the model at the end of epoch 18
Length of dataset: 47

(Val @ epoch 18) acc: 0.9037433155080213; ap: 0.9559524679249035
EarlyStopping counter: 1 out of 3
Train loss: 0.12391279637813568 at step: 8000
Iter time:  0.15651064637303352
Train loss: 0.3843429982662201 at step: 8400
Iter time:  0.15555647600264777
saving the model at the end of epoch 19
Length of dataset: 47

(Val @ epoch 19) acc: 0.9064171122994652; ap: 0.954287578629317
EarlyStopping counter: 2 out of 3
Train loss: 0.30445602536201477 at step: 8800
Iter time:  0.15563910912383686
saving the model at the end of epoch 20
Length of dataset: 47

(Val @ epoch 20) acc: 0.9144385026737968; ap: 0.961190367784923
Validation accuracy increased (0.910428 --> 0.914439).  Saving model ...
Train loss: 0.07841825485229492 at step: 9200
Iter time:  0.15572950658590898
saving the model at the end of epoch 21
Length of dataset: 47

(Val @ epoch 21) acc: 0.9197860962566845; ap: 0.9555394364006634
Validation accuracy increased (0.914439 --> 0.919786).  Saving model ...
Train loss: 0.24969065189361572 at step: 9600
Iter time:  0.15580738107363382
saving the model at the end of epoch 22
Length of dataset: 47

(Val @ epoch 22) acc: 0.9077540106951871; ap: 0.9530894287476528
EarlyStopping counter: 1 out of 3
Train loss: 0.25837746262550354 at step: 10000
Iter time:  0.15587880697250367
saving the model at the end of epoch 23
Length of dataset: 47

(Val @ epoch 23) acc: 0.9064171122994652; ap: 0.9529044535565792
EarlyStopping counter: 2 out of 3
Train loss: 0.16991622745990753 at step: 10400
Iter time:  0.15593815883764853
saving the model at the end of epoch 24
Length of dataset: 47

(Val @ epoch 24) acc: 0.9064171122994652; ap: 0.953536639544375
EarlyStopping counter: 3 out of 3
Early stopping.
Training completed in 27 minutes and 26 seconds.
