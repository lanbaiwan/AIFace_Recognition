Model loaded..
Use LinearProbe head: pretrained_weights/10_12.pth
Choose layer: 23 for cls embedding
Not add Gaussian noise to the feature embedding.
Not use random erasing.
data mode: ours
[{'data_path': '/home/data/szk/face_B', 'data_mode': 'ours'}]
total_list_len: 6000
Fix the backbone.
Length of dataset: 375
Directory ./TTO_checkpoints/2024-10-12-22-31-12 is created.
Train loss: 0.6604973673820496 at step: 1
Iter time:  0.9161443710327148


Train loss: 0.7453159093856812 at step: 2
Iter time:  0.5915672779083252


Train loss: 0.5463340282440186 at step: 3
Iter time:  0.4869110584259033


Train loss: 0.68174147605896 at step: 4
Iter time:  0.4328022599220276


Train loss: 0.674164891242981 at step: 5
Iter time:  0.40012969970703127


Train loss: 0.6052654981613159 at step: 6
Iter time:  0.3782740831375122


Train loss: 0.6562347412109375 at step: 7
Iter time:  0.3626644951956613


Train loss: 0.5594989061355591 at step: 8
Iter time:  0.35119152069091797


Train loss: 0.734427809715271 at step: 9
Iter time:  0.342110554377238


Train loss: 0.6999895572662354 at step: 10
Iter time:  0.3348772764205933


Train loss: 0.7268655896186829 at step: 11
Iter time:  0.3289373787966641


Train loss: 0.7888016700744629 at step: 12
Iter time:  0.3238936861356099


Train loss: 0.6902535557746887 at step: 13
Iter time:  0.31963421748234677


Train loss: 0.6999120116233826 at step: 14
Iter time:  0.31635596070970806


Train loss: 0.7200229167938232 at step: 15
Iter time:  0.31318933169047036


Train loss: 0.6663559079170227 at step: 16
Iter time:  0.310446172952652


Train loss: 0.5641534328460693 at step: 17
Iter time:  0.30805712587693157


Train loss: 0.6399879455566406 at step: 18
Iter time:  0.30587710274590385


Train loss: 0.7080931663513184 at step: 19
Iter time:  0.30400225990696955


Train loss: 0.7085364460945129 at step: 20
Iter time:  0.30225664377212524


Train loss: 0.631043553352356 at step: 21
Iter time:  0.30066702479407903


Train loss: 0.6679821014404297 at step: 22
Iter time:  0.2992235638878562


Train loss: 0.5914582014083862 at step: 23
Iter time:  0.29791563490162726


Train loss: 0.7640378475189209 at step: 24
Iter time:  0.29674261808395386


Train loss: 0.5824885368347168 at step: 25
Iter time:  0.29565360069274904


Train loss: 0.7813596129417419 at step: 26
Iter time:  0.2946245945416964


Train loss: 0.6053597927093506 at step: 27
Iter time:  0.293699926800198


Train loss: 0.6751765012741089 at step: 28
Iter time:  0.29281212602342876


Train loss: 0.5519011616706848 at step: 29
Iter time:  0.29210967031018487


Train loss: 0.6501045227050781 at step: 30
Iter time:  0.2913224776585897


Train loss: 0.6561657190322876 at step: 31
Iter time:  0.29057258944357595


Train loss: 0.6727441549301147 at step: 32
Iter time:  0.28987834602594376


Train loss: 0.7764923572540283 at step: 33
Iter time:  0.28924119833743933


Train loss: 0.6959760189056396 at step: 34
Iter time:  0.28864844406352325


Train loss: 0.8159618377685547 at step: 35
Iter time:  0.28806826046534945


Train loss: 0.546556830406189 at step: 36
Iter time:  0.2875254551569621


Train loss: 0.6725822687149048 at step: 37
Iter time:  0.28701394313090556


Train loss: 0.7920629978179932 at step: 38
Iter time:  0.28653595949474137


Train loss: 0.642987072467804 at step: 39
Iter time:  0.2861001797211476


Train loss: 0.6861568689346313 at step: 40
Iter time:  0.28566492795944215


Train loss: 0.614717960357666 at step: 41
Iter time:  0.28525795006170507


Train loss: 0.7130367755889893 at step: 42
Iter time:  0.28488201186770484


Train loss: 0.6504175662994385 at step: 43
Iter time:  0.28452181261639264


Train loss: 0.7263885736465454 at step: 44
Iter time:  0.2841873114759272


Train loss: 0.7262213230133057 at step: 45
Iter time:  0.28384261661105686


Train loss: 0.7059644460678101 at step: 46
Iter time:  0.2835097209266994


Train loss: 0.6816483736038208 at step: 47
Iter time:  0.2832014205607962


Train loss: 0.6793955564498901 at step: 48
Iter time:  0.28290631373723346


Train loss: 0.750293493270874 at step: 49
Iter time:  0.2826172964913504


Train loss: 0.808717668056488 at step: 50
Iter time:  0.2823409605026245


Train loss: 0.531641960144043 at step: 51
Iter time:  0.2820741522545908


Train loss: 0.6496412754058838 at step: 52
Iter time:  0.28182926086279064


Train loss: 0.6136753559112549 at step: 53
Iter time:  0.28161994016395425


Train loss: 0.6033142805099487 at step: 54
Iter time:  0.2813892364501953


Train loss: 0.7174934148788452 at step: 55
Iter time:  0.2811722278594971


Train loss: 0.6827119588851929 at step: 56
Iter time:  0.2809499331883022


Train loss: 0.5100210905075073 at step: 57
Iter time:  0.28074540171706885


Train loss: 0.5919412970542908 at step: 58
Iter time:  0.28058269517175083


Train loss: 0.6629729270935059 at step: 59
Iter time:  0.28038260896327133


Train loss: 0.559423565864563 at step: 60
Iter time:  0.2801885922749837


Train loss: 0.752015233039856 at step: 61
Iter time:  0.2800163011081883


Train loss: 0.7707618474960327 at step: 62
Iter time:  0.2798354933338781


Train loss: 0.6097238063812256 at step: 63
Iter time:  0.2796774402497307


Train loss: 0.6771241426467896 at step: 64
Iter time:  0.27950985729694366


Train loss: 0.6367577314376831 at step: 65
Iter time:  0.27935296572171725


Train loss: 0.6437188386917114 at step: 66
Iter time:  0.27920519583153003


Train loss: 0.7343245148658752 at step: 67
Iter time:  0.27907157655972153


Train loss: 0.7073975801467896 at step: 68
Iter time:  0.27893587771584005


Train loss: 0.7129725217819214 at step: 69
Iter time:  0.27880108183708746


Train loss: 0.750389039516449 at step: 70
Iter time:  0.27868013381958007


Train loss: 0.7017069458961487 at step: 71
Iter time:  0.2785595638651243


Train loss: 0.751007080078125 at step: 72
Iter time:  0.27845578723483616


Train loss: 0.6324077248573303 at step: 73
Iter time:  0.2783398595574784


Train loss: 0.6434441804885864 at step: 74
Iter time:  0.27822980365237676


Train loss: 0.5929746031761169 at step: 75
Iter time:  0.27812609672546384


Train loss: 0.6991324424743652 at step: 76
Iter time:  0.278017753048947


Train loss: 0.7097526788711548 at step: 77
Iter time:  0.2779153569952234


Train loss: 0.7018579244613647 at step: 78
Iter time:  0.27783812009371245


Train loss: 0.6747943162918091 at step: 79
Iter time:  0.27774378619616547


Train loss: 0.6913392543792725 at step: 80
Iter time:  0.2776551216840744


Train loss: 0.6525091528892517 at step: 81
Iter time:  0.27756703635792673


Train loss: 0.7279862761497498 at step: 82
Iter time:  0.277477197530793


Train loss: 0.6692084074020386 at step: 83
Iter time:  0.27741105872464467


Train loss: 0.6579028964042664 at step: 84
Iter time:  0.27732457717259723


Train loss: 0.7222461700439453 at step: 85
Iter time:  0.2772476785323199


Train loss: 0.6852267384529114 at step: 86
Iter time:  0.27716990958812626


Train loss: 0.708495557308197 at step: 87
Iter time:  0.2770948875909564


Train loss: 0.5717024803161621 at step: 88
Iter time:  0.2770292488011447


Train loss: 0.629249095916748 at step: 89
Iter time:  0.2769560653172182


Train loss: 0.651313066482544 at step: 90
Iter time:  0.2768813371658325


Train loss: 0.7809804677963257 at step: 91
Iter time:  0.27680841121044786


Train loss: 0.6775568723678589 at step: 92
Iter time:  0.2767499866692916


Train loss: 0.6493797302246094 at step: 93
Iter time:  0.2766845585197531


Train loss: 0.684145450592041 at step: 94
Iter time:  0.276620885159107


Train loss: 0.6608827114105225 at step: 95
Iter time:  0.27656019863329434


Train loss: 0.5541354417800903 at step: 96
Iter time:  0.27650808294614154


Train loss: 0.6827718019485474 at step: 97
Iter time:  0.27645420536552506


Train loss: 0.7719631791114807 at step: 98
Iter time:  0.27641491743983054


Train loss: 0.7002438306808472 at step: 99
Iter time:  0.27635782896870315


Train loss: 0.6887755393981934 at step: 100
Iter time:  0.276299033164978


Train loss: 0.723795473575592 at step: 101
Iter time:  0.2762520761773138


Train loss: 0.6589242219924927 at step: 102
Iter time:  0.2762056051516065


Train loss: 0.7200273871421814 at step: 103
Iter time:  0.27615101129105946


Train loss: 0.631018340587616 at step: 104
Iter time:  0.2761030930739183


Train loss: 0.7600603699684143 at step: 105
Iter time:  0.2760565893990653


Train loss: 0.5607905983924866 at step: 106
Iter time:  0.2760108934258515


Train loss: 0.7219909429550171 at step: 107
Iter time:  0.275985662068162


Train loss: 0.7493793368339539 at step: 108
Iter time:  0.2759371686864782


Train loss: 0.7371562719345093 at step: 109
Iter time:  0.275895711478837


Train loss: 0.680390477180481 at step: 110
Iter time:  0.27585215785286643


Train loss: 0.6851135492324829 at step: 111
Iter time:  0.27580952644348145


Train loss: 0.6861083507537842 at step: 112
Iter time:  0.2757792557988848


Train loss: 0.6818605661392212 at step: 113
Iter time:  0.27573462081166494


Train loss: 0.6890555620193481 at step: 114
Iter time:  0.2756942406035306


Train loss: 0.6971241235733032 at step: 115
Iter time:  0.275655170108961


Train loss: 0.6534322500228882 at step: 116
Iter time:  0.2756176220959631


Train loss: 0.6564764380455017 at step: 117
Iter time:  0.27559012225550467


Train loss: 0.6605861783027649 at step: 118
Iter time:  0.2755554328530522


Train loss: 0.6708576083183289 at step: 119
Iter time:  0.27551947721914083


Train loss: 0.5772639513015747 at step: 120
Iter time:  0.2754888296127319


Train loss: 0.7035161256790161 at step: 121
Iter time:  0.27545767973277197


Train loss: 0.7477697134017944 at step: 122
Iter time:  0.27542561585785913


Train loss: 0.642132043838501 at step: 123
Iter time:  0.27539864594374247


Train loss: 0.7290661334991455 at step: 124
Iter time:  0.27536827325820923


Train loss: 0.669861376285553 at step: 125
Iter time:  0.27534061622619627


Train loss: 0.48383691906929016 at step: 126
Iter time:  0.27531923944987946


Train loss: 0.735615611076355 at step: 127
Iter time:  0.2752872827484852


Train loss: 0.725489616394043 at step: 128
Iter time:  0.27526133693754673


Train loss: 0.7468713521957397 at step: 129
Iter time:  0.2752359856006711


Train loss: 0.7837375998497009 at step: 130
Iter time:  0.2752195266576914


Train loss: 0.719322919845581 at step: 131
Iter time:  0.2752026055605357


Train loss: 0.7815802693367004 at step: 132
Iter time:  0.2751903317191384


Train loss: 0.6271059513092041 at step: 133
Iter time:  0.27517502648489817


Train loss: 0.7119995355606079 at step: 134
Iter time:  0.27515644457802846


Train loss: 0.6857945322990417 at step: 135
Iter time:  0.2751471554791486


Train loss: 0.6709418296813965 at step: 136
Iter time:  0.2751319443478304


Train loss: 0.6283904910087585 at step: 137
Iter time:  0.2751217619346006


Train loss: 0.6015810966491699 at step: 138
Iter time:  0.27511279824851215


Train loss: 0.7362262606620789 at step: 139
Iter time:  0.27511163066617017


Train loss: 0.7473160624504089 at step: 140
Iter time:  0.27511039461408343


Train loss: 0.7583534717559814 at step: 141
Iter time:  0.27510333568491835


Train loss: 0.7406313419342041 at step: 142
Iter time:  0.27509615454875247


Train loss: 0.6498242616653442 at step: 143
Iter time:  0.27507405847936245


Train loss: 0.666228175163269 at step: 144
Iter time:  0.2750529862112469


Train loss: 0.639641284942627 at step: 145
Iter time:  0.27503959063825933


Train loss: 0.6547846794128418 at step: 146
Iter time:  0.27501676017290927


Train loss: 0.5633143186569214 at step: 147
Iter time:  0.27499542268766025


Train loss: 0.6070966124534607 at step: 148
Iter time:  0.27497187659547134


Train loss: 0.7343037128448486 at step: 149
Iter time:  0.2749541573876503


Train loss: 0.6644157767295837 at step: 150
Iter time:  0.27493161042531333


Train loss: 0.6149622201919556 at step: 151
Iter time:  0.27491716991197196


Train loss: 0.7344861030578613 at step: 152
Iter time:  0.27490173829229253


Train loss: 0.5982931852340698 at step: 153
Iter time:  0.27488670785442676


Train loss: 0.7841012477874756 at step: 154
Iter time:  0.27486746342151197


Train loss: 0.6890600919723511 at step: 155
Iter time:  0.27485338641751195


Train loss: 0.6562888622283936 at step: 156
Iter time:  0.2748341942444826


Train loss: 0.663077175617218 at step: 157
Iter time:  0.2748159876294956


Train loss: 0.6296740770339966 at step: 158
Iter time:  0.27480397496042375


Train loss: 0.5899530053138733 at step: 159
Iter time:  0.27479140263683394


Train loss: 0.6506025791168213 at step: 160
Iter time:  0.2747833028435707


Train loss: 0.6453065872192383 at step: 161
Iter time:  0.27476976969227285


Train loss: 0.5929322242736816 at step: 162
Iter time:  0.27475689517127144


Train loss: 0.6856482028961182 at step: 163
Iter time:  0.2747421367036784


Train loss: 0.635685920715332 at step: 164
Iter time:  0.2747279332905281


Train loss: 0.761013388633728 at step: 165
Iter time:  0.2747128761175907


Train loss: 0.6926314234733582 at step: 166
Iter time:  0.27470732309732093


Train loss: 0.7368739247322083 at step: 167
Iter time:  0.27469476825462846


Train loss: 0.716884195804596 at step: 168
Iter time:  0.27468113388334003


Train loss: 0.8141369819641113 at step: 169
Iter time:  0.2746666267778746


Train loss: 0.6229515671730042 at step: 170
Iter time:  0.27465304627138026


Train loss: 0.7046729326248169 at step: 171
Iter time:  0.2746482787773623


Train loss: 0.49280619621276855 at step: 172
Iter time:  0.2746355824692305


Train loss: 0.6211224794387817 at step: 173
Iter time:  0.27462408721791526


Train loss: 0.5697301626205444 at step: 174
Iter time:  0.27461176631094397


Train loss: 0.70490962266922 at step: 175
Iter time:  0.2746018055507115


Train loss: 0.7140177488327026 at step: 176
Iter time:  0.2745907564054836


Train loss: 0.626380205154419 at step: 177
Iter time:  0.274577709241102


Train loss: 0.6767202615737915 at step: 178
Iter time:  0.2745695114135742


Train loss: 0.6352367401123047 at step: 179
Iter time:  0.2745580353550405


Train loss: 0.615696370601654 at step: 180
Iter time:  0.27454528676138984


Train loss: 0.763251543045044 at step: 181
Iter time:  0.27454046386381536


Train loss: 0.672814130783081 at step: 182
Iter time:  0.2745302208177336


Train loss: 0.6008462309837341 at step: 183
Iter time:  0.27451859667001527


Train loss: 0.7204570770263672 at step: 184
Iter time:  0.27450670755427814


Train loss: 0.6831910610198975 at step: 185
Iter time:  0.27450023470698176


Train loss: 0.6657850742340088 at step: 186
Iter time:  0.27449119860126125


Train loss: 0.7201582193374634 at step: 187
Iter time:  0.27448151710836644


Train loss: 0.7431917190551758 at step: 188
Iter time:  0.2744697763564739


Train loss: 0.7422847151756287 at step: 189
Iter time:  0.2744629711070389


Train loss: 0.7639584541320801 at step: 190
Iter time:  0.2744558447285702


Train loss: 0.6486942768096924 at step: 191
Iter time:  0.27445397327083565


Train loss: 0.6235363483428955 at step: 192
Iter time:  0.2744448371231556


Train loss: 0.5670204162597656 at step: 193
Iter time:  0.2744367592075328


Train loss: 0.6746630668640137 at step: 194
Iter time:  0.27442905583332494


Train loss: 0.7842043042182922 at step: 195
Iter time:  0.2744182403271015


Train loss: 0.7484853267669678 at step: 196
Iter time:  0.2744173663003104


Train loss: 0.7322255373001099 at step: 197
Iter time:  0.27440918641647105


Train loss: 0.6102732419967651 at step: 198
Iter time:  0.2743992371992631


Train loss: 0.756982684135437 at step: 199
Iter time:  0.27439067711183174


Train loss: 0.678156316280365 at step: 200
Iter time:  0.2743829095363617


Train loss: 0.6544886827468872 at step: 201
Iter time:  0.2743756688056301


Train loss: 0.6947073936462402 at step: 202
Iter time:  0.27437033157537477


Train loss: 0.6827976107597351 at step: 203
Iter time:  0.27436155403776125


Train loss: 0.474637508392334 at step: 204
Iter time:  0.2743559316092846


Train loss: 0.7389737367630005 at step: 205
Iter time:  0.2743602240957865


Train loss: 0.5302298069000244 at step: 206
Iter time:  0.27435366389820875


Train loss: 0.7061612606048584 at step: 207
Iter time:  0.2743468445856214


Train loss: 0.7502914071083069 at step: 208
Iter time:  0.2743390236909573


Train loss: 0.6966150999069214 at step: 209
Iter time:  0.2743291923303924


Train loss: 0.644982099533081 at step: 210
Iter time:  0.27432291961851574


Train loss: 0.6875077486038208 at step: 211
Iter time:  0.2743167978892394


Train loss: 0.6870287656784058 at step: 212
Iter time:  0.27430907285438394


Train loss: 0.6051998734474182 at step: 213
Iter time:  0.2743040899715513


Train loss: 0.6979549527168274 at step: 214
Iter time:  0.27429964052182493


Train loss: 0.6032675504684448 at step: 215
Iter time:  0.2742950971736464


Train loss: 0.6126506924629211 at step: 216
Iter time:  0.274286616731573


Train loss: 0.6271381378173828 at step: 217
Iter time:  0.2742814116763629


Train loss: 0.7662780284881592 at step: 218
Iter time:  0.27427426062592675


Train loss: 0.6455656290054321 at step: 219
Iter time:  0.2742690223537079


Train loss: 0.6758229732513428 at step: 220
Iter time:  0.27426375367424705


Train loss: 0.6719055771827698 at step: 221
Iter time:  0.2742575099565325


Train loss: 0.6302859783172607 at step: 222
Iter time:  0.27425163178830536


Train loss: 0.6348102688789368 at step: 223
Iter time:  0.27424539365041417


Train loss: 0.690536618232727 at step: 224
Iter time:  0.27423919311591555


Train loss: 0.5819066166877747 at step: 225
Iter time:  0.2742339293162028


Train loss: 0.6982322931289673 at step: 226
Iter time:  0.2742338634170262


Train loss: 0.7148441076278687 at step: 227
Iter time:  0.2742297344795933


Train loss: 0.5811117887496948 at step: 228
Iter time:  0.2742252872701277


Train loss: 0.6624933481216431 at step: 229
Iter time:  0.2742198054967489


Train loss: 0.5535270571708679 at step: 230
Iter time:  0.27421399821405823


Train loss: 0.6227558255195618 at step: 231
Iter time:  0.274211090880555


Train loss: 0.5691485404968262 at step: 232
Iter time:  0.27420485122450466


Train loss: 0.5898241996765137 at step: 233
Iter time:  0.27419845331380294


Train loss: 0.6754878163337708 at step: 234
Iter time:  0.2741961010500916


Train loss: 0.5729103684425354 at step: 235
Iter time:  0.27419130548517756


Train loss: 0.6516422033309937 at step: 236
Iter time:  0.274191896794206


Train loss: 0.7539072036743164 at step: 237
Iter time:  0.2741868003008235


Train loss: 0.7257247567176819 at step: 238
Iter time:  0.27418015984927907


Train loss: 0.6565151214599609 at step: 239
Iter time:  0.27417537956557014


Train loss: 0.7981188893318176 at step: 240
Iter time:  0.27417131265004474


Train loss: 0.6082308292388916 at step: 241
Iter time:  0.27417081223483897


Train loss: 0.6636922359466553 at step: 242
Iter time:  0.2741654618712496


Train loss: 0.5775669813156128 at step: 243
Iter time:  0.27415987101111394


Train loss: 0.6042488813400269 at step: 244
Iter time:  0.2741543767882175


Train loss: 0.6692713499069214 at step: 245
Iter time:  0.2741499151502337


Train loss: 0.7043322920799255 at step: 246
Iter time:  0.27415398175154276


Train loss: 0.7490899562835693 at step: 247
Iter time:  0.27414784740339887


Train loss: 0.6945179104804993 at step: 248
Iter time:  0.27414292577774296


Train loss: 0.7440106272697449 at step: 249
Iter time:  0.2741389332047428


Train loss: 0.7396557331085205 at step: 250
Iter time:  0.2741354732513428


Train loss: 0.6784510612487793 at step: 251
Iter time:  0.27413038808511075


Train loss: 0.6387416124343872 at step: 252
Iter time:  0.27412454476432196


Train loss: 0.6866052746772766 at step: 253
Iter time:  0.27412061634742224


Train loss: 0.660081684589386 at step: 254
Iter time:  0.2741187632553221


Train loss: 0.6357818841934204 at step: 255
Iter time:  0.2741144348593319


Train loss: 0.5960283279418945 at step: 256
Iter time:  0.2741126650944352


Train loss: 0.6472162008285522 at step: 257
Iter time:  0.2741084553388306


Train loss: 0.7594664096832275 at step: 258
Iter time:  0.2741055978361026


Train loss: 0.6782035827636719 at step: 259
Iter time:  0.2741025865768374


Train loss: 0.625023603439331 at step: 260
Iter time:  0.2740985934550946


Train loss: 0.6157786846160889 at step: 261
Iter time:  0.2741096969765265


Train loss: 0.6784421801567078 at step: 262
Iter time:  0.27410775104551827


Train loss: 0.7076331377029419 at step: 263
Iter time:  0.2741060057520413


Train loss: 0.6195105910301208 at step: 264
Iter time:  0.2741040497115164


Train loss: 0.7082695960998535 at step: 265
Iter time:  0.27410269503323537


Train loss: 0.6458727121353149 at step: 266
Iter time:  0.2740994216804218


Train loss: 0.6563791036605835 at step: 267
Iter time:  0.27409492896290755


Train loss: 0.6359066963195801 at step: 268
Iter time:  0.2740928495108192


Train loss: 0.6847643852233887 at step: 269
Iter time:  0.27409084756135055


Train loss: 0.7244256734848022 at step: 270
Iter time:  0.27408942558147287


Train loss: 0.6046453714370728 at step: 271
Iter time:  0.27408641730727307


Train loss: 0.6782246828079224 at step: 272
Iter time:  0.27408503171275644


Train loss: 0.6520875692367554 at step: 273
Iter time:  0.27408298467978454


Train loss: 0.5931938886642456 at step: 274
Iter time:  0.2740815703886269


Train loss: 0.675805926322937 at step: 275
Iter time:  0.27408469980413264


Train loss: 0.6260448694229126 at step: 276
Iter time:  0.2740831772486369


Train loss: 0.5018481016159058 at step: 277
Iter time:  0.2740809814163924


Train loss: 0.6137279868125916 at step: 278
Iter time:  0.27408065641526697


Train loss: 0.6924718618392944 at step: 279
Iter time:  0.27407950739706716


Train loss: 0.6568219661712646 at step: 280
Iter time:  0.2740809031895229


Train loss: 0.5642987489700317 at step: 281
Iter time:  0.27407927021013034


Train loss: 0.5740728974342346 at step: 282
Iter time:  0.27407680504710963


Train loss: 0.6284434795379639 at step: 283
Iter time:  0.2740746749163516


Train loss: 0.6976529359817505 at step: 284
Iter time:  0.27407478362741605


Train loss: 0.7042120695114136 at step: 285
Iter time:  0.2740723768870036


Train loss: 0.5439771413803101 at step: 286
Iter time:  0.2740722777960184


Train loss: 0.7223296761512756 at step: 287
Iter time:  0.2740692627139208


Train loss: 0.6739531755447388 at step: 288
Iter time:  0.27406959070099723


Train loss: 0.6902440786361694 at step: 289
Iter time:  0.27406725174002994


Train loss: 0.6802023649215698 at step: 290
Iter time:  0.27406723170444885


Train loss: 0.7084155082702637 at step: 291
Iter time:  0.27406612376576844


Train loss: 0.6428102254867554 at step: 292
Iter time:  0.2740635292170799


Train loss: 0.6775192022323608 at step: 293
Iter time:  0.27406031361212096


Train loss: 0.7208355069160461 at step: 294
Iter time:  0.27405670873161886


Train loss: 0.6863356828689575 at step: 295
Iter time:  0.27405669406308963


Train loss: 0.6248743534088135 at step: 296
Iter time:  0.27405520065410716


Train loss: 0.5896750688552856 at step: 297
Iter time:  0.27405409700541383


Train loss: 0.6773891448974609 at step: 298
Iter time:  0.27405442087442283


Train loss: 0.6700042486190796 at step: 299
Iter time:  0.27405152432495933


Train loss: 0.6941763162612915 at step: 300
Iter time:  0.2740540647506714


Train loss: 0.6183210611343384 at step: 301
Iter time:  0.27405161715029086


Train loss: 0.5872037410736084 at step: 302
Iter time:  0.2740488778676418


Train loss: 0.6197414398193359 at step: 303
Iter time:  0.27404780985892013


Train loss: 0.615798830986023 at step: 304
Iter time:  0.27404609008839254


Train loss: 0.6488309502601624 at step: 305
Iter time:  0.27404163704543816


Train loss: 0.6465073227882385 at step: 306
Iter time:  0.27404045279509104


Train loss: 0.5660572052001953 at step: 307
Iter time:  0.27403833268131417


Train loss: 0.6870518922805786 at step: 308
Iter time:  0.27403400006232326


Train loss: 0.6616770625114441 at step: 309
Iter time:  0.27403894211482077


Train loss: 0.6109436750411987 at step: 310
Iter time:  0.2740360713774158


Train loss: 0.6912544369697571 at step: 311
Iter time:  0.2740372085877937


Train loss: 0.6368301510810852 at step: 312
Iter time:  0.27403383606519455


Train loss: 0.7133539319038391 at step: 313
Iter time:  0.2740316802320389


Train loss: 0.5910847187042236 at step: 314
Iter time:  0.27403586685277853


Train loss: 0.5866192579269409 at step: 315
Iter time:  0.27403450996156725


Train loss: 0.7118362188339233 at step: 316
Iter time:  0.2740313584291482


Train loss: 0.7562240958213806 at step: 317
Iter time:  0.27403020482710105


Train loss: 0.7334058284759521 at step: 318
Iter time:  0.27402897825780903


Train loss: 0.6936661005020142 at step: 319
Iter time:  0.2740289880937917


Train loss: 0.6918702125549316 at step: 320
Iter time:  0.2740284167230129


Train loss: 0.6302307844161987 at step: 321
Iter time:  0.27402578113235043


Train loss: 0.7038108110427856 at step: 322
Iter time:  0.27402546835241853


Train loss: 0.6365636587142944 at step: 323
Iter time:  0.27402436179642337


Train loss: 0.6625775694847107 at step: 324
Iter time:  0.27402066227830485


Train loss: 0.6699971556663513 at step: 325
Iter time:  0.2740188980102539


Train loss: 0.620802640914917 at step: 326
Iter time:  0.27401787883664935


Train loss: 0.6077380776405334 at step: 327
Iter time:  0.2740157058844144


Train loss: 0.7053342461585999 at step: 328
Iter time:  0.2740139903091803


Train loss: 0.5909906625747681 at step: 329
Iter time:  0.27401560128278646


Train loss: 0.6197363138198853 at step: 330
Iter time:  0.2740128264282689


Train loss: 0.7435248494148254 at step: 331
Iter time:  0.2740115125373771


Train loss: 0.7171950340270996 at step: 332
Iter time:  0.27401466470166863


Train loss: 0.641393780708313 at step: 333
Iter time:  0.27401466985364575


Train loss: 0.6111134886741638 at step: 334
Iter time:  0.27401474278844046


Train loss: 0.7506774067878723 at step: 335
Iter time:  0.27401325168894297


Train loss: 0.6986856460571289 at step: 336
Iter time:  0.2740132205543064


Train loss: 0.6282140016555786 at step: 337
Iter time:  0.2740111195369007


Train loss: 0.5730264186859131 at step: 338
Iter time:  0.27401029852015024


Train loss: 0.7556815147399902 at step: 339
Iter time:  0.2740177981621396


Train loss: 0.662700891494751 at step: 340
Iter time:  0.2740198808557847


Train loss: 0.6381329298019409 at step: 341
Iter time:  0.27402881722995615


Train loss: 0.6450369358062744 at step: 342
Iter time:  0.27402681147145946


Train loss: 0.6700576543807983 at step: 343
Iter time:  0.2740278216214639


Train loss: 0.6513579487800598 at step: 344
Iter time:  0.2740266593389733


Train loss: 0.71356600522995 at step: 345
Iter time:  0.27402369941490284


Train loss: 0.7334436774253845 at step: 346
Iter time:  0.27402273630131185


Train loss: 0.7189691066741943 at step: 347
Iter time:  0.27402236688377535


Train loss: 0.6929255723953247 at step: 348
Iter time:  0.274021620037912


Train loss: 0.6200488805770874 at step: 349
Iter time:  0.2740205591250969


Train loss: 0.6258774399757385 at step: 350
Iter time:  0.2740187570026943


Train loss: 0.6737082004547119 at step: 351
Iter time:  0.2740179779183151


Train loss: 0.7273049354553223 at step: 352
Iter time:  0.27401679821989755


Train loss: 0.6479727625846863 at step: 353
Iter time:  0.274024525715339


Train loss: 0.6282212734222412 at step: 354
Iter time:  0.2740244825007552


Train loss: 0.709839940071106 at step: 355
Iter time:  0.27402255568705813


Train loss: 0.4447282552719116 at step: 356
Iter time:  0.2740228618128916


Train loss: 0.6753000617027283 at step: 357
Iter time:  0.27402101444597005


Train loss: 0.576574444770813 at step: 358
Iter time:  0.27401927929350783


Train loss: 0.6912441253662109 at step: 359
Iter time:  0.27402173111365696


Train loss: 0.7386903762817383 at step: 360
Iter time:  0.2740209374162886


Train loss: 0.6727694272994995 at step: 361
Iter time:  0.2740192472769613


Train loss: 0.6970093250274658 at step: 362
Iter time:  0.27401778250109426


Train loss: 0.6022865772247314 at step: 363
Iter time:  0.27401753824932845


Train loss: 0.6606003046035767 at step: 364
Iter time:  0.2740180466201279


Train loss: 0.5912984609603882 at step: 365
Iter time:  0.2740165494892695


Train loss: 0.7299749851226807 at step: 366
Iter time:  0.2740153986248162


Train loss: 0.5427552461624146 at step: 367
Iter time:  0.27401463926975345


Train loss: 0.6476832628250122 at step: 368
Iter time:  0.2740124904591104


Train loss: 0.6583969593048096 at step: 369
Iter time:  0.27401482509726754


Train loss: 0.626636803150177 at step: 370
Iter time:  0.2740151160472148


Train loss: 0.7077667713165283 at step: 371
Iter time:  0.27401291135186456


Train loss: 0.7531346678733826 at step: 372
Iter time:  0.2740125361309257


Train loss: 0.7083349227905273 at step: 373
Iter time:  0.2740113255805049


Train loss: 0.7347797155380249 at step: 374
Iter time:  0.2740104593695166


Train loss: 0.6480280160903931 at step: 375
Iter time:  0.2740117467244466


Found 964 trainable_data in total.
