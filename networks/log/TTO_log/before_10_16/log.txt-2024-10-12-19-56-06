Model loaded..
Use LinearProbe head: pretrained_weights/10_12.pth
Choose layer: 23 for cls embedding
Not add Gaussian noise to the feature embedding.
Not use random erasing.
data mode: ours
[{'data_path': '/home/data/szk/face_B', 'data_mode': 'ours'}]
total_list_len: 6000
Fix the backbone.
Length of dataset: 375
Directory ./TTO_checkpoints/2024-10-12-19-57-15 is created.
Train loss: 0.4862689971923828 at step: 1
Iter time:  1.3598997592926025


Train loss: 0.5250130295753479 at step: 2
Iter time:  0.8211209774017334


Train loss: 0.46550774574279785 at step: 3
Iter time:  0.636056105295817


Train loss: 0.47173598408699036 at step: 4
Iter time:  0.5446118116378784


Train loss: 0.5622427463531494 at step: 5
Iter time:  0.4890096664428711


Train loss: 0.5545052886009216 at step: 6
Iter time:  0.4524238506952922


Train loss: 0.5285202264785767 at step: 7
Iter time:  0.4258910928453718


Train loss: 0.5668136477470398 at step: 8
Iter time:  0.40591704845428467


Train loss: 0.514075517654419 at step: 9
Iter time:  0.39059996604919434


Train loss: 0.6112927198410034 at step: 10
Iter time:  0.3786107301712036


Train loss: 0.4879046082496643 at step: 11
Iter time:  0.36859926310452545


Train loss: 0.5797227621078491 at step: 12
Iter time:  0.3604100743929545


Train loss: 0.5430458188056946 at step: 13
Iter time:  0.35341323339022124


Train loss: 0.5285340547561646 at step: 14
Iter time:  0.34741415296282085


Train loss: 0.5157024264335632 at step: 15
Iter time:  0.3422201156616211


Train loss: 0.6807394027709961 at step: 16
Iter time:  0.33759576082229614


Train loss: 0.29678481817245483 at step: 17
Iter time:  0.33355318798738365


Train loss: 0.4431937038898468 at step: 18
Iter time:  0.3299543460210164


Train loss: 0.5559017658233643 at step: 19
Iter time:  0.32682530503523977


Train loss: 0.5888744592666626 at step: 20
Iter time:  0.3239921689033508


Train loss: 0.475168913602829 at step: 21
Iter time:  0.32159881364731563


Train loss: 0.5860868096351624 at step: 22
Iter time:  0.31954391436143353


Train loss: 0.44022810459136963 at step: 23
Iter time:  0.3173490918200949


Train loss: 0.5383093357086182 at step: 24
Iter time:  0.3154916763305664


Train loss: 0.4577730894088745 at step: 25
Iter time:  0.31373072624206544


Train loss: 0.5976884365081787 at step: 26
Iter time:  0.31200865598825306


Train loss: 0.44410794973373413 at step: 27
Iter time:  0.3106328469735605


Train loss: 0.5264424681663513 at step: 28
Iter time:  0.30933958292007446


Train loss: 0.5080651044845581 at step: 29
Iter time:  0.3079276002686599


Train loss: 0.5398905277252197 at step: 30
Iter time:  0.30681623617808024


Train loss: 0.45245224237442017 at step: 31
Iter time:  0.30557578609835717


Train loss: 0.47765517234802246 at step: 32
Iter time:  0.3044653907418251


Train loss: 0.5205985903739929 at step: 33
Iter time:  0.3033925619992343


Train loss: 0.5738502740859985 at step: 34
Iter time:  0.3025156610152301


Train loss: 0.5874472856521606 at step: 35
Iter time:  0.3015153408050537


Train loss: 0.4776442348957062 at step: 36
Iter time:  0.30055809683269924


Train loss: 0.5130056738853455 at step: 37
Iter time:  0.29965665533735947


Train loss: 0.5203083157539368 at step: 38
Iter time:  0.29880955344752264


Train loss: 0.45561671257019043 at step: 39
Iter time:  0.2985844856653458


Train loss: 0.490637868642807 at step: 40
Iter time:  0.369667649269104


Train loss: 0.35323527455329895 at step: 41
Iter time:  0.4074039982586372


Train loss: 0.504284143447876 at step: 42
Iter time:  0.41525278772626606


Train loss: 0.5460096597671509 at step: 43
Iter time:  0.41378137677214866


Train loss: 0.4807438254356384 at step: 44
Iter time:  0.41190461137078027


Train loss: 0.4450696110725403 at step: 45
Iter time:  0.41044262250264485


Train loss: 0.567060112953186 at step: 46
Iter time:  0.40918027318042255


Train loss: 0.491127610206604 at step: 47
Iter time:  0.4075971562811669


Train loss: 0.3340792655944824 at step: 48
Iter time:  0.4048582464456558


Train loss: 0.5215721130371094 at step: 49
Iter time:  0.402786128374995


Train loss: 0.5163811445236206 at step: 50
Iter time:  0.4004949140548706


Train loss: 0.4071173667907715 at step: 51
Iter time:  0.3979897125094545


Train loss: 0.5008038282394409 at step: 52
Iter time:  0.3955493431824904


Train loss: 0.39786332845687866 at step: 53
Iter time:  0.39316057709028135


Train loss: 0.4276852607727051 at step: 54
Iter time:  0.3908341549060963


Train loss: 0.47114643454551697 at step: 55
Iter time:  0.3886422243985263


Train loss: 0.46619749069213867 at step: 56
Iter time:  0.38650429248809814


Train loss: 0.42888468503952026 at step: 57
Iter time:  0.3844343402929473


Train loss: 0.3408374786376953 at step: 58
Iter time:  0.3824321195997041


Train loss: 0.5232935547828674 at step: 59
Iter time:  0.38050435357174633


Train loss: 0.37056028842926025 at step: 60
Iter time:  0.37862470547358196


Train loss: 0.4610424041748047 at step: 61
Iter time:  0.37682511376552896


Train loss: 0.5776605606079102 at step: 62
Iter time:  0.3751122182415378


Train loss: 0.40277624130249023 at step: 63
Iter time:  0.37343611792912557


Train loss: 0.42269715666770935 at step: 64
Iter time:  0.3718018904328346


Train loss: 0.4216325581073761 at step: 65
Iter time:  0.3702283052297739


Train loss: 0.48227381706237793 at step: 66
Iter time:  0.3686981165047848


Train loss: 0.4281350076198578 at step: 67
Iter time:  0.36721467615953135


Train loss: 0.347494900226593 at step: 68
Iter time:  0.36576663746553306


Train loss: 0.4505350887775421 at step: 69
Iter time:  0.364435569099758


Train loss: 0.4826379120349884 at step: 70
Iter time:  0.363072555405753


Train loss: 0.360286682844162 at step: 71
Iter time:  0.36175380626194914


Train loss: 0.40524810552597046 at step: 72
Iter time:  0.3604723976718055


Train loss: 0.4400009512901306 at step: 73
Iter time:  0.35922766058412314


Train loss: 0.391480028629303 at step: 74
Iter time:  0.35801722552325277


Train loss: 0.2676490545272827 at step: 75
Iter time:  0.35684449195861817


Train loss: 0.43526405096054077 at step: 76
Iter time:  0.3557000003362957


Train loss: 0.401081919670105 at step: 77
Iter time:  0.3545826719952868


Train loss: 0.46066924929618835 at step: 78
Iter time:  0.3534979850817949


Train loss: 0.3548102080821991 at step: 79
Iter time:  0.35244023045407064


Train loss: 0.4885094165802002 at step: 80
Iter time:  0.3514052242040634


Train loss: 0.30064114928245544 at step: 81
Iter time:  0.3504132135414783


Train loss: 0.37760815024375916 at step: 82
Iter time:  0.34942915090700477


Train loss: 0.37655478715896606 at step: 83
Iter time:  0.34847123651619416


Train loss: 0.3330347239971161 at step: 84
Iter time:  0.34753689595631193


Train loss: 0.4164546728134155 at step: 85
Iter time:  0.3466298439923455


Train loss: 0.43484950065612793 at step: 86
Iter time:  0.34573274157768075


Train loss: 0.444296270608902 at step: 87
Iter time:  0.34486807077780535


Train loss: 0.3132484555244446 at step: 88
Iter time:  0.3440167118202556


Train loss: 0.41145074367523193 at step: 89
Iter time:  0.3431876937994796


Train loss: 0.35945212841033936 at step: 90
Iter time:  0.3423759407467312


Train loss: 0.4508180618286133 at step: 91
Iter time:  0.34157823730301073


Train loss: 0.32590949535369873 at step: 92
Iter time:  0.3408024414725926


Train loss: 0.3499085009098053 at step: 93
Iter time:  0.34004379856971


Train loss: 0.34235498309135437 at step: 94
Iter time:  0.33929605433281435


Train loss: 0.2486470639705658 at step: 95
Iter time:  0.33857555640371223


Train loss: 0.20362356305122375 at step: 96
Iter time:  0.3378561759988467


Train loss: 0.3582537770271301 at step: 97
Iter time:  0.3371506867949496


Train loss: 0.5016909837722778 at step: 98
Iter time:  0.33645811859442265


Train loss: 0.3286738395690918 at step: 99
Iter time:  0.33578246290033514


Train loss: 0.2509433627128601 at step: 100
Iter time:  0.3351392960548401


Train loss: 0.31710147857666016 at step: 101
Iter time:  0.33449727473872726


Train loss: 0.24669060111045837 at step: 102
Iter time:  0.3338589270909627


Train loss: 0.2815232276916504 at step: 103
Iter time:  0.3332442450291902


Train loss: 0.32637614011764526 at step: 104
Iter time:  0.33267601407491243


Train loss: 0.3117467761039734 at step: 105
Iter time:  0.33207756678263345


Train loss: 0.23120242357254028 at step: 106
Iter time:  0.33149279063602666


Train loss: 0.4047531187534332 at step: 107
Iter time:  0.33092717589619003


Train loss: 0.3365057706832886 at step: 108
Iter time:  0.3303818217030278


Train loss: 0.39187270402908325 at step: 109
Iter time:  0.3298822871041954


Train loss: 0.1959836184978485 at step: 110
Iter time:  0.3293509765104814


Train loss: 0.3130277395248413 at step: 111
Iter time:  0.3288302507486429


Train loss: 0.2325303852558136 at step: 112
Iter time:  0.32832130576883045


Train loss: 0.35155147314071655 at step: 113
Iter time:  0.32786059168587744


Train loss: 0.2769729197025299 at step: 114
Iter time:  0.32738746258250456


Train loss: 0.22670990228652954 at step: 115
Iter time:  0.32690378272015114


Train loss: 0.2914522886276245 at step: 116
Iter time:  0.32643332358064325


Train loss: 0.31234949827194214 at step: 117
Iter time:  0.32596582632798415


Train loss: 0.33687087893486023 at step: 118
Iter time:  0.3255121364431866


Train loss: 0.26090165972709656 at step: 119
Iter time:  0.3250829872964811


Train loss: 0.2358984798192978 at step: 120
Iter time:  0.3246369461218516


Train loss: 0.3301044702529907 at step: 121
Iter time:  0.3242103028888545


Train loss: 0.2345094531774521 at step: 122
Iter time:  0.32377928593119637


Train loss: 0.31146737933158875 at step: 123
Iter time:  0.3233516255045325


Train loss: 0.32242923974990845 at step: 124
Iter time:  0.322953543355388


Train loss: 0.2847932279109955 at step: 125
Iter time:  0.3225427417755127


Train loss: 0.2546277642250061 at step: 126
Iter time:  0.32213367545415483


Train loss: 0.3327119052410126 at step: 127
Iter time:  0.3217352919691191


Train loss: 0.31425511837005615 at step: 128
Iter time:  0.32134378887712955


Train loss: 0.22633200883865356 at step: 129
Iter time:  0.3209679921468099


Train loss: 0.2670646905899048 at step: 130
Iter time:  0.32058924711667575


Train loss: 0.25186362862586975 at step: 131
Iter time:  0.3202219573596052


Train loss: 0.33449316024780273 at step: 132
Iter time:  0.319853941599528


Train loss: 0.3659738302230835 at step: 133
Iter time:  0.31948481287275043


Train loss: 0.27113819122314453 at step: 134
Iter time:  0.3191292339296483


Train loss: 0.29151421785354614 at step: 135
Iter time:  0.31881516774495444


Train loss: 0.1721455156803131 at step: 136
Iter time:  0.31846217723453746


Train loss: 0.25416409969329834 at step: 137
Iter time:  0.3181583515919038


Train loss: 0.2086809277534485 at step: 138
Iter time:  0.3178212832713473


Train loss: 0.21592813730239868 at step: 139
Iter time:  0.3175539747416544


Train loss: 0.2096485197544098 at step: 140
Iter time:  0.31723938499178206


Train loss: 0.3162838816642761 at step: 141
Iter time:  0.3169473164470483


Train loss: 0.2589200735092163 at step: 142
Iter time:  0.31663667484068536


Train loss: 0.24921317398548126 at step: 143
Iter time:  0.31633086471290855


Train loss: 0.229082390666008 at step: 144
Iter time:  0.31604281067848206


Train loss: 0.14267894625663757 at step: 145
Iter time:  0.31573643848813815


Train loss: 0.19690991938114166 at step: 146
Iter time:  0.31543602192238585


Train loss: 0.16546787321567535 at step: 147
Iter time:  0.3151411280340078


Train loss: 0.13887718319892883 at step: 148
Iter time:  0.3148495635470828


Train loss: 0.28210896253585815 at step: 149
Iter time:  0.31456470329489483


Train loss: 0.19419193267822266 at step: 150
Iter time:  0.3142830101648966


Train loss: 0.2713613510131836 at step: 151
Iter time:  0.31400778435713406


Train loss: 0.20508433878421783 at step: 152
Iter time:  0.31372435939939397


Train loss: 0.1493227779865265 at step: 153
Iter time:  0.31345438489726946


Train loss: 0.25640133023262024 at step: 154
Iter time:  0.3131984085231632


Train loss: 0.1826450526714325 at step: 155
Iter time:  0.31293119768942557


Train loss: 0.1611505150794983 at step: 156
Iter time:  0.31266754407149094


Train loss: 0.13037140667438507 at step: 157
Iter time:  0.31241279346927714


Train loss: 0.2322813868522644 at step: 158
Iter time:  0.31216373775578754


Train loss: 0.18512852489948273 at step: 159
Iter time:  0.31193694528543725


Train loss: 0.1305914968252182 at step: 160
Iter time:  0.3116867780685425


Train loss: 0.2567182779312134 at step: 161
Iter time:  0.3114411593964381


Train loss: 0.18715022504329681 at step: 162
Iter time:  0.3112048190317036


Train loss: 0.21203766763210297 at step: 163
Iter time:  0.3109722035062825


Train loss: 0.11700990796089172 at step: 164
Iter time:  0.31075642167068107


Train loss: 0.23794057965278625 at step: 165
Iter time:  0.3105312405210553


Train loss: 0.16876038908958435 at step: 166
Iter time:  0.3103042338267866


Train loss: 0.21637898683547974 at step: 167
Iter time:  0.31008016420695594


Train loss: 0.24043820798397064 at step: 168
Iter time:  0.3098694738887605


Train loss: 0.290427565574646 at step: 169
Iter time:  0.3096711649697208


Train loss: 0.14849916100502014 at step: 170
Iter time:  0.3094694558311911


Train loss: 0.20500320196151733 at step: 171
Iter time:  0.30926102643821674


Train loss: 0.1362297534942627 at step: 172
Iter time:  0.30905224417531213


Train loss: 0.14763863384723663 at step: 173
Iter time:  0.30888792545120153


Train loss: 0.08822576701641083 at step: 174
Iter time:  0.30869998054942865


Train loss: 0.2435275912284851 at step: 175
Iter time:  0.3085060977935791


Train loss: 0.19780126214027405 at step: 176
Iter time:  0.3083027655428106


Train loss: 0.22525805234909058 at step: 177
Iter time:  0.3081116716740495


Train loss: 0.1939382553100586 at step: 178
Iter time:  0.3079222668422742


Train loss: 0.10857617855072021 at step: 179
Iter time:  0.3077676322873078


Train loss: 0.0887739509344101 at step: 180
Iter time:  0.30757575697369044


Train loss: 0.15101268887519836 at step: 181
Iter time:  0.3073912549414029


Train loss: 0.17514356970787048 at step: 182
Iter time:  0.3072070145344996


Train loss: 0.12089364230632782 at step: 183
Iter time:  0.3070552583600654


Train loss: 0.15437187254428864 at step: 184
Iter time:  0.30687866521918256


Train loss: 0.12846088409423828 at step: 185
Iter time:  0.3067026847117656


Train loss: 0.12268546968698502 at step: 186
Iter time:  0.3065388664122551


Train loss: 0.19014395773410797 at step: 187
Iter time:  0.3063644942115335


Train loss: 0.1558322012424469 at step: 188
Iter time:  0.3061938552146262


Train loss: 0.08503580838441849 at step: 189
Iter time:  0.3060380100573181


Train loss: 0.22638200223445892 at step: 190
Iter time:  0.3058705493023521


Train loss: 0.17539580166339874 at step: 191
Iter time:  0.3057075607839055


Train loss: 0.058698803186416626 at step: 192
Iter time:  0.3055420418580373


Train loss: 0.1612357199192047 at step: 193
Iter time:  0.30537857292847315


Train loss: 0.1115415096282959 at step: 194
Iter time:  0.3052318145319359


Train loss: 0.2031799554824829 at step: 195
Iter time:  0.30507870454054614


Train loss: 0.16790646314620972 at step: 196
Iter time:  0.3049118591814625


Train loss: 0.14281731843948364 at step: 197
Iter time:  0.30475667043385773


Train loss: 0.10749934613704681 at step: 198
Iter time:  0.30459846270204793


Train loss: 0.18010510504245758 at step: 199
Iter time:  0.3044529224759969


Train loss: 0.0907946527004242 at step: 200
Iter time:  0.30429773330688475


Train loss: 0.10309731215238571 at step: 201
Iter time:  0.30414397562321144


Train loss: 0.11627068370580673 at step: 202
Iter time:  0.3039884047933144


Train loss: 0.16107428073883057 at step: 203
Iter time:  0.3038423906993396


Train loss: 0.08508063852787018 at step: 204
Iter time:  0.3036984964913013


Train loss: 0.12864425778388977 at step: 205
Iter time:  0.303569973968878


Train loss: 0.10931065678596497 at step: 206
Iter time:  0.30342047770046493


Train loss: 0.14093729853630066 at step: 207
Iter time:  0.3032724707598847


Train loss: 0.13159099221229553 at step: 208
Iter time:  0.3031317706291492


Train loss: 0.1172751933336258 at step: 209
Iter time:  0.30298770785902107


Train loss: 0.14816755056381226 at step: 210
Iter time:  0.3028452759697324


Train loss: 0.1304021179676056 at step: 211
Iter time:  0.3027075342657442


Train loss: 0.051522593945264816 at step: 212
Iter time:  0.3025685818690174


Train loss: 0.09975641965866089 at step: 213
Iter time:  0.3024438793110735


Train loss: 0.11899589002132416 at step: 214
Iter time:  0.30231067398998224


Train loss: 0.14365023374557495 at step: 215
Iter time:  0.30217418005300123


Train loss: 0.14647379517555237 at step: 216
Iter time:  0.302041118895566


Train loss: 0.15286600589752197 at step: 217
Iter time:  0.3019102487695931


Train loss: 0.09465824067592621 at step: 218
Iter time:  0.30178087566970685


Train loss: 0.09771168977022171 at step: 219
Iter time:  0.3152170943342932


Train loss: 0.11016224324703217 at step: 220
Iter time:  0.3168155735189265


Train loss: 0.14966847002506256 at step: 221
Iter time:  0.31891723348004786


Train loss: 0.11550722271203995 at step: 222
Iter time:  0.32219713443034403


Train loss: 0.07858245074748993 at step: 223
Iter time:  0.32475711305045224


Train loss: 0.08555444329977036 at step: 224
Iter time:  0.3294139547007425


Train loss: 0.07945556938648224 at step: 225
Iter time:  0.3499674383799235


Train loss: 0.06405752897262573 at step: 226
Iter time:  0.35696100977669776


Train loss: 0.1260804533958435 at step: 227
Iter time:  0.35672631977938346


Train loss: 0.17562276124954224 at step: 228
Iter time:  0.35637154077228744


Train loss: 0.16782501339912415 at step: 229
Iter time:  0.3560234865246902


Train loss: 0.07815036922693253 at step: 230
Iter time:  0.35565995548082435


Train loss: 0.06868412345647812 at step: 231
Iter time:  0.3553198756593646


Train loss: 0.14121215045452118 at step: 232
Iter time:  0.3549655470354804


Train loss: 0.06101144850254059 at step: 233
Iter time:  0.3546216119512468


Train loss: 0.10197912156581879 at step: 234
Iter time:  0.3542757472421369


Train loss: 0.09759512543678284 at step: 235
Iter time:  0.35393063159699134


Train loss: 0.1341153085231781 at step: 236
Iter time:  0.35358862957711945


Train loss: 0.2274307906627655 at step: 237
Iter time:  0.3532473638590881


Train loss: 0.07384662330150604 at step: 238
Iter time:  0.35290967616714347


Train loss: 0.0915200486779213 at step: 239
Iter time:  0.35257752570148293


Train loss: 0.06273576617240906 at step: 240
Iter time:  0.35224413176377617


Train loss: 0.04937036707997322 at step: 241
Iter time:  0.35191582940920757


Train loss: 0.16154557466506958 at step: 242
Iter time:  0.35158127989650756


Train loss: 0.09266607463359833 at step: 243
Iter time:  0.3512545878013956


Train loss: 0.10208731144666672 at step: 244
Iter time:  0.35093287268622975


Train loss: 0.10290447622537613 at step: 245
Iter time:  0.3506192217067796


Train loss: 0.07312086969614029 at step: 246
Iter time:  0.3503124481294213


Train loss: 0.06938536465167999 at step: 247
Iter time:  0.3499973495962166


Train loss: 0.12421533465385437 at step: 248
Iter time:  0.3496842038246893


Train loss: 0.14761009812355042 at step: 249
Iter time:  0.3493740012846797


Train loss: 0.06578342616558075 at step: 250
Iter time:  0.34906336879730226


Train loss: 0.11301296949386597 at step: 251
Iter time:  0.348760103324495


Train loss: 0.12512321770191193 at step: 252
Iter time:  0.3484553505503942


Train loss: 0.0929533839225769 at step: 253
Iter time:  0.34815064532012335


Train loss: 0.11138199269771576 at step: 254
Iter time:  0.3478488903346024


Train loss: 0.07546204328536987 at step: 255
Iter time:  0.347554095586141


Train loss: 0.0910567194223404 at step: 256
Iter time:  0.34725731518119574


Train loss: 0.12314474582672119 at step: 257
Iter time:  0.34697845102748054


Train loss: 0.10764182358980179 at step: 258
Iter time:  0.34668575608453084


Train loss: 0.07381946593523026 at step: 259
Iter time:  0.34639736400147664


Train loss: 0.05273615941405296 at step: 260
Iter time:  0.34613768962713387


Train loss: 0.10410887002944946 at step: 261
Iter time:  0.34585703104391863


Train loss: 0.08980926871299744 at step: 262
Iter time:  0.34557307676504584


Train loss: 0.07372071593999863 at step: 263
Iter time:  0.3452929380728718


Train loss: 0.047527115792036057 at step: 264
Iter time:  0.34501580939148413


Train loss: 0.05517696216702461 at step: 265
Iter time:  0.34473884420574835


Train loss: 0.09276218712329865 at step: 266
Iter time:  0.34446570568514945


Train loss: 0.06151124835014343 at step: 267
Iter time:  0.34419546145178403


Train loss: 0.11900988966226578 at step: 268
Iter time:  0.34393039034373724


Train loss: 0.0713011771440506 at step: 269
Iter time:  0.3436653817896506


Train loss: 0.08585184067487717 at step: 270
Iter time:  0.3433985162664343


Train loss: 0.09475483000278473 at step: 271
Iter time:  0.3431383287774681


Train loss: 0.06406539678573608 at step: 272
Iter time:  0.3428778122453129


Train loss: 0.08400614559650421 at step: 273
Iter time:  0.34261973174937044


Train loss: 0.04585415869951248 at step: 274
Iter time:  0.3423620218778179


Train loss: 0.032205283641815186 at step: 275
Iter time:  0.34210947123440827


Train loss: 0.038153599947690964 at step: 276
Iter time:  0.3418625930081243


Train loss: 0.031946875154972076 at step: 277
Iter time:  0.34161037916741216


Train loss: 0.03914020210504532 at step: 278
Iter time:  0.34135827657987744


Train loss: 0.06583884358406067 at step: 279
Iter time:  0.34111324176993424


Train loss: 0.0323646180331707 at step: 280
Iter time:  0.34086783868925913


Train loss: 0.04978568106889725 at step: 281
Iter time:  0.3406234559639493


Train loss: 0.042145758867263794 at step: 282
Iter time:  0.34038026535764654


Train loss: 0.10261939465999603 at step: 283
Iter time:  0.3401379079785027


Train loss: 0.06472833454608917 at step: 284
Iter time:  0.3399007034973359


Train loss: 0.0948057472705841 at step: 285
Iter time:  0.3396833252488521


Train loss: 0.13451135158538818 at step: 286
Iter time:  0.3394463804218319


Train loss: 0.05042911320924759 at step: 287
Iter time:  0.33922197843677904


Train loss: 0.06201603263616562 at step: 288
Iter time:  0.3389938250184059


Train loss: 0.07738317549228668 at step: 289
Iter time:  0.3387687552758979


Train loss: 0.10789251327514648 at step: 290
Iter time:  0.3385429489201513


Train loss: 0.04958463832736015 at step: 291
Iter time:  0.3383170681720747


Train loss: 0.06533923745155334 at step: 292
Iter time:  0.3380934734867044


Train loss: 0.09434214234352112 at step: 293
Iter time:  0.33787053518327836


Train loss: 0.10682216286659241 at step: 294
Iter time:  0.33764920348212835


Train loss: 0.0808447003364563 at step: 295
Iter time:  0.33743249198137704


Train loss: 0.04169684275984764 at step: 296
Iter time:  0.3372173607349396


Train loss: 0.02082052454352379 at step: 297
Iter time:  0.33700042621856585


Train loss: 0.03453466296195984 at step: 298
Iter time:  0.3367837595459599


Train loss: 0.05561207979917526 at step: 299
Iter time:  0.33658575612964436


Train loss: 0.06471298635005951 at step: 300
Iter time:  0.336374462445577


Train loss: 0.04702179878950119 at step: 301
Iter time:  0.3361641616124251


Train loss: 0.033913753926754 at step: 302
Iter time:  0.3359535458861597


Train loss: 0.024504533037543297 at step: 303
Iter time:  0.33574304564951274


Train loss: 0.06972706317901611 at step: 304
Iter time:  0.33553451848657506


Train loss: 0.012461874634027481 at step: 305
Iter time:  0.33533326211522835


Train loss: 0.09998057782649994 at step: 306
Iter time:  0.3351285138161354


Train loss: 0.11893445253372192 at step: 307
Iter time:  0.3349234125901511


Train loss: 0.04102649539709091 at step: 308
Iter time:  0.33472038244272206


Train loss: 0.0357508659362793 at step: 309
Iter time:  0.33451790639883494


Train loss: 0.05819462984800339 at step: 310
Iter time:  0.33431659590813423


Train loss: 0.039390936493873596 at step: 311
Iter time:  0.3341186843884336


Train loss: 0.0787915289402008 at step: 312
Iter time:  0.3339209258556366


Train loss: 0.07208886742591858 at step: 313
Iter time:  0.3337255773452905


Train loss: 0.030872654169797897 at step: 314
Iter time:  0.33353207445448374


Train loss: 0.05678574740886688 at step: 315
Iter time:  0.33334477591136147


Train loss: 0.04337778687477112 at step: 316
Iter time:  0.33315362507783913


Train loss: 0.05946815758943558 at step: 317
Iter time:  0.3329625257558251


Train loss: 0.06690166890621185 at step: 318
Iter time:  0.33277116181715477


Train loss: 0.02301638200879097 at step: 319
Iter time:  0.3325858616903658


Train loss: 0.05463830381631851 at step: 320
Iter time:  0.33239889815449714


Train loss: 0.05811551958322525 at step: 321
Iter time:  0.3322128254305165


Train loss: 0.1186913400888443 at step: 322
Iter time:  0.33202887173765194


Train loss: 0.050006888806819916 at step: 323
Iter time:  0.3318483504717564


Train loss: 0.053449228405952454 at step: 324
Iter time:  0.3316684306403737


Train loss: 0.08537402749061584 at step: 325
Iter time:  0.33148764610290526


Train loss: 0.04409553110599518 at step: 326
Iter time:  0.33130784341894043


Train loss: 0.04920700937509537 at step: 327
Iter time:  0.33113272474446426


Train loss: 0.03875629976391792 at step: 328
Iter time:  0.3309543837861317


Train loss: 0.07601989805698395 at step: 329
Iter time:  0.330778016870145


Train loss: 0.03938651829957962 at step: 330
Iter time:  0.33060611667055073


Train loss: 0.06411826610565186 at step: 331
Iter time:  0.33043253313738774


Train loss: 0.05178717523813248 at step: 332
Iter time:  0.33025815185294094


Train loss: 0.05403975397348404 at step: 333
Iter time:  0.3300855059523482


Train loss: 0.04380541294813156 at step: 334
Iter time:  0.3299160510480047


Train loss: 0.05878324806690216 at step: 335
Iter time:  0.329746854127343


Train loss: 0.06319146603345871 at step: 336
Iter time:  0.32958054542541504


Train loss: 0.06281822919845581 at step: 337
Iter time:  0.3294128819813714


Train loss: 0.03377028554677963 at step: 338
Iter time:  0.32924570557633803


Train loss: 0.03745928034186363 at step: 339
Iter time:  0.32908107608468834


Train loss: 0.040358562022447586 at step: 340
Iter time:  0.32891709804534913


Train loss: 0.03816572576761246 at step: 341
Iter time:  0.3287529148314356


Train loss: 0.018954401835799217 at step: 342
Iter time:  0.32858935434218733


Train loss: 0.03229150176048279 at step: 343
Iter time:  0.328428898191313


Train loss: 0.03685808926820755 at step: 344
Iter time:  0.32827033968858943


Train loss: 0.0528041273355484 at step: 345
Iter time:  0.3281083328136499


Train loss: 0.05536944419145584 at step: 346
Iter time:  0.3279516938104795


Train loss: 0.035154711455106735 at step: 347
Iter time:  0.3277935267181836


Train loss: 0.05823199450969696 at step: 348
Iter time:  0.3276387795634653


Train loss: 0.02748008258640766 at step: 349
Iter time:  0.3274832536976112


Train loss: 0.020578403025865555 at step: 350
Iter time:  0.3273319496427263


Train loss: 0.025529734790325165 at step: 351
Iter time:  0.3271803285321619


Train loss: 0.03331228345632553 at step: 352
Iter time:  0.3270289505069906


Train loss: 0.035850271582603455 at step: 353
Iter time:  0.3268773690836963


Train loss: 0.036383435130119324 at step: 354
Iter time:  0.32672753105055813


Train loss: 0.060968250036239624 at step: 355
Iter time:  0.32657756805419924


Train loss: 0.03553265333175659 at step: 356
Iter time:  0.3264287462395229


Train loss: 0.02817436121404171 at step: 357
Iter time:  0.32627929826410546


Train loss: 0.029914099723100662 at step: 358
Iter time:  0.326132737058501


Train loss: 0.02733030542731285 at step: 359
Iter time:  0.32598592311891006


Train loss: 0.06356404721736908 at step: 360
Iter time:  0.3258413222101


Train loss: 0.022933343425393105 at step: 361
Iter time:  0.32570106765239853


Train loss: 0.041184186935424805 at step: 362
Iter time:  0.3255559041355196


Train loss: 0.03875744715332985 at step: 363
Iter time:  0.3254112297509984


Train loss: 0.03145008534193039 at step: 364
Iter time:  0.325268926856282


Train loss: 0.1109369546175003 at step: 365
Iter time:  0.32512965594252496


Train loss: 0.030089551582932472 at step: 366
Iter time:  0.32498916381043813


Train loss: 0.033183418214321136 at step: 367
Iter time:  0.32485080285033346


Train loss: 0.04602530971169472 at step: 368
Iter time:  0.32471285371676734


Train loss: 0.04268566891551018 at step: 369
Iter time:  0.32457292435291984


Train loss: 0.08345380425453186 at step: 370
Iter time:  0.3244359390155689


Train loss: 0.028707731515169144 at step: 371
Iter time:  0.324299201811099


Train loss: 0.03603330999612808 at step: 372
Iter time:  0.32416244860618343


Train loss: 0.02793268859386444 at step: 373
Iter time:  0.32402610459212644


Train loss: 0.040223781019449234 at step: 374
Iter time:  0.32389163970947266


Train loss: 0.07914428412914276 at step: 375
Iter time:  0.32375893465677896


Found 5259 trainable_data in total.
