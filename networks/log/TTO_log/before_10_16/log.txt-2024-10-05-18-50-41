Model loaded..
Use LinearProbe head: pretrained_weights/10_1_TTO_epoch2.pth
Choose layer: 23 for cls embedding
Not add Gaussian noise to the feature embedding.
Not use random erasing.
data mode: ours
[{'data_path': '/home/data/szk/face/face', 'data_mode': 'ours'}]
total_list_len: 6000
Fix the backbone.
Length of dataset: 375
Directory ./TTO_checkpoints/2024-10-05-18-51-03 is created.
Train loss: 0.022380756214261055 at step: 1
Iter time:  1.2631144523620605


Train loss: 0.0719594806432724 at step: 2
Iter time:  0.7668654918670654


Train loss: 0.006500381510704756 at step: 3
Iter time:  0.6005125840504965


Train loss: 0.062124378979206085 at step: 4
Iter time:  0.5167379975318909


Train loss: 0.01145212259143591 at step: 5
Iter time:  0.46673245429992677


Train loss: 0.04035068303346634 at step: 6
Iter time:  0.4333378076553345


Train loss: 0.08023394644260406 at step: 7
Iter time:  0.4096510750906808


Train loss: 0.0702231153845787 at step: 8
Iter time:  0.391612708568573


Train loss: 0.09861543029546738 at step: 9
Iter time:  0.37769436836242676


Train loss: 0.03191215544939041 at step: 10
Iter time:  0.3666110038757324


Train loss: 0.03288232907652855 at step: 11
Iter time:  0.35750029303810815


Train loss: 0.025670545175671577 at step: 12
Iter time:  0.34994492928187054


Train loss: 0.007044694386422634 at step: 13
Iter time:  0.3435377891247089


Train loss: 0.04358644783496857 at step: 14
Iter time:  0.3380491052355085


Train loss: 0.08338700234889984 at step: 15
Iter time:  0.33339967727661135


Train loss: 0.032522015273571014 at step: 16
Iter time:  0.32923004031181335


Train loss: 0.021572191268205643 at step: 17
Iter time:  0.3255673156065099


Train loss: 0.010695395991206169 at step: 18
Iter time:  0.3222959836324056


Train loss: 0.014960783533751965 at step: 19
Iter time:  0.31938291850842926


Train loss: 0.13368813693523407 at step: 20
Iter time:  0.3167687177658081


Train loss: 0.07935543358325958 at step: 21
Iter time:  0.31442290260678246


Train loss: 0.03033078834414482 at step: 22
Iter time:  0.312325737693093


Train loss: 0.08225463330745697 at step: 23
Iter time:  0.31039098034734314


Train loss: 0.02598748728632927 at step: 24
Iter time:  0.3086184561252594


Train loss: 0.06874693930149078 at step: 25
Iter time:  0.3069968414306641


Train loss: 0.019136590883135796 at step: 26
Iter time:  0.3054998471186711


Train loss: 0.08812236040830612 at step: 27
Iter time:  0.3041114542219374


Train loss: 0.036422427743673325 at step: 28
Iter time:  0.3028210401535034


Train loss: 0.039079029113054276 at step: 29
Iter time:  0.301638989612974


Train loss: 0.025312870740890503 at step: 30
Iter time:  0.30052049160003663


Train loss: 0.07797115296125412 at step: 31
Iter time:  0.2994692171773603


Train loss: 0.0632001981139183 at step: 32
Iter time:  0.2985026240348816


Train loss: 0.02190764807164669 at step: 33
Iter time:  0.29758675893147785


Train loss: 0.007795602083206177 at step: 34
Iter time:  0.29671349244959216


Train loss: 0.08775602281093597 at step: 35
Iter time:  0.29591174806867326


Train loss: 0.061267830431461334 at step: 36
Iter time:  0.2951691018210517


Train loss: 0.02857927978038788 at step: 37
Iter time:  0.2944594718314506


Train loss: 0.024882014840841293 at step: 38
Iter time:  0.29378403487958404


Train loss: 0.10382112860679626 at step: 39
Iter time:  0.2931510668534499


Train loss: 0.03307531774044037 at step: 40
Iter time:  0.29254236817359924


Train loss: 0.08327013999223709 at step: 41
Iter time:  0.2919726778821247


Train loss: 0.00897618755698204 at step: 42
Iter time:  0.29142031215486075


Train loss: 0.11310718208551407 at step: 43
Iter time:  0.29090336866157


Train loss: 0.05116063356399536 at step: 44
Iter time:  0.29039782827550714


Train loss: 0.010896196588873863 at step: 45
Iter time:  0.28994222217135956


Train loss: 0.020715773105621338 at step: 46
Iter time:  0.2894959086957185


Train loss: 0.01693863421678543 at step: 47
Iter time:  0.289026899540678


Train loss: 0.14012432098388672 at step: 48
Iter time:  0.2885870734850566


Train loss: 0.014000676572322845 at step: 49
Iter time:  0.28816149186114876


Train loss: 0.06888476014137268 at step: 50
Iter time:  0.28775410175323485


Train loss: 0.04278922080993652 at step: 51
Iter time:  0.28737763330048205


Train loss: 0.10614565014839172 at step: 52
Iter time:  0.28700321454268235


Train loss: 0.03637784719467163 at step: 53
Iter time:  0.28664830045880013


Train loss: 0.03879353404045105 at step: 54
Iter time:  0.28630558649698895


Train loss: 0.08238992840051651 at step: 55
Iter time:  0.2859697862104936


Train loss: 0.010251392610371113 at step: 56
Iter time:  0.2856475370270865


Train loss: 0.07468289881944656 at step: 57
Iter time:  0.285336410790159


Train loss: 0.05404701456427574 at step: 58
Iter time:  0.28503341510378083


Train loss: 0.08175382018089294 at step: 59
Iter time:  0.2847495240680242


Train loss: 0.03439965099096298 at step: 60
Iter time:  0.2844726045926412


Train loss: 0.09304071217775345 at step: 61
Iter time:  0.284199167470463


Train loss: 0.054485779255628586 at step: 62
Iter time:  0.283937354241648


Train loss: 0.048597998917102814 at step: 63
Iter time:  0.2836814797113812


Train loss: 0.08599773794412613 at step: 64
Iter time:  0.28343284502625465


Train loss: 0.03198041766881943 at step: 65
Iter time:  0.28320354314950796


Train loss: 0.022004924714565277 at step: 66
Iter time:  0.28296727122682513


Train loss: 0.10119746625423431 at step: 67
Iter time:  0.28274011256089854


Train loss: 0.08567185699939728 at step: 68
Iter time:  0.28252265733831067


Train loss: 0.0684128850698471 at step: 69
Iter time:  0.2823098569676496


Train loss: 0.020533191040158272 at step: 70
Iter time:  0.28210302080426897


Train loss: 0.033884335309267044 at step: 71
Iter time:  0.2819026221691723


Train loss: 0.017672982066869736 at step: 72
Iter time:  0.28170621063974166


Train loss: 0.0981399267911911 at step: 73
Iter time:  0.28152216950508013


Train loss: 0.03422529622912407 at step: 74
Iter time:  0.2813415881749746


Train loss: 0.033765193074941635 at step: 75
Iter time:  0.281164395014445


Train loss: 0.028828561305999756 at step: 76
Iter time:  0.2809935494473106


Train loss: 0.06025105342268944 at step: 77
Iter time:  0.28082429278980603


Train loss: 0.08432337641716003 at step: 78
Iter time:  0.2806711747096135


Train loss: 0.052016936242580414 at step: 79
Iter time:  0.28052661086939557


Train loss: 0.06738729029893875 at step: 80
Iter time:  0.2803809821605682


Train loss: 0.050489142537117004 at step: 81
Iter time:  0.28024451232250824


Train loss: 0.024326438084244728 at step: 82
Iter time:  0.28010907987268957


Train loss: 0.054788410663604736 at step: 83
Iter time:  0.2799712146621153


Train loss: 0.055432870984077454 at step: 84
Iter time:  0.2798418856802441


Train loss: 0.04111867770552635 at step: 85
Iter time:  0.2797166319454418


Train loss: 0.03610558435320854 at step: 86
Iter time:  0.27959480950998705


Train loss: 0.01118883490562439 at step: 87
Iter time:  0.27947622058035315


Train loss: 0.09552700817584991 at step: 88
Iter time:  0.2793560949238864


Train loss: 0.10300697386264801 at step: 89
Iter time:  0.2792432656448879


Train loss: 0.05924012139439583 at step: 90
Iter time:  0.27913037406073676


Train loss: 0.009110515005886555 at step: 91
Iter time:  0.2790216718401228


Train loss: 0.035462889820337296 at step: 92
Iter time:  0.27891212960948114


Train loss: 0.03694109246134758 at step: 93
Iter time:  0.2788093500239875


Train loss: 0.03174494951963425 at step: 94
Iter time:  0.2787038823391529


Train loss: 0.09890598058700562 at step: 95
Iter time:  0.27860402558979236


Train loss: 0.039465561509132385 at step: 96
Iter time:  0.2785058220227559


Train loss: 0.07090924680233002 at step: 97
Iter time:  0.27841118438956663


Train loss: 0.048476073890924454 at step: 98
Iter time:  0.27833510904896014


Train loss: 0.017087411135435104 at step: 99
Iter time:  0.2782454683323099


Train loss: 0.011773316189646721 at step: 100
Iter time:  0.27815855264663697


Train loss: 0.03304118663072586 at step: 101
Iter time:  0.278073249476971


Train loss: 0.07518386840820312 at step: 102
Iter time:  0.27798359768063413


Train loss: 0.10847733914852142 at step: 103
Iter time:  0.2779048530800829


Train loss: 0.0047043426893651485 at step: 104
Iter time:  0.27782289339945865


Train loss: 0.04169973358511925 at step: 105
Iter time:  0.2777419362749372


Train loss: 0.04989037662744522 at step: 106
Iter time:  0.277666928633204


Train loss: 0.011841129511594772 at step: 107
Iter time:  0.2775924562293792


Train loss: 0.0771179348230362 at step: 108
Iter time:  0.2775202305228622


Train loss: 0.01766795851290226 at step: 109
Iter time:  0.27745090274635803


Train loss: 0.050128813832998276 at step: 110
Iter time:  0.2773800741542469


Train loss: 0.05523628368973732 at step: 111
Iter time:  0.2773147552937001


Train loss: 0.09906260669231415 at step: 112
Iter time:  0.27724816117967876


Train loss: 0.06841815263032913 at step: 113
Iter time:  0.277185366217014


Train loss: 0.016731219366192818 at step: 114
Iter time:  0.27712685392613995


Train loss: 0.012797719798982143 at step: 115
Iter time:  0.27706817751345425


Train loss: 0.05932263657450676 at step: 116
Iter time:  0.27700915829888706


Train loss: 0.035107217729091644 at step: 117
Iter time:  0.27695139860495543


Train loss: 0.07700297981500626 at step: 118
Iter time:  0.27689411074428233


Train loss: 0.015168995596468449 at step: 119
Iter time:  0.2768382745630601


Train loss: 0.005299350246787071 at step: 120
Iter time:  0.27678124109903973


Train loss: 0.03778841719031334 at step: 121
Iter time:  0.2767253867850816


Train loss: 0.06815631687641144 at step: 122
Iter time:  0.276671796548562


Train loss: 0.0454157218337059 at step: 123
Iter time:  0.2766198763033239


Train loss: 0.06328136473894119 at step: 124
Iter time:  0.2765686185129227


Train loss: 0.08496075123548508 at step: 125
Iter time:  0.27651606369018555


Train loss: 0.01479943748563528 at step: 126
Iter time:  0.2764671227288625


Train loss: 0.07758770883083344 at step: 127
Iter time:  0.27641984984630674


Train loss: 0.021705832332372665 at step: 128
Iter time:  0.2763701118528843


Train loss: 0.02488015592098236 at step: 129
Iter time:  0.27632554002510484


Train loss: 0.012802413664758205 at step: 130
Iter time:  0.27627939994518574


Train loss: 0.026060927659273148 at step: 131
Iter time:  0.2762351800467222


Train loss: 0.060690633952617645 at step: 132
Iter time:  0.27618945186788385


Train loss: 0.06473009288311005 at step: 133
Iter time:  0.2761464692596206


Train loss: 0.07711395621299744 at step: 134
Iter time:  0.27610434169199927


Train loss: 0.05791410803794861 at step: 135
Iter time:  0.27606243557400173


Train loss: 0.022046305239200592 at step: 136
Iter time:  0.27602115624091206


Train loss: 0.06792961061000824 at step: 137
Iter time:  0.27598076493200596


Train loss: 0.0041902875527739525 at step: 138
Iter time:  0.2759433328241542


Train loss: 0.07169781625270844 at step: 139
Iter time:  0.27590902932256245


Train loss: 0.0492471307516098 at step: 140
Iter time:  0.27587393181664605


Train loss: 0.09512824565172195 at step: 141
Iter time:  0.27583983434852977


Train loss: 0.05584843456745148 at step: 142
Iter time:  0.2758077013660485


Train loss: 0.11205348372459412 at step: 143
Iter time:  0.27577570101597926


Train loss: 0.12264642119407654 at step: 144
Iter time:  0.27574513687027824


Train loss: 0.028866734355688095 at step: 145
Iter time:  0.2757133483886719


Train loss: 0.12293115258216858 at step: 146
Iter time:  0.2756837018548626


Train loss: 0.07472038269042969 at step: 147
Iter time:  0.27565471169088973


Train loss: 0.016249654814600945 at step: 148
Iter time:  0.2756217218734123


Train loss: 0.029506683349609375 at step: 149
Iter time:  0.275590919008191


Train loss: 0.12947583198547363 at step: 150
Iter time:  0.2755648946762085


Train loss: 0.10986803472042084 at step: 151
Iter time:  0.2755367819047132


Train loss: 0.05508683621883392 at step: 152
Iter time:  0.27550908138877467


Train loss: 0.09552232176065445 at step: 153
Iter time:  0.275483486699123


Train loss: 0.02574685961008072 at step: 154
Iter time:  0.2754583002684952


Train loss: 0.07034160196781158 at step: 155
Iter time:  0.2754320190798852


Train loss: 0.0904025286436081 at step: 156
Iter time:  0.2754075878705734


Train loss: 0.006712047383189201 at step: 157
Iter time:  0.2753839416868368


Train loss: 0.06930668652057648 at step: 158
Iter time:  0.2753605118280725


Train loss: 0.05885661393404007 at step: 159
Iter time:  0.2753371352669578


Train loss: 0.1238662600517273 at step: 160
Iter time:  0.27531383782625196


Train loss: 0.022224480286240578 at step: 161
Iter time:  0.2752929918514275


Train loss: 0.0533057302236557 at step: 162
Iter time:  0.2752700249354045


Train loss: 0.033357199281454086 at step: 163
Iter time:  0.2752505475026698


Train loss: 0.12374226748943329 at step: 164
Iter time:  0.2752318774781576


Train loss: 0.02527213655412197 at step: 165
Iter time:  0.2752121246222294


Train loss: 0.061574507504701614 at step: 166
Iter time:  0.27519068086003684


Train loss: 0.010328664444386959 at step: 167
Iter time:  0.27516921266110356


Train loss: 0.04707935452461243 at step: 168
Iter time:  0.27515011600085665


Train loss: 0.09295861423015594 at step: 169
Iter time:  0.2751308898248616


Train loss: 0.005563653539866209 at step: 170
Iter time:  0.2751126064973719


Train loss: 0.014633570797741413 at step: 171
Iter time:  0.27509172478614496


Train loss: 0.10547946393489838 at step: 172
Iter time:  0.27507235144459924


Train loss: 0.07898233830928802 at step: 173
Iter time:  0.27505388011822124


Train loss: 0.057329799979925156 at step: 174
Iter time:  0.2750336575782162


Train loss: 0.039734553545713425 at step: 175
Iter time:  0.2750153405325753


Train loss: 0.06688549369573593 at step: 176
Iter time:  0.27499650012363086


Train loss: 0.03632460534572601 at step: 177
Iter time:  0.27499021244587873


Train loss: 0.05733461678028107 at step: 178
Iter time:  0.27497372600469694


Train loss: 0.014694851823151112 at step: 179
Iter time:  0.274955696233824


Train loss: 0.03346555307507515 at step: 180
Iter time:  0.2749392416742113


Train loss: 0.04854732006788254 at step: 181
Iter time:  0.2749215924278807


Train loss: 0.06054963544011116 at step: 182
Iter time:  0.27490336423391826


Train loss: 0.07718770951032639 at step: 183
Iter time:  0.27488879167317043


Train loss: 0.04210086166858673 at step: 184
Iter time:  0.2748730739821558


Train loss: 0.013067583553493023 at step: 185
Iter time:  0.27485716665113297


Train loss: 0.06858786940574646 at step: 186
Iter time:  0.27484134063925797


Train loss: 0.0591520294547081 at step: 187
Iter time:  0.2748256303409842


Train loss: 0.01343761757016182 at step: 188
Iter time:  0.2748102216010398


Train loss: 0.04755552113056183 at step: 189
Iter time:  0.274795168922061


Train loss: 0.05049903690814972 at step: 190
Iter time:  0.27477998482553584


Train loss: 0.06361757218837738 at step: 191
Iter time:  0.27476501714496715


Train loss: 0.04070319980382919 at step: 192
Iter time:  0.2747490406036377


Train loss: 0.05660144239664078 at step: 193
Iter time:  0.27473384852236415


Train loss: 0.016579151153564453 at step: 194
Iter time:  0.27471948653152306


Train loss: 0.010817185044288635 at step: 195
Iter time:  0.27470584037976387


Train loss: 0.038332387804985046 at step: 196
Iter time:  0.2746906876564026


Train loss: 0.05161894112825394 at step: 197
Iter time:  0.27467584004862056


Train loss: 0.05661434680223465 at step: 198
Iter time:  0.27466168548121594


Train loss: 0.028243830427527428 at step: 199
Iter time:  0.27464693515145


Train loss: 0.05098837614059448 at step: 200
Iter time:  0.2746340620517731


Train loss: 0.057539816945791245 at step: 201
Iter time:  0.27462061957933415


Train loss: 0.03865588456392288 at step: 202
Iter time:  0.27460549019350866


Train loss: 0.08994917571544647 at step: 203
Iter time:  0.2745927002629623


Train loss: 0.058716922998428345 at step: 204
Iter time:  0.274579548368267


Train loss: 0.024092543870210648 at step: 205
Iter time:  0.2745678122450666


Train loss: 0.06237272918224335 at step: 206
Iter time:  0.27455524564946737


Train loss: 0.072421595454216 at step: 207
Iter time:  0.27454115227224746


Train loss: 0.0602184534072876 at step: 208
Iter time:  0.2745292175274629


Train loss: 0.019655290991067886 at step: 209
Iter time:  0.2745163429296758


Train loss: 0.033507175743579865 at step: 210
Iter time:  0.27450404848371235


Train loss: 0.06954299658536911 at step: 211
Iter time:  0.274492629896408


Train loss: 0.026210956275463104 at step: 212
Iter time:  0.2744787256672697


Train loss: 0.02389749512076378 at step: 213
Iter time:  0.2744668145694643


Train loss: 0.026433531194925308 at step: 214
Iter time:  0.27445524875248706


Train loss: 0.058277711272239685 at step: 215
Iter time:  0.2744436319484267


Train loss: 0.029514122754335403 at step: 216
Iter time:  0.27443281147215104


Train loss: 0.018938584253191948 at step: 217
Iter time:  0.2744193186957715


Train loss: 0.05423273891210556 at step: 218
Iter time:  0.2744075836391624


Train loss: 0.05634920671582222 at step: 219
Iter time:  0.2743965371014321


Train loss: 0.05669257044792175 at step: 220
Iter time:  0.27438524961471555


Train loss: 0.005033445544540882 at step: 221
Iter time:  0.27437431564158443


Train loss: 0.17646828293800354 at step: 222
Iter time:  0.27436310106569584


Train loss: 0.030148789286613464 at step: 223
Iter time:  0.274351655635064


Train loss: 0.09512513130903244 at step: 224
Iter time:  0.27434060509715763


Train loss: 0.0276887658983469 at step: 225
Iter time:  0.274329588148329


Train loss: 0.0707874745130539 at step: 226
Iter time:  0.2743184830235169


Train loss: 0.08414936810731888 at step: 227
Iter time:  0.2743074904454437


Train loss: 0.055922094732522964 at step: 228
Iter time:  0.2742965346888492


Train loss: 0.034768421202898026 at step: 229
Iter time:  0.27428632844483486


Train loss: 0.05420385301113129 at step: 230
Iter time:  0.27427608552186383


Train loss: 0.0216878242790699 at step: 231
Iter time:  0.2742655442390607


Train loss: 0.09213439375162125 at step: 232
Iter time:  0.2742550804697234


Train loss: 0.0299057774245739 at step: 233
Iter time:  0.27424542279714165


Train loss: 0.009901230223476887 at step: 234
Iter time:  0.2742355104185577


Train loss: 0.023194368928670883 at step: 235
Iter time:  0.27422538818197045


Train loss: 0.07716131955385208 at step: 236
Iter time:  0.2742161326489206


Train loss: 0.008424894884228706 at step: 237
Iter time:  0.2742058556794114


Train loss: 0.011036163195967674 at step: 238
Iter time:  0.2741960898166945


Train loss: 0.03435957431793213 at step: 239
Iter time:  0.2741874032439547


Train loss: 0.11771547794342041 at step: 240
Iter time:  0.27417918543020886


Train loss: 0.011584591120481491 at step: 241
Iter time:  0.27417062426998406


Train loss: 0.03836527094244957 at step: 242
Iter time:  0.2741602718337508


Train loss: 0.03032730147242546 at step: 243
Iter time:  0.2741506099700928


Train loss: 0.018891965970396996 at step: 244
Iter time:  0.27414190769195557


Train loss: 0.010707370005548 at step: 245
Iter time:  0.27413310518070144


Train loss: 0.009138895198702812 at step: 246
Iter time:  0.27412428894663243


Train loss: 0.07086740434169769 at step: 247
Iter time:  0.2741148780714645


Train loss: 0.006829140707850456 at step: 248
Iter time:  0.2741073033502025


Train loss: 0.08407852798700333 at step: 249
Iter time:  0.2740987180227257


Train loss: 0.014931266196072102 at step: 250
Iter time:  0.2740895175933838


Train loss: 0.06546254456043243 at step: 251
Iter time:  0.2740808977073882


Train loss: 0.03377421200275421 at step: 252
Iter time:  0.27407394136701313


Train loss: 0.014242779463529587 at step: 253
Iter time:  0.27406545118852094


Train loss: 0.006591583136469126 at step: 254
Iter time:  0.27405651817171595


Train loss: 0.029260260984301567 at step: 255
Iter time:  0.2740503694496903


Train loss: 0.06873967498540878 at step: 256
Iter time:  0.2740430384874344


Train loss: 0.07445453852415085 at step: 257
Iter time:  0.2740351829083513


Train loss: 0.014261114411056042 at step: 258
Iter time:  0.2740267302638801


Train loss: 0.05593152716755867 at step: 259
Iter time:  0.2740180639686732


Train loss: 0.12929600477218628 at step: 260
Iter time:  0.2740118641119737


Train loss: 0.03695329278707504 at step: 261
Iter time:  0.27400339791601186


Train loss: 0.12070602923631668 at step: 262
Iter time:  0.27399492809790693


Train loss: 0.028903067111968994 at step: 263
Iter time:  0.2739937813109771


Train loss: 0.03180253505706787 at step: 264
Iter time:  0.27398565592187824


Train loss: 0.10832758992910385 at step: 265
Iter time:  0.273977134812553


Train loss: 0.09543994814157486 at step: 266
Iter time:  0.27397234905931284


Train loss: 0.07094921171665192 at step: 267
Iter time:  0.27396676870767545


Train loss: 0.11194847524166107 at step: 268
Iter time:  0.2739591064737804


Train loss: 0.05912007763981819 at step: 269
Iter time:  0.27395125835801587


Train loss: 0.006184904836118221 at step: 270
Iter time:  0.2739442631050392


Train loss: 0.040278661996126175 at step: 271
Iter time:  0.27393777432037014


Train loss: 0.06691180914640427 at step: 272
Iter time:  0.27393186793607827


Train loss: 0.009862749837338924 at step: 273
Iter time:  0.2739245219108386


Train loss: 0.018621457740664482 at step: 274
Iter time:  0.2739176045369058


Train loss: 0.030474592000246048 at step: 275
Iter time:  0.2739111423492432


Train loss: 0.07835312187671661 at step: 276
Iter time:  0.2739063907360685


Train loss: 0.030079180374741554 at step: 277
Iter time:  0.27389969550315224


Train loss: 0.057688698172569275 at step: 278
Iter time:  0.2738937662659789


Train loss: 0.006072822492569685 at step: 279
Iter time:  0.27388708565824776


Train loss: 0.05449109524488449 at step: 280
Iter time:  0.2738811416285379


Train loss: 0.05838785320520401 at step: 281
Iter time:  0.2738758423150222


Train loss: 0.01729944534599781 at step: 282
Iter time:  0.27386951615624394


Train loss: 0.026984823867678642 at step: 283
Iter time:  0.27386226418161563


Train loss: 0.07196329534053802 at step: 284
Iter time:  0.2738576271164585


Train loss: 0.07252148538827896 at step: 285
Iter time:  0.27385286782917223


Train loss: 0.06900974363088608 at step: 286
Iter time:  0.27384585350543467


Train loss: 0.03571808338165283 at step: 287
Iter time:  0.27383957839593653


Train loss: 0.03906729072332382 at step: 288
Iter time:  0.27383507208691704


Train loss: 0.062232084572315216 at step: 289
Iter time:  0.27382921265070825


Train loss: 0.058814339339733124 at step: 290
Iter time:  0.2738226339734834


Train loss: 0.06002281233668327 at step: 291
Iter time:  0.273816153765544


Train loss: 0.07078346610069275 at step: 292
Iter time:  0.27381215275150456


Train loss: 0.07700163871049881 at step: 293
Iter time:  0.2738083442323444


Train loss: 0.052246496081352234 at step: 294
Iter time:  0.2738022382567529


Train loss: 0.010784954763948917 at step: 295
Iter time:  0.27379712896831965


Train loss: 0.05508248507976532 at step: 296
Iter time:  0.2737933010668368


Train loss: 0.01805325224995613 at step: 297
Iter time:  0.2737879223293728


Train loss: 0.011899027973413467 at step: 298
Iter time:  0.2737832861458695


Train loss: 0.024535343050956726 at step: 299
Iter time:  0.2737790589348528


Train loss: 0.04399466887116432 at step: 300
Iter time:  0.2737741390864054


Train loss: 0.0471353754401207 at step: 301
Iter time:  0.27376875212026197


Train loss: 0.06011021509766579 at step: 302
Iter time:  0.27376449818642723


Train loss: 0.043538227677345276 at step: 303
Iter time:  0.27376072713644195


Train loss: 0.010041698813438416 at step: 304
Iter time:  0.2737568044348767


Train loss: 0.05226963758468628 at step: 305
Iter time:  0.27375235948406285


Train loss: 0.0716889426112175 at step: 306
Iter time:  0.27374855131884807


Train loss: 0.0699610635638237 at step: 307
Iter time:  0.2737443214130712


Train loss: 0.03460513800382614 at step: 308
Iter time:  0.27374098440269373


Train loss: 0.07093530893325806 at step: 309
Iter time:  0.2737365733458386


Train loss: 0.06605374068021774 at step: 310
Iter time:  0.2737316393083142


Train loss: 0.0348738431930542 at step: 311
Iter time:  0.27372770600763546


Train loss: 0.0455179363489151 at step: 312
Iter time:  0.27372400806500363


Train loss: 0.04937782883644104 at step: 313
Iter time:  0.2737199429886791


Train loss: 0.015547020360827446 at step: 314
Iter time:  0.27371479295621254


Train loss: 0.10385596752166748 at step: 315
Iter time:  0.27371164730616976


Train loss: 0.009868502616882324 at step: 316
Iter time:  0.27370818204517605


Train loss: 0.012355847284197807 at step: 317
Iter time:  0.27370337808169776


Train loss: 0.059885453432798386 at step: 318
Iter time:  0.2736997192010939


Train loss: 0.1164969727396965 at step: 319
Iter time:  0.2736972387307864


Train loss: 0.037210769951343536 at step: 320
Iter time:  0.2736933261156082


Train loss: 0.06803366541862488 at step: 321
Iter time:  0.2736885139132586


Train loss: 0.14252109825611115 at step: 322
Iter time:  0.27368646008627756


Train loss: 0.030971962958574295 at step: 323
Iter time:  0.2736829670590144


Train loss: 0.072999007999897 at step: 324
Iter time:  0.2736777096618841


Train loss: 0.06804705411195755 at step: 325
Iter time:  0.27368583532480095


Train loss: 0.02045237086713314 at step: 326
Iter time:  0.2736819273123712


Train loss: 0.053088169544935226 at step: 327
Iter time:  0.2736782582892555


Train loss: 0.03271639347076416 at step: 328
Iter time:  0.2736747315744074


Train loss: 0.0073651960119605064 at step: 329
Iter time:  0.27367094584873747


Train loss: 0.11811994761228561 at step: 330
Iter time:  0.2736680045272365


Train loss: 0.02690231055021286 at step: 331
Iter time:  0.2736647914183464


Train loss: 0.04500103369355202 at step: 332
Iter time:  0.2736623445189143


Train loss: 0.03795190155506134 at step: 333
Iter time:  0.2736600483501996


Train loss: 0.055408600717782974 at step: 334
Iter time:  0.27365504624600895


Train loss: 0.027502156794071198 at step: 335
Iter time:  0.2736527023030751


Train loss: 0.06189345195889473 at step: 336
Iter time:  0.2736498514811198


Train loss: 0.07140374928712845 at step: 337
Iter time:  0.2736463178866695


Train loss: 0.018756765872240067 at step: 338
Iter time:  0.2736431727042565


Train loss: 0.021474871784448624 at step: 339
Iter time:  0.2736401339899474


Train loss: 0.06435893476009369 at step: 340
Iter time:  0.2736381117035361


Train loss: 0.003460872219875455 at step: 341
Iter time:  0.27363500567125787


Train loss: 0.04698638617992401 at step: 342
Iter time:  0.2736328303465369


Train loss: 0.011869404464960098 at step: 343
Iter time:  0.27363007895800534


Train loss: 0.021926717832684517 at step: 344
Iter time:  0.2736276582229969


Train loss: 0.06010906770825386 at step: 345
Iter time:  0.2736245943152386


Train loss: 0.022749241441488266 at step: 346
Iter time:  0.27362176586437775


Train loss: 0.016103722155094147 at step: 347
Iter time:  0.2736184047347187


Train loss: 0.005111014470458031 at step: 348
Iter time:  0.2736155068737337


Train loss: 0.007493413984775543 at step: 349
Iter time:  0.27361574009018164


Train loss: 0.05331510305404663 at step: 350
Iter time:  0.27361178398132324


Train loss: 0.029087606817483902 at step: 351
Iter time:  0.27361217659083525


Train loss: 0.04006684944033623 at step: 352
Iter time:  0.2736119336702607


Train loss: 0.03259823098778725 at step: 353
Iter time:  0.2736115259759487


Train loss: 0.016086064279079437 at step: 354
Iter time:  0.27361185604569604


Train loss: 0.018859202042222023 at step: 355
Iter time:  0.2736114703433614


Train loss: 0.005509613081812859 at step: 356
Iter time:  0.2736108832145005


Train loss: 0.012371723540127277 at step: 357
Iter time:  0.2736107828904267


Train loss: 0.07958263158798218 at step: 358
Iter time:  0.27361225549069196


Train loss: 0.011225290596485138 at step: 359
Iter time:  0.27361215854421633


Train loss: 0.04620317742228508 at step: 360
Iter time:  0.2736115197340647


Train loss: 0.017547478899359703 at step: 361
Iter time:  0.27361268482049744


Train loss: 0.019068606197834015 at step: 362
Iter time:  0.27361338639127614


Train loss: 0.0748300701379776 at step: 363
Iter time:  0.27361293600938863


Train loss: 0.04982569441199303 at step: 364
Iter time:  0.2736124383224236


Train loss: 0.07640399783849716 at step: 365
Iter time:  0.2736131694218884


Train loss: 0.05768580734729767 at step: 366
Iter time:  0.2736140163869806


Train loss: 0.014578520320355892 at step: 367
Iter time:  0.2736134672034989


Train loss: 0.024249836802482605 at step: 368
Iter time:  0.27361211763775867


Train loss: 0.025870591402053833 at step: 369
Iter time:  0.273612746701331


Train loss: 0.023934513330459595 at step: 370
Iter time:  0.27361195538495037


Train loss: 0.0417720302939415 at step: 371
Iter time:  0.27361179362088844


Train loss: 0.09706179052591324 at step: 372
Iter time:  0.2736106181657442


Train loss: 0.06394755095243454 at step: 373
Iter time:  0.2736102000637924


Train loss: 0.009829324670135975 at step: 374
Iter time:  0.2736087629501832


Train loss: 0.009753272868692875 at step: 375
Iter time:  0.27360770988464356


Found 5833 trainable_data in total.
