Model loaded..
Use LinearProbe head: pretrained_weights/10_14.pth
Choose layer: 23 for cls embedding
Not add Gaussian noise to the feature embedding.
Not use random erasing.
data mode: ours
[{'data_path': '/home/data/szk/face_B', 'data_mode': 'ours'}]
total_list_len: 6000
Fix the backbone.
Length of dataset: 375
Directory ./TTO_checkpoints/2024-10-14-11-30-57 is created.
Train loss: 0.5360740423202515 at step: 1
Iter time:  1.3583879470825195


Train loss: 0.5610113143920898 at step: 2
Iter time:  0.8131885528564453


Train loss: 0.4517486095428467 at step: 3
Iter time:  0.6321976979573568


Train loss: 0.42303740978240967 at step: 4
Iter time:  0.5426476001739502


Train loss: 0.4718077778816223 at step: 5
Iter time:  0.48853440284729005


Train loss: 0.45721346139907837 at step: 6
Iter time:  0.451942245165507


Train loss: 0.5309744477272034 at step: 7
Iter time:  0.42574494225638254


Train loss: 0.4129118323326111 at step: 8
Iter time:  0.4067666530609131


Train loss: 0.4972759485244751 at step: 9
Iter time:  0.39175907770792645


Train loss: 0.5425080060958862 at step: 10
Iter time:  0.37957451343536375


Train loss: 0.5122477412223816 at step: 11
Iter time:  0.36960686336864124


Train loss: 0.5279021859169006 at step: 12
Iter time:  0.3613140384356181


Train loss: 0.47452598810195923 at step: 13
Iter time:  0.35443758964538574


Train loss: 0.4899432063102722 at step: 14
Iter time:  0.3484882797513689


Train loss: 0.5165166854858398 at step: 15
Iter time:  0.34330143928527834


Train loss: 0.5830620527267456 at step: 16
Iter time:  0.33869004249572754


Train loss: 0.3937532901763916 at step: 17
Iter time:  0.33456887918360095


Train loss: 0.41997140645980835 at step: 18
Iter time:  0.3309730821185642


Train loss: 0.5133466124534607 at step: 19
Iter time:  0.3277304799933183


Train loss: 0.49529480934143066 at step: 20
Iter time:  0.3248703122138977


Train loss: 0.4883940517902374 at step: 21
Iter time:  0.3222114699227469


Train loss: 0.4843340814113617 at step: 22
Iter time:  0.31978144428946753


Train loss: 0.4200100898742676 at step: 23
Iter time:  0.31755178907643195


Train loss: 0.4459044337272644 at step: 24
Iter time:  0.31552451848983765


Train loss: 0.46714770793914795 at step: 25
Iter time:  0.31366480827331544


Train loss: 0.5787811875343323 at step: 26
Iter time:  0.31194937229156494


Train loss: 0.40610742568969727 at step: 27
Iter time:  0.3105143970913357


Train loss: 0.5115910768508911 at step: 28
Iter time:  0.30904254743031095


Train loss: 0.42973440885543823 at step: 29
Iter time:  0.3078424519505994


Train loss: 0.5408618450164795 at step: 30
Iter time:  0.30660057862599693


Train loss: 0.5943037271499634 at step: 31
Iter time:  0.30541386142853766


Train loss: 0.45960667729377747 at step: 32
Iter time:  0.3042929023504257


Train loss: 0.5301595330238342 at step: 33
Iter time:  0.3032246575211034


Train loss: 0.5914530158042908 at step: 34
Iter time:  0.30221683137557087


Train loss: 0.4537479281425476 at step: 35
Iter time:  0.30141965321132114


Train loss: 0.48676618933677673 at step: 36
Iter time:  0.30061014493306476


Train loss: 0.4533160924911499 at step: 37
Iter time:  0.29985672718769796


Train loss: 0.45135733485221863 at step: 38
Iter time:  0.2990257740020752


Train loss: 0.46274423599243164 at step: 39
Iter time:  0.29827013382544887


Train loss: 0.5417695045471191 at step: 40
Iter time:  0.2975591778755188


Train loss: 0.432052880525589 at step: 41
Iter time:  0.29687024325859257


Train loss: 0.582416832447052 at step: 42
Iter time:  0.29624169781094506


Train loss: 0.6154266595840454 at step: 43
Iter time:  0.29562870291776433


Train loss: 0.45902565121650696 at step: 44
Iter time:  0.2950584888458252


Train loss: 0.5068861842155457 at step: 45
Iter time:  0.2945261319478353


Train loss: 0.5492790937423706 at step: 46
Iter time:  0.294007482736007


Train loss: 0.49561774730682373 at step: 47
Iter time:  0.293525533473238


Train loss: 0.393598735332489 at step: 48
Iter time:  0.2930379658937454


Train loss: 0.5701677203178406 at step: 49
Iter time:  0.292602251987068


Train loss: 0.6157792210578918 at step: 50
Iter time:  0.29215349674224855


Train loss: 0.4754341244697571 at step: 51
Iter time:  0.2917216385112089


Train loss: 0.4926002323627472 at step: 52
Iter time:  0.29131492284628063


Train loss: 0.5196338891983032 at step: 53
Iter time:  0.29092032504531573


Train loss: 0.461243599653244 at step: 54
Iter time:  0.29053089795289216


Train loss: 0.5648413896560669 at step: 55
Iter time:  0.2901633175936612


Train loss: 0.5673984885215759 at step: 56
Iter time:  0.2898199941430773


Train loss: 0.3156106770038605 at step: 57
Iter time:  0.2895130483727706


Train loss: 0.39035937190055847 at step: 58
Iter time:  0.28924106729441673


Train loss: 0.5712400674819946 at step: 59
Iter time:  0.28898641618631654


Train loss: 0.4263492822647095 at step: 60
Iter time:  0.28874577283859254


Train loss: 0.4377138316631317 at step: 61
Iter time:  0.2884994842967049


Train loss: 0.5051596164703369 at step: 62
Iter time:  0.28820941140574796


Train loss: 0.5319628715515137 at step: 63
Iter time:  0.28795065955510213


Train loss: 0.51188063621521 at step: 64
Iter time:  0.28775082901120186


Train loss: 0.5305148959159851 at step: 65
Iter time:  0.2874947217794565


Train loss: 0.3563486933708191 at step: 66
Iter time:  0.28725262121720746


Train loss: 0.5523446202278137 at step: 67
Iter time:  0.28700062766003964


Train loss: 0.5137046575546265 at step: 68
Iter time:  0.2868078876944149


Train loss: 0.5656173229217529 at step: 69
Iter time:  0.2865962222002555


Train loss: 0.6030183434486389 at step: 70
Iter time:  0.28637590067727225


Train loss: 0.6024360656738281 at step: 71
Iter time:  0.28626507436725457


Train loss: 0.5147113800048828 at step: 72
Iter time:  0.2861307164033254


Train loss: 0.447306752204895 at step: 73
Iter time:  0.2859681632420788


Train loss: 0.5111201405525208 at step: 74
Iter time:  0.2857707062283078


Train loss: 0.4213659465312958 at step: 75
Iter time:  0.2855889511108398


Train loss: 0.5583668351173401 at step: 76
Iter time:  0.2854011717595552


Train loss: 0.5025864839553833 at step: 77
Iter time:  0.2852187868836638


Train loss: 0.6203802227973938 at step: 78
Iter time:  0.285072617041759


Train loss: 0.4661640524864197 at step: 79
Iter time:  0.28492188151878645


Train loss: 0.3947887122631073 at step: 80
Iter time:  0.2847699195146561


Train loss: 0.5056685209274292 at step: 81
Iter time:  0.2846104657208478


Train loss: 0.41833895444869995 at step: 82
Iter time:  0.28444521310852794


Train loss: 0.544513463973999 at step: 83
Iter time:  0.28431855339601814


Train loss: 0.5162784457206726 at step: 84
Iter time:  0.2841650588171823


Train loss: 0.45274779200553894 at step: 85
Iter time:  0.2840165839475744


Train loss: 0.4886355400085449 at step: 86
Iter time:  0.2838663611301156


Train loss: 0.3934032917022705 at step: 87
Iter time:  0.2837230994783599


Train loss: 0.4070304334163666 at step: 88
Iter time:  0.283589858900417


Train loss: 0.5669423937797546 at step: 89
Iter time:  0.2834593740741858


Train loss: 0.43519327044487 at step: 90
Iter time:  0.28332713974846735


Train loss: 0.3982064127922058 at step: 91
Iter time:  0.28320624016143464


Train loss: 0.5726972818374634 at step: 92
Iter time:  0.28316564922747406


Train loss: 0.4799480140209198 at step: 93
Iter time:  0.28305551057220785


Train loss: 0.46975424885749817 at step: 94
Iter time:  0.28294045874413026


Train loss: 0.5477046966552734 at step: 95
Iter time:  0.28282351242868525


Train loss: 0.4105345606803894 at step: 96
Iter time:  0.2827204018831253


Train loss: 0.5544916391372681 at step: 97
Iter time:  0.2826493794156104


Train loss: 0.6441715955734253 at step: 98
Iter time:  0.2825639345207993


Train loss: 0.5721766948699951 at step: 99
Iter time:  0.28245244844995365


Train loss: 0.4088922142982483 at step: 100
Iter time:  0.2823925018310547


Train loss: 0.5096579790115356 at step: 101
Iter time:  0.28229339051954816


Train loss: 0.4029795229434967 at step: 102
Iter time:  0.2822506871877932


Train loss: 0.4689924418926239 at step: 103
Iter time:  0.28217254564600086


Train loss: 0.3969011902809143 at step: 104
Iter time:  0.28208513672535235


Train loss: 0.48882362246513367 at step: 105
Iter time:  0.2819879599979946


Train loss: 0.46051377058029175 at step: 106
Iter time:  0.2819094005620705


Train loss: 0.43187156319618225 at step: 107
Iter time:  0.28181784620908934


Train loss: 0.5066245794296265 at step: 108
Iter time:  0.2817349875414813


Train loss: 0.5991268157958984 at step: 109
Iter time:  0.2816519846609973


Train loss: 0.5414149761199951 at step: 110
Iter time:  0.2815656206824563


Train loss: 0.5883605480194092 at step: 111
Iter time:  0.28148339245770426


Train loss: 0.5702642202377319 at step: 112
Iter time:  0.28141314004148754


Train loss: 0.4646686613559723 at step: 113
Iter time:  0.28134980032929274


Train loss: 0.4844309389591217 at step: 114
Iter time:  0.2812749858488116


Train loss: 0.5322571396827698 at step: 115
Iter time:  0.2812030211738918


Train loss: 0.48904097080230713 at step: 116
Iter time:  0.28113408951923763


Train loss: 0.4047745168209076 at step: 117
Iter time:  0.2810611215412107


Train loss: 0.4466703534126282 at step: 118
Iter time:  0.2810361142885887


Train loss: 0.42451536655426025 at step: 119
Iter time:  0.2809772411314379


Train loss: 0.46799880266189575 at step: 120
Iter time:  0.2809016803900401


Train loss: 0.4875301718711853 at step: 121
Iter time:  0.280853620245437


Train loss: 0.5100106000900269 at step: 122
Iter time:  0.28081251363285253


Train loss: 0.4907621741294861 at step: 123
Iter time:  0.2807747154701047


Train loss: 0.5342510938644409 at step: 124
Iter time:  0.2807159635328477


Train loss: 0.5004993081092834 at step: 125
Iter time:  0.2806901988983154


Train loss: 0.42606979608535767 at step: 126
Iter time:  0.280627793735928


Train loss: 0.5657161474227905 at step: 127
Iter time:  0.28056966413663126


Train loss: 0.40312594175338745 at step: 128
Iter time:  0.2805363591760397


Train loss: 0.4543928802013397 at step: 129
Iter time:  0.2804716058479723


Train loss: 0.6218727827072144 at step: 130
Iter time:  0.28040619079883283


Train loss: 0.49448031187057495 at step: 131
Iter time:  0.28038150117597505


Train loss: 0.43641600012779236 at step: 132
Iter time:  0.280333602067196


Train loss: 0.4373176097869873 at step: 133
Iter time:  0.2802992530335161


Train loss: 0.5151482820510864 at step: 134
Iter time:  0.2802624115303381


Train loss: 0.46984171867370605 at step: 135
Iter time:  0.2802102707050465


Train loss: 0.49505311250686646 at step: 136
Iter time:  0.2801711629418766


Train loss: 0.5468717813491821 at step: 137
Iter time:  0.28013545057199296


Train loss: 0.4572649598121643 at step: 138
Iter time:  0.28009855401688727


Train loss: 0.600826621055603 at step: 139
Iter time:  0.2800601557861987


Train loss: 0.5133056640625 at step: 140
Iter time:  0.28000994409833635


Train loss: 0.5180861353874207 at step: 141
Iter time:  0.27995588762540347


Train loss: 0.4742826819419861 at step: 142
Iter time:  0.27990015963433496


Train loss: 0.4886237382888794 at step: 143
Iter time:  0.27988507030727144


Train loss: 0.5122148394584656 at step: 144
Iter time:  0.27985890706380206


Train loss: 0.49707186222076416 at step: 145
Iter time:  0.2798092661232784


Train loss: 0.44425302743911743 at step: 146
Iter time:  0.27976167855197437


Train loss: 0.4523167014122009 at step: 147
Iter time:  0.27971681445634283


Train loss: 0.5009734034538269 at step: 148
Iter time:  0.27967435927004425


Train loss: 0.39289507269859314 at step: 149
Iter time:  0.2796359062194824


Train loss: 0.5134022831916809 at step: 150
Iter time:  0.2795890998840332


Train loss: 0.430277943611145 at step: 151
Iter time:  0.27954541610566197


Train loss: 0.5795787572860718 at step: 152
Iter time:  0.27952693010631363


Train loss: 0.4870489537715912 at step: 153
Iter time:  0.2794811554204405


Train loss: 0.5816289186477661 at step: 154
Iter time:  0.2794595430423687


Train loss: 0.6477731466293335 at step: 155
Iter time:  0.2794087671464489


Train loss: 0.5104510188102722 at step: 156
Iter time:  0.2793912887573242


Train loss: 0.4807310998439789 at step: 157
Iter time:  0.279350541959143


Train loss: 0.473105788230896 at step: 158
Iter time:  0.27931167958657954


Train loss: 0.3841252326965332 at step: 159
Iter time:  0.2792977896876305


Train loss: 0.46530959010124207 at step: 160
Iter time:  0.27926541715860365


Train loss: 0.44177573919296265 at step: 161
Iter time:  0.2792315083260862


Train loss: 0.4209921956062317 at step: 162
Iter time:  0.2792252949726434


Train loss: 0.42177683115005493 at step: 163
Iter time:  0.27920164652397295


Train loss: 0.5471596717834473 at step: 164
Iter time:  0.27918465835292167


Train loss: 0.4711671769618988 at step: 165
Iter time:  0.2791632146546335


Train loss: 0.5227372050285339 at step: 166
Iter time:  0.279126616845648


Train loss: 0.41092246770858765 at step: 167
Iter time:  0.27909918602355227


Train loss: 0.45056846737861633 at step: 168
Iter time:  0.27909132838249207


Train loss: 0.4197419285774231 at step: 169
Iter time:  0.2790573941179987


Train loss: 0.5285824537277222 at step: 170
Iter time:  0.27901919589323154


Train loss: 0.535216748714447 at step: 171
Iter time:  0.27899303352623656


Train loss: 0.3247046172618866 at step: 172
Iter time:  0.27895622197971787


Train loss: 0.5887190699577332 at step: 173
Iter time:  0.27894152933462507


Train loss: 0.4397177994251251 at step: 174
Iter time:  0.2789319808455719


Train loss: 0.48068273067474365 at step: 175
Iter time:  0.2789225060599191


Train loss: 0.5070006847381592 at step: 176
Iter time:  0.27888921715996484


Train loss: 0.4469827115535736 at step: 177
Iter time:  0.27885590434747903


Train loss: 0.4074352979660034 at step: 178
Iter time:  0.278829837113284


Train loss: 0.5400997996330261 at step: 179
Iter time:  0.278811706511002


Train loss: 0.32208147644996643 at step: 180
Iter time:  0.27965580224990844


Train loss: 0.5459403991699219 at step: 181
Iter time:  0.2796591368828031


Train loss: 0.35144907236099243 at step: 182
Iter time:  0.2796583869955042


Train loss: 0.38489842414855957 at step: 183
Iter time:  0.2796378904353074


Train loss: 0.5870376825332642 at step: 184
Iter time:  0.27963119745254517


Train loss: 0.5379980802536011 at step: 185
Iter time:  0.27959293932528106


Train loss: 0.578343391418457 at step: 186
Iter time:  0.27960540786866217


Train loss: 0.4199675917625427 at step: 187
Iter time:  0.2796703812910274


Train loss: 0.47718968987464905 at step: 188
Iter time:  0.279664342707776


Train loss: 0.5089475512504578 at step: 189
Iter time:  0.2796370062247786


Train loss: 0.41389280557632446 at step: 190
Iter time:  0.27960463197607743


Train loss: 0.3771854043006897 at step: 191
Iter time:  0.2795831420658771


Train loss: 0.4399298429489136 at step: 192
Iter time:  0.2795726719001929


Train loss: 0.3693235516548157 at step: 193
Iter time:  0.2795638136295457


Train loss: 0.41358858346939087 at step: 194
Iter time:  0.27954319088729385


Train loss: 0.4368932545185089 at step: 195
Iter time:  0.2795210398160494


Train loss: 0.5241174101829529 at step: 196
Iter time:  0.27949421868032337


Train loss: 0.44602033495903015 at step: 197
Iter time:  0.2794720654560225


Train loss: 0.38079941272735596 at step: 198
Iter time:  0.27945158096274947


Train loss: 0.42370039224624634 at step: 199
Iter time:  0.27942726839726895


Train loss: 0.6391288042068481 at step: 200
Iter time:  0.2794041073322296


Train loss: 0.5479136109352112 at step: 201
Iter time:  0.27939670833189095


Train loss: 0.4603128135204315 at step: 202
Iter time:  0.27937604531203164


Train loss: 0.5487988591194153 at step: 203
Iter time:  0.2793506836069041


Train loss: 0.3277466893196106 at step: 204
Iter time:  0.27932756905462225


Train loss: 0.5964081287384033 at step: 205
Iter time:  0.2793096321385081


Train loss: 0.4545133709907532 at step: 206
Iter time:  0.27928636837931514


Train loss: 0.374137818813324 at step: 207
Iter time:  0.2792599039953112


Train loss: 0.5080397725105286 at step: 208
Iter time:  0.2792311883889712


Train loss: 0.4410821795463562 at step: 209
Iter time:  0.27921267331502087


Train loss: 0.39513909816741943 at step: 210
Iter time:  0.2791963497797648


Train loss: 0.48508065938949585 at step: 211
Iter time:  0.2791860510387692


Train loss: 0.45379966497421265 at step: 212
Iter time:  0.27915874854573663


Train loss: 0.37221598625183105 at step: 213
Iter time:  0.2791349742334214


Train loss: 0.4630105197429657 at step: 214
Iter time:  0.2791122454349126


Train loss: 0.46141505241394043 at step: 215
Iter time:  0.2790873228117477


Train loss: 0.32821032404899597 at step: 216
Iter time:  0.27908807441040323


Train loss: 0.26165908575057983 at step: 217
Iter time:  0.27908027776375344


Train loss: 0.6398063898086548 at step: 218
Iter time:  0.27905679842747677


Train loss: 0.49123305082321167 at step: 219
Iter time:  0.2790337926176585


Train loss: 0.3276493549346924 at step: 220
Iter time:  0.2790173660625111


Train loss: 0.46440964937210083 at step: 221
Iter time:  0.27899940844574667


Train loss: 0.4427065849304199 at step: 222
Iter time:  0.27897955383266415


Train loss: 0.5107923150062561 at step: 223
Iter time:  0.2789538580205943


Train loss: 0.4152812957763672 at step: 224
Iter time:  0.27893224890742985


Train loss: 0.40096378326416016 at step: 225
Iter time:  0.2789113510979546


Train loss: 0.6441820859909058 at step: 226
Iter time:  0.2788903576082888


Train loss: 0.5527955293655396 at step: 227
Iter time:  0.27887184609400545


Train loss: 0.37679654359817505 at step: 228
Iter time:  0.27885233937648307


Train loss: 0.42430320382118225 at step: 229
Iter time:  0.2788347510791762


Train loss: 0.4161182940006256 at step: 230
Iter time:  0.27881495745285695


Train loss: 0.4227569103240967 at step: 231
Iter time:  0.27879704231823677


Train loss: 0.3947702944278717 at step: 232
Iter time:  0.27877745237843743


Train loss: 0.5227696895599365 at step: 233
Iter time:  0.2787571321741194


Train loss: 0.5290724635124207 at step: 234
Iter time:  0.27873485821944016


Train loss: 0.3566651940345764 at step: 235
Iter time:  0.2787132263183594


Train loss: 0.47951948642730713 at step: 236
Iter time:  0.2786954126115573


Train loss: 0.49020975828170776 at step: 237
Iter time:  0.2786824421540594


Train loss: 0.5477750301361084 at step: 238
Iter time:  0.2786584882175221


Train loss: 0.4719577431678772 at step: 239
Iter time:  0.27865374736706083


Train loss: 0.4990037679672241 at step: 240
Iter time:  0.27865460415681204


Train loss: 0.5122281908988953 at step: 241
Iter time:  0.2786386636282893


Train loss: 0.35339200496673584 at step: 242
Iter time:  0.2786245346069336


Train loss: 0.42301666736602783 at step: 243
Iter time:  0.2786104728164987


Train loss: 0.5133463740348816 at step: 244
Iter time:  0.2785951377915554


Train loss: 0.384676456451416 at step: 245
Iter time:  0.27858359473092215


Train loss: 0.47421956062316895 at step: 246
Iter time:  0.2785672889492376


Train loss: 0.6530332565307617 at step: 247
Iter time:  0.2785902718300762


Train loss: 0.4058752655982971 at step: 248
Iter time:  0.2785713778388116


Train loss: 0.38542884588241577 at step: 249
Iter time:  0.27855461476797083


Train loss: 0.4483594596385956 at step: 250
Iter time:  0.27853974914550783


Train loss: 0.3773409128189087 at step: 251
Iter time:  0.27853289163445094


Train loss: 0.4448699355125427 at step: 252
Iter time:  0.2785227667717707


Train loss: 0.3528361916542053 at step: 253
Iter time:  0.2785114855634365


Train loss: 0.4503927528858185 at step: 254
Iter time:  0.27849388873483255


Train loss: 0.5157885551452637 at step: 255
Iter time:  0.2784990179772471


Train loss: 0.33787643909454346 at step: 256
Iter time:  0.2784929443150759


Train loss: 0.424428254365921 at step: 257
Iter time:  0.27848965370237594


Train loss: 0.5323885083198547 at step: 258
Iter time:  0.2784760044526684


Train loss: 0.4145395755767822 at step: 259
Iter time:  0.27846784941478125


Train loss: 0.5240716934204102 at step: 260
Iter time:  0.278473555124723


Train loss: 0.4857550263404846 at step: 261
Iter time:  0.278455692232797


Train loss: 0.3966849744319916 at step: 262
Iter time:  0.2784404645439323


Train loss: 0.46865248680114746 at step: 263
Iter time:  0.27843228492446725


Train loss: 0.42562633752822876 at step: 264
Iter time:  0.27841751954772254


Train loss: 0.4609029293060303 at step: 265
Iter time:  0.27840535775670466


Train loss: 0.5994384288787842 at step: 266
Iter time:  0.2783920487066857


Train loss: 0.46272820234298706 at step: 267
Iter time:  0.2783793733361062


Train loss: 0.3955156207084656 at step: 268
Iter time:  0.27836556399046486


Train loss: 0.39566266536712646 at step: 269
Iter time:  0.27834971066301195


Train loss: 0.5075370073318481 at step: 270
Iter time:  0.27833527105825917


Train loss: 0.4096379280090332 at step: 271
Iter time:  0.27832051660741824


Train loss: 0.38969045877456665 at step: 272
Iter time:  0.2783051527598325


Train loss: 0.4435715675354004 at step: 273
Iter time:  0.2782874212160215


Train loss: 0.3124277889728546 at step: 274
Iter time:  0.27827226332504384


Train loss: 0.547347903251648 at step: 275
Iter time:  0.2782579638741233


Train loss: 0.5005769729614258 at step: 276
Iter time:  0.2782430450121562


Train loss: 0.36253297328948975 at step: 277
Iter time:  0.2782280006133262


Train loss: 0.5240895748138428 at step: 278
Iter time:  0.27821906522023593


Train loss: 0.456131249666214 at step: 279
Iter time:  0.27820625185539216


Train loss: 0.44035324454307556 at step: 280
Iter time:  0.27822173067501615


Train loss: 0.48637986183166504 at step: 281
Iter time:  0.2782076177223721


Train loss: 0.4185919165611267 at step: 282
Iter time:  0.2781950928640704


Train loss: 0.4489114284515381 at step: 283
Iter time:  0.2781833827284958


Train loss: 0.5173386335372925 at step: 284
Iter time:  0.2781801055854475


Train loss: 0.47849464416503906 at step: 285
Iter time:  0.27817199941267046


Train loss: 0.49562227725982666 at step: 286
Iter time:  0.2781661257043585


Train loss: 0.5523906946182251 at step: 287
Iter time:  0.2781590127778801


Train loss: 0.38151371479034424 at step: 288
Iter time:  0.2781457288397683


Train loss: 0.512897253036499 at step: 289
Iter time:  0.2781339095950539


Train loss: 0.38821670413017273 at step: 290
Iter time:  0.27812217268450506


Train loss: 0.5360055565834045 at step: 291
Iter time:  0.27811994667315404


Train loss: 0.48201972246170044 at step: 292
Iter time:  0.2781083289891073


Train loss: 0.3382062315940857 at step: 293
Iter time:  0.2780981462563264


Train loss: 0.315732479095459 at step: 294
Iter time:  0.2780980650259524


Train loss: 0.4361117482185364 at step: 295
Iter time:  0.27808478242259915


Train loss: 0.47566521167755127 at step: 296
Iter time:  0.2780718932280669


Train loss: 0.40647822618484497 at step: 297
Iter time:  0.2780666431593975


Train loss: 0.4524020552635193 at step: 298
Iter time:  0.27805924815619554


Train loss: 0.36985287070274353 at step: 299
Iter time:  0.27804811184222883


Train loss: 0.5714844465255737 at step: 300
Iter time:  0.27803241888682045


Train loss: 0.43719857931137085 at step: 301
Iter time:  0.2780205791574776


Train loss: 0.5539581775665283 at step: 302
Iter time:  0.278009360989198


Train loss: 0.5153964161872864 at step: 303
Iter time:  0.27799498129992595


Train loss: 0.5340589284896851 at step: 304
Iter time:  0.27798232436180115


Train loss: 0.4829549789428711 at step: 305
Iter time:  0.27797053993725385


Train loss: 0.35004663467407227 at step: 306
Iter time:  0.27795826609617746


Train loss: 0.32366567850112915 at step: 307
Iter time:  0.2779477217298377


Train loss: 0.4893915057182312 at step: 308
Iter time:  0.27793945507569745


Train loss: 0.45826831459999084 at step: 309
Iter time:  0.2779272320201096


Train loss: 0.5694616436958313 at step: 310
Iter time:  0.2779151355066607


Train loss: 0.5831817388534546 at step: 311
Iter time:  0.27791025170942596


Train loss: 0.5082476139068604 at step: 312
Iter time:  0.27790174499536174


Train loss: 0.4689202606678009 at step: 313
Iter time:  0.2778932118949037


Train loss: 0.4122007489204407 at step: 314
Iter time:  0.2778834484185383


Train loss: 0.45821014046669006 at step: 315
Iter time:  0.2778740829891629


Train loss: 0.5240676999092102 at step: 316
Iter time:  0.2778781667540345


Train loss: 0.4356212615966797 at step: 317
Iter time:  0.27788765498140255


Train loss: 0.42121025919914246 at step: 318
Iter time:  0.2778784786380312


Train loss: 0.5240806937217712 at step: 319
Iter time:  0.27786777161505527


Train loss: 0.5280435681343079 at step: 320
Iter time:  0.2778669662773609


Train loss: 0.42216846346855164 at step: 321
Iter time:  0.27785845263353387


Train loss: 0.4081394672393799 at step: 322
Iter time:  0.2778488168064852


Train loss: 0.39723169803619385 at step: 323
Iter time:  0.27783996844808384


Train loss: 0.471401572227478 at step: 324
Iter time:  0.2778311680864405


Train loss: 0.5184847116470337 at step: 325
Iter time:  0.2778218738849346


Train loss: 0.3829459249973297 at step: 326
Iter time:  0.27781033881602846


Train loss: 0.45120006799697876 at step: 327
Iter time:  0.27780009263881483


Train loss: 0.4819347560405731 at step: 328
Iter time:  0.2778014344413106


Train loss: 0.3547908067703247 at step: 329
Iter time:  0.2778040319228245


Train loss: 0.29990190267562866 at step: 330
Iter time:  0.27779235984339856


Train loss: 0.5822510719299316 at step: 331
Iter time:  0.27779339735601605


Train loss: 0.5420424938201904 at step: 332
Iter time:  0.2777865227446499


Train loss: 0.44601815938949585 at step: 333
Iter time:  0.27777739974471544


Train loss: 0.5229400992393494 at step: 334
Iter time:  0.27777051354596716


Train loss: 0.43330997228622437 at step: 335
Iter time:  0.2777629382574736


Train loss: 0.5006353855133057 at step: 336
Iter time:  0.277755469083786


Train loss: 0.33582013845443726 at step: 337
Iter time:  0.2777602898968433


Train loss: 0.4797375798225403 at step: 338
Iter time:  0.2777518986244879


Train loss: 0.5140034556388855 at step: 339
Iter time:  0.2777585265910731


Train loss: 0.5074678659439087 at step: 340
Iter time:  0.27775312802370855


Train loss: 0.5116367340087891 at step: 341
Iter time:  0.27774795688841697


Train loss: 0.5106757879257202 at step: 342
Iter time:  0.27773794653820016


Train loss: 0.4972328841686249 at step: 343
Iter time:  0.2777291637120372


Train loss: 0.5293444991111755 at step: 344
Iter time:  0.2777230524739554


Train loss: 0.424535870552063 at step: 345
Iter time:  0.27771738232045934


Train loss: 0.5212094187736511 at step: 346
Iter time:  0.2777189981041616


Train loss: 0.50612473487854 at step: 347
Iter time:  0.27770924843010364


Train loss: 0.5114591121673584 at step: 348
Iter time:  0.27771512804360227


Train loss: 0.4170758128166199 at step: 349
Iter time:  0.27771943688051065


Train loss: 0.5220818519592285 at step: 350
Iter time:  0.2777104752404349


Train loss: 0.5101057291030884 at step: 351
Iter time:  0.2777023641472189


Train loss: 0.47345882654190063 at step: 352
Iter time:  0.2776934267445044


Train loss: 0.4597293734550476 at step: 353
Iter time:  0.27768770628542805


Train loss: 0.44806182384490967 at step: 354
Iter time:  0.2776806913526718


Train loss: 0.515403687953949 at step: 355
Iter time:  0.27768043061377295


Train loss: 0.3483628034591675 at step: 356
Iter time:  0.27768076939529246


Train loss: 0.3994739055633545 at step: 357
Iter time:  0.2776739917883352


Train loss: 0.49875709414482117 at step: 358
Iter time:  0.27766386623489125


Train loss: 0.32657861709594727 at step: 359
Iter time:  0.2776554839524718


Train loss: 0.4343230128288269 at step: 360
Iter time:  0.27766464286380343


Train loss: 0.47297656536102295 at step: 361
Iter time:  0.2776672192887916


Train loss: 0.3858984410762787 at step: 362
Iter time:  0.27765547965771586


Train loss: 0.4342239499092102 at step: 363
Iter time:  0.2776599455799281


Train loss: 0.48519617319107056 at step: 364
Iter time:  0.2776562833524012


Train loss: 0.3290509581565857 at step: 365
Iter time:  0.27764904858314826


Train loss: 0.4661828279495239 at step: 366
Iter time:  0.27764390596275124


Train loss: 0.4788888394832611 at step: 367
Iter time:  0.27764064674481387


Train loss: 0.42717456817626953 at step: 368
Iter time:  0.2776361768660338


Train loss: 0.4464389979839325 at step: 369
Iter time:  0.27762644206928366


Train loss: 0.27714216709136963 at step: 370
Iter time:  0.2776200545800699


Train loss: 0.49162325263023376 at step: 371
Iter time:  0.2776251732499773


Train loss: 0.5553358793258667 at step: 372
Iter time:  0.27761651495451567


Train loss: 0.5283626317977905 at step: 373
Iter time:  0.27760668286689166


Train loss: 0.5376318693161011 at step: 374
Iter time:  0.2776003648890531


Train loss: 0.4036332964897156 at step: 375
Iter time:  0.27759260559082033


Found 2923 trainable_data in total.
