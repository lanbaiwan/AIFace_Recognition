Model loaded..
Use LinearProbe head: pretrained_weights/10_12.pth
Choose layer: 23 for cls embedding
Not add Gaussian noise to the feature embedding.
Not use random erasing.
data mode: ours
[{'data_path': '/home/data/szk/face_B', 'data_mode': 'ours'}]
total_list_len: 6000
Fix the backbone.
Length of dataset: 375
Directory ./TTO_checkpoints/2024-10-12-22-21-42 is created.
Train loss: 0.5434553027153015 at step: 1
Iter time:  1.1590888500213623


Train loss: 0.5223302841186523 at step: 2
Iter time:  0.7134524583816528


Train loss: 0.42262518405914307 at step: 3
Iter time:  0.5657082398732504


Train loss: 0.44155198335647583 at step: 4
Iter time:  0.4909641146659851


Train loss: 0.43260908126831055 at step: 5
Iter time:  0.44624619483947753


Train loss: 0.5517924427986145 at step: 6
Iter time:  0.4166791041692098


Train loss: 0.5246156454086304 at step: 7
Iter time:  0.39526540892464773


Train loss: 0.4140448272228241 at step: 8
Iter time:  0.378965824842453


Train loss: 0.46548959612846375 at step: 9
Iter time:  0.3664866023593479


Train loss: 0.5573806166648865 at step: 10
Iter time:  0.3564746618270874


Train loss: 0.44207483530044556 at step: 11
Iter time:  0.348351543599909


Train loss: 0.5348255634307861 at step: 12
Iter time:  0.3415234287579854


Train loss: 0.4990323483943939 at step: 13
Iter time:  0.3357384388263409


Train loss: 0.4469945430755615 at step: 14
Iter time:  0.3307961736406599


Train loss: 0.5080891251564026 at step: 15
Iter time:  0.326530917485555


Train loss: 0.5667803287506104 at step: 16
Iter time:  0.3229071646928787


Train loss: 0.35638105869293213 at step: 17
Iter time:  0.3195832757388844


Train loss: 0.3774998188018799 at step: 18
Iter time:  0.31666408644782174


Train loss: 0.4979207217693329 at step: 19
Iter time:  0.31410315162257146


Train loss: 0.4235667288303375 at step: 20
Iter time:  0.3117940425872803


Train loss: 0.43988892436027527 at step: 21
Iter time:  0.3097874437059675


Train loss: 0.43179088830947876 at step: 22
Iter time:  0.30790214105085895


Train loss: 0.40687644481658936 at step: 23
Iter time:  0.30613773802052374


Train loss: 0.44349297881126404 at step: 24
Iter time:  0.3045859436194102


Train loss: 0.3547120988368988 at step: 25
Iter time:  0.303132963180542


Train loss: 0.49843406677246094 at step: 26
Iter time:  0.3018445876928476


Train loss: 0.44490692019462585 at step: 27
Iter time:  0.30057869134125886


Train loss: 0.4508685767650604 at step: 28
Iter time:  0.29944537367139545


Train loss: 0.46782758831977844 at step: 29
Iter time:  0.2983724988740066


Train loss: 0.49085843563079834 at step: 30
Iter time:  0.2973959525426229


Train loss: 0.5074938535690308 at step: 31
Iter time:  0.2965406294791929


Train loss: 0.4128071665763855 at step: 32
Iter time:  0.2956457883119583


Train loss: 0.41294699907302856 at step: 33
Iter time:  0.2948334433815696


Train loss: 0.5169329047203064 at step: 34
Iter time:  0.2940672565908993


Train loss: 0.47444549202919006 at step: 35
Iter time:  0.2933602264949254


Train loss: 0.4032163619995117 at step: 36
Iter time:  0.292684190803104


Train loss: 0.4273366332054138 at step: 37
Iter time:  0.2920593119956352


Train loss: 0.4463224411010742 at step: 38
Iter time:  0.291435768729762


Train loss: 0.5056914687156677 at step: 39
Iter time:  0.2908578652601976


Train loss: 0.4164983928203583 at step: 40
Iter time:  0.29031400084495546


Train loss: 0.3631212115287781 at step: 41
Iter time:  0.2897899674206245


Train loss: 0.47513729333877563 at step: 42
Iter time:  0.28928113551366896


Train loss: 0.4353038966655731 at step: 43
Iter time:  0.28877229468767035


Train loss: 0.49425816535949707 at step: 44
Iter time:  0.2882799506187439


Train loss: 0.45340144634246826 at step: 45
Iter time:  0.28783126407199433


Train loss: 0.5230007767677307 at step: 46
Iter time:  0.2874229213465815


Train loss: 0.36011791229248047 at step: 47
Iter time:  0.28699707984924316


Train loss: 0.25489866733551025 at step: 48
Iter time:  0.28658801813920337


Train loss: 0.3565882444381714 at step: 49
Iter time:  0.2861930496838628


Train loss: 0.4406503140926361 at step: 50
Iter time:  0.28580822944641116


Train loss: 0.34738194942474365 at step: 51
Iter time:  0.28546976575664446


Train loss: 0.3681149482727051 at step: 52
Iter time:  0.28512213780329776


Train loss: 0.42965197563171387 at step: 53
Iter time:  0.28479424512611246


Train loss: 0.4311380982398987 at step: 54
Iter time:  0.2844831148783366


Train loss: 0.407707154750824 at step: 55
Iter time:  0.28417910662564366


Train loss: 0.36886265873908997 at step: 56
Iter time:  0.28392450724329266


Train loss: 0.3973614573478699 at step: 57
Iter time:  0.2836515568850333


Train loss: 0.3572869896888733 at step: 58
Iter time:  0.28344139148449077


Train loss: 0.5333399176597595 at step: 59
Iter time:  0.28318222902588924


Train loss: 0.28883129358291626 at step: 60
Iter time:  0.2829404910405477


Train loss: 0.36382466554641724 at step: 61
Iter time:  0.2828454345953269


Train loss: 0.5857991576194763 at step: 62
Iter time:  0.2826037291557558


Train loss: 0.2813486158847809 at step: 63
Iter time:  0.28236913681030273


Train loss: 0.35562941431999207 at step: 64
Iter time:  0.2821447215974331


Train loss: 0.39122474193573 at step: 65
Iter time:  0.2819337954887977


Train loss: 0.47622165083885193 at step: 66
Iter time:  0.28173498673872516


Train loss: 0.3361141085624695 at step: 67
Iter time:  0.28153840107704275


Train loss: 0.3571796715259552 at step: 68
Iter time:  0.2813392211409176


Train loss: 0.41081875562667847 at step: 69
Iter time:  0.2811462464539901


Train loss: 0.3903687596321106 at step: 70
Iter time:  0.2809842722756522


Train loss: 0.3344259262084961 at step: 71
Iter time:  0.28080531576989404


Train loss: 0.39078009128570557 at step: 72
Iter time:  0.28063109185960555


Train loss: 0.4253785312175751 at step: 73
Iter time:  0.2804605634245154


Train loss: 0.30766937136650085 at step: 74
Iter time:  0.28035152925027385


Train loss: 0.2756229043006897 at step: 75
Iter time:  0.2802089786529541


Train loss: 0.4316958785057068 at step: 76
Iter time:  0.2800611414407429


Train loss: 0.3936235308647156 at step: 77
Iter time:  0.27992495004232826


Train loss: 0.4152352511882782 at step: 78
Iter time:  0.2797823808132074


Train loss: 0.3502463102340698 at step: 79
Iter time:  0.27964343300348593


Train loss: 0.4043751657009125 at step: 80
Iter time:  0.2795261353254318


Train loss: 0.2590544819831848 at step: 81
Iter time:  0.27939608656329873


Train loss: 0.34041303396224976 at step: 82
Iter time:  0.279271794528496


Train loss: 0.38027051091194153 at step: 83
Iter time:  0.2791523761059864


Train loss: 0.3099384903907776 at step: 84
Iter time:  0.27904858191808063


Train loss: 0.41200491786003113 at step: 85
Iter time:  0.2789349780363195


Train loss: 0.42053714394569397 at step: 86
Iter time:  0.27881650314774625


Train loss: 0.47475466132164 at step: 87
Iter time:  0.2787009272082099


Train loss: 0.27757441997528076 at step: 88
Iter time:  0.2785880782387473


Train loss: 0.3398491144180298 at step: 89
Iter time:  0.2784961341472154


Train loss: 0.36969614028930664 at step: 90
Iter time:  0.27838798893822564


Train loss: 0.4128352403640747 at step: 91
Iter time:  0.2782839549766792


Train loss: 0.34616124629974365 at step: 92
Iter time:  0.27819186449050903


Train loss: 0.352189838886261 at step: 93
Iter time:  0.27809389944999446


Train loss: 0.3193100690841675 at step: 94
Iter time:  0.2779991829648931


Train loss: 0.29337844252586365 at step: 95
Iter time:  0.2779104132401316


Train loss: 0.15059641003608704 at step: 96
Iter time:  0.2778177286187808


Train loss: 0.3793807029724121 at step: 97
Iter time:  0.27773149726317103


Train loss: 0.6025314331054688 at step: 98
Iter time:  0.27765296186719624


Train loss: 0.28221333026885986 at step: 99
Iter time:  0.27760794186832927


Train loss: 0.12854278087615967 at step: 100
Iter time:  0.2775281548500061


Train loss: 0.2714952230453491 at step: 101
Iter time:  0.277448307169546


Train loss: 0.14927053451538086 at step: 102
Iter time:  0.2773751371047076


Train loss: 0.31610849499702454 at step: 103
Iter time:  0.2772971750463097


Train loss: 0.33806443214416504 at step: 104
Iter time:  0.27724648668215823


Train loss: 0.30010297894477844 at step: 105
Iter time:  0.27717111451285226


Train loss: 0.21651306748390198 at step: 106
Iter time:  0.2771048118483345


Train loss: 0.3188733756542206 at step: 107
Iter time:  0.2770360942198851


Train loss: 0.4489961564540863 at step: 108
Iter time:  0.2769744042997007


Train loss: 0.42016351222991943 at step: 109
Iter time:  0.27691878310037316


Train loss: 0.2153220772743225 at step: 110
Iter time:  0.27684988975524905


Train loss: 0.35465681552886963 at step: 111
Iter time:  0.27678685789709695


Train loss: 0.25041455030441284 at step: 112
Iter time:  0.27672453011785236


Train loss: 0.2959599196910858 at step: 113
Iter time:  0.27666881232135065


Train loss: 0.247090682387352 at step: 114
Iter time:  0.2766187065526059


Train loss: 0.2518283724784851 at step: 115
Iter time:  0.2765625062196151


Train loss: 0.34473466873168945 at step: 116
Iter time:  0.2765084011801358


Train loss: 0.35821300745010376 at step: 117
Iter time:  0.2764580698094816


Train loss: 0.42938676476478577 at step: 118
Iter time:  0.27641478837546657


Train loss: 0.2493562251329422 at step: 119
Iter time:  0.2763603174385904


Train loss: 0.26379308104515076 at step: 120
Iter time:  0.2763102869192759


Train loss: 0.3707332909107208 at step: 121
Iter time:  0.2762589651691027


Train loss: 0.27521783113479614 at step: 122
Iter time:  0.27620935049213347


Train loss: 0.37850430607795715 at step: 123
Iter time:  0.27616971488890607


Train loss: 0.4182146489620209 at step: 124
Iter time:  0.27612964953145674


Train loss: 0.2007349133491516 at step: 125
Iter time:  0.2760862808227539


Train loss: 0.3259904384613037 at step: 126
Iter time:  0.2760425030239045


Train loss: 0.37305158376693726 at step: 127
Iter time:  0.2759954497570128


Train loss: 0.38974788784980774 at step: 128
Iter time:  0.2759617995470762


Train loss: 0.28504008054733276 at step: 129
Iter time:  0.2759182009586068


Train loss: 0.3466935157775879 at step: 130
Iter time:  0.2758751704142644


Train loss: 0.2922896444797516 at step: 131
Iter time:  0.2758330734631487


Train loss: 0.38682830333709717 at step: 132
Iter time:  0.2757908683834654


Train loss: 0.42509278655052185 at step: 133
Iter time:  0.27575967903424026


Train loss: 0.26145580410957336 at step: 134
Iter time:  0.27571708052905636


Train loss: 0.39465850591659546 at step: 135
Iter time:  0.275680633827492


Train loss: 0.2144104540348053 at step: 136
Iter time:  0.27564287360976725


Train loss: 0.27979373931884766 at step: 137
Iter time:  0.27561284503797545


Train loss: 0.1980513334274292 at step: 138
Iter time:  0.275588225627291


Train loss: 0.22505490481853485 at step: 139
Iter time:  0.27555960373912786


Train loss: 0.19224855303764343 at step: 140
Iter time:  0.2755269152777536


Train loss: 0.36478662490844727 at step: 141
Iter time:  0.27549496441022725


Train loss: 0.31064730882644653 at step: 142
Iter time:  0.27546667045270895


Train loss: 0.24897262454032898 at step: 143
Iter time:  0.2754307043302309


Train loss: 0.2859784960746765 at step: 144
Iter time:  0.27539652917120194


Train loss: 0.18470321595668793 at step: 145
Iter time:  0.27536443184162007


Train loss: 0.16817380487918854 at step: 146
Iter time:  0.27533802594224066


Train loss: 0.20001251995563507 at step: 147
Iter time:  0.27531853825056635


Train loss: 0.19428539276123047 at step: 148
Iter time:  0.2752904247593235


Train loss: 0.30564266443252563 at step: 149
Iter time:  0.27526423275070705


Train loss: 0.1791936755180359 at step: 150
Iter time:  0.27523924350738527


Train loss: 0.293379545211792 at step: 151
Iter time:  0.2752157962874861


Train loss: 0.2668989300727844 at step: 152
Iter time:  0.2752054851306112


Train loss: 0.14266696572303772 at step: 153
Iter time:  0.27517878152186576


Train loss: 0.31937751173973083 at step: 154
Iter time:  0.2751533458759258


Train loss: 0.19892442226409912 at step: 155
Iter time:  0.2751268756005072


Train loss: 0.17190733551979065 at step: 156
Iter time:  0.2751066302641844


Train loss: 0.18602518737316132 at step: 157
Iter time:  0.27509471717154144


Train loss: 0.3265983760356903 at step: 158
Iter time:  0.27507332759567454


Train loss: 0.22711661458015442 at step: 159
Iter time:  0.27504914361725813


Train loss: 0.2280622124671936 at step: 160
Iter time:  0.27502569556236267


Train loss: 0.29015642404556274 at step: 161
Iter time:  0.27500544127470217


Train loss: 0.11715271323919296 at step: 162
Iter time:  0.27498662030255355


Train loss: 0.27215588092803955 at step: 163
Iter time:  0.27496439401357453


Train loss: 0.18484532833099365 at step: 164
Iter time:  0.27494368902066857


Train loss: 0.3212999105453491 at step: 165
Iter time:  0.2749361500595555


Train loss: 0.23996801674365997 at step: 166
Iter time:  0.27491955872041635


Train loss: 0.25136345624923706 at step: 167
Iter time:  0.27489692579486413


Train loss: 0.23181922733783722 at step: 168
Iter time:  0.2748771451768421


Train loss: 0.35080188512802124 at step: 169
Iter time:  0.2748591645934878


Train loss: 0.20105496048927307 at step: 170
Iter time:  0.27484114731059356


Train loss: 0.2635345757007599 at step: 171
Iter time:  0.27482769363804865


Train loss: 0.21525785326957703 at step: 172
Iter time:  0.2748097014981647


Train loss: 0.23414203524589539 at step: 173
Iter time:  0.27479323348558016


Train loss: 0.12383654713630676 at step: 174
Iter time:  0.27477593531553773


Train loss: 0.37210333347320557 at step: 175
Iter time:  0.2747597735268729


Train loss: 0.16451266407966614 at step: 176
Iter time:  0.27475604685870086


Train loss: 0.29595068097114563 at step: 177
Iter time:  0.27474082930613375


Train loss: 0.3109506368637085 at step: 178
Iter time:  0.27472421292508586


Train loss: 0.1651543378829956 at step: 179
Iter time:  0.27470860934124314


Train loss: 0.11188802123069763 at step: 180
Iter time:  0.27469333277808294


Train loss: 0.20704734325408936 at step: 181
Iter time:  0.2746810860396749


Train loss: 0.2767966389656067 at step: 182
Iter time:  0.27466452776730715


Train loss: 0.22471626102924347 at step: 183
Iter time:  0.27465152870761894


Train loss: 0.18387044966220856 at step: 184
Iter time:  0.27463815134504566


Train loss: 0.15882441401481628 at step: 185
Iter time:  0.2746250784074938


Train loss: 0.16814947128295898 at step: 186
Iter time:  0.2746165939556655


Train loss: 0.26749470829963684 at step: 187
Iter time:  0.2746162350802498


Train loss: 0.21715094149112701 at step: 188
Iter time:  0.27460812380973326


Train loss: 0.0950237438082695 at step: 189
Iter time:  0.27460090571610385


Train loss: 0.35615748167037964 at step: 190
Iter time:  0.2745946946897005


Train loss: 0.1818181276321411 at step: 191
Iter time:  0.274593289609979


Train loss: 0.08302663266658783 at step: 192
Iter time:  0.27458631868163746


Train loss: 0.2719506621360779 at step: 193
Iter time:  0.27458209694976016


Train loss: 0.15264403820037842 at step: 194
Iter time:  0.2745783304430775


Train loss: 0.34868037700653076 at step: 195
Iter time:  0.27457778025896123


Train loss: 0.2694951891899109 at step: 196
Iter time:  0.27457081420081003


Train loss: 0.17431935667991638 at step: 197
Iter time:  0.27456938070694203


Train loss: 0.16126158833503723 at step: 198
Iter time:  0.27456884793560915


Train loss: 0.24982047080993652 at step: 199
Iter time:  0.27456598186013687


Train loss: 0.12311664968729019 at step: 200
Iter time:  0.27456470966339114


Train loss: 0.13604211807250977 at step: 201
Iter time:  0.2745607646543588


Train loss: 0.1447247415781021 at step: 202
Iter time:  0.27454575099567374


Train loss: 0.22455623745918274 at step: 203
Iter time:  0.27453313555036274


Train loss: 0.12672972679138184 at step: 204
Iter time:  0.2745242399327895


Train loss: 0.2235916256904602 at step: 205
Iter time:  0.27451212696912813


Train loss: 0.07514221221208572 at step: 206
Iter time:  0.2745010065800935


Train loss: 0.23279133439064026 at step: 207
Iter time:  0.2744893371195033


Train loss: 0.16154450178146362 at step: 208
Iter time:  0.2744780056751691


Train loss: 0.17875415086746216 at step: 209
Iter time:  0.27446620430102187


Train loss: 0.22080720961093903 at step: 210
Iter time:  0.27446038041796


Train loss: 0.15754267573356628 at step: 211
Iter time:  0.2744488942114663


Train loss: 0.0824136883020401 at step: 212
Iter time:  0.2744378076409394


Train loss: 0.1896248161792755 at step: 213
Iter time:  0.27442762549494354


Train loss: 0.18735098838806152 at step: 214
Iter time:  0.27441670738648033


Train loss: 0.21674826741218567 at step: 215
Iter time:  0.2744247259095658


Train loss: 0.17885717749595642 at step: 216
Iter time:  0.2744137092872902


Train loss: 0.14840076863765717 at step: 217
Iter time:  0.274401124171947


Train loss: 0.11304689198732376 at step: 218
Iter time:  0.27439053671075664


Train loss: 0.11504227668046951 at step: 219
Iter time:  0.27438061313542056


Train loss: 0.20017316937446594 at step: 220
Iter time:  0.2743755979971452


Train loss: 0.2375660389661789 at step: 221
Iter time:  0.27436359543606165


Train loss: 0.1429830938577652 at step: 222
Iter time:  0.2743520446725794


Train loss: 0.11017781496047974 at step: 223
Iter time:  0.27434139080646325


Train loss: 0.11432366073131561 at step: 224
Iter time:  0.2743307224341801


Train loss: 0.1509498804807663 at step: 225
Iter time:  0.2743219545152452


Train loss: 0.06262040883302689 at step: 226
Iter time:  0.27431176299542454


Train loss: 0.15563759207725525 at step: 227
Iter time:  0.27430447292748


Train loss: 0.27080392837524414 at step: 228
Iter time:  0.2742936642546403


Train loss: 0.18066230416297913 at step: 229
Iter time:  0.27428327689524823


Train loss: 0.14875656366348267 at step: 230
Iter time:  0.2742745057396267


Train loss: 0.11622980237007141 at step: 231
Iter time:  0.27426582600647237


Train loss: 0.18965651094913483 at step: 232
Iter time:  0.27425565493517906


Train loss: 0.07955750823020935 at step: 233
Iter time:  0.2742465831691103


Train loss: 0.12705641984939575 at step: 234
Iter time:  0.27423752271212065


Train loss: 0.11247088760137558 at step: 235
Iter time:  0.274232047669431


Train loss: 0.17384469509124756 at step: 236
Iter time:  0.27422279523590865


Train loss: 0.29661011695861816 at step: 237
Iter time:  0.27421230706484506


Train loss: 0.10479753464460373 at step: 238
Iter time:  0.2742013791028191


Train loss: 0.15348894894123077 at step: 239
Iter time:  0.2741933307887121


Train loss: 0.07714115083217621 at step: 240
Iter time:  0.2741880754629771


Train loss: 0.08099536597728729 at step: 241
Iter time:  0.2741767806136262


Train loss: 0.2362930327653885 at step: 242
Iter time:  0.27416769926213036


Train loss: 0.18018832802772522 at step: 243
Iter time:  0.2741583266866551


Train loss: 0.12716199457645416 at step: 244
Iter time:  0.27414933677579534


Train loss: 0.15481284260749817 at step: 245
Iter time:  0.27414300101143974


Train loss: 0.10568762570619583 at step: 246
Iter time:  0.27413360762402295


Train loss: 0.07643347978591919 at step: 247
Iter time:  0.27412447948687474


Train loss: 0.21054618060588837 at step: 248
Iter time:  0.27411780145860487


Train loss: 0.22772878408432007 at step: 249
Iter time:  0.27410993039847376


Train loss: 0.06838767975568771 at step: 250
Iter time:  0.2741039524078369


Train loss: 0.13404089212417603 at step: 251
Iter time:  0.2740972792484846


Train loss: 0.10720111429691315 at step: 252
Iter time:  0.2740890544558328


Train loss: 0.13735046982765198 at step: 253
Iter time:  0.27408232142331573


Train loss: 0.1453440636396408 at step: 254
Iter time:  0.27407421464995135


Train loss: 0.07653123140335083 at step: 255
Iter time:  0.2740683882844214


Train loss: 0.12525923550128937 at step: 256
Iter time:  0.27406299766153097


Train loss: 0.11909376829862595 at step: 257
Iter time:  0.2740547888937627


Train loss: 0.1268097460269928 at step: 258
Iter time:  0.27404702541440035


Train loss: 0.09834226965904236 at step: 259
Iter time:  0.27404397058671043


Train loss: 0.05350199714303017 at step: 260
Iter time:  0.2740356784600478


Train loss: 0.07058589905500412 at step: 261
Iter time:  0.27402556170905684


Train loss: 0.12179230898618698 at step: 262
Iter time:  0.27401862617667394


Train loss: 0.0921536237001419 at step: 263
Iter time:  0.2740178062888606


Train loss: 0.06616787612438202 at step: 264
Iter time:  0.27401116038813733


Train loss: 0.05677526444196701 at step: 265
Iter time:  0.2740028093445976


Train loss: 0.10440243780612946 at step: 266
Iter time:  0.27399688376519915


Train loss: 0.07300850003957748 at step: 267
Iter time:  0.2739920000012001


Train loss: 0.14650960266590118 at step: 268
Iter time:  0.2739830355146038


Train loss: 0.10853525996208191 at step: 269
Iter time:  0.2739750886938386


Train loss: 0.14045430719852448 at step: 270
Iter time:  0.2739717174459387


Train loss: 0.12545834481716156 at step: 271
Iter time:  0.2739652338063145


Train loss: 0.09944068640470505 at step: 272
Iter time:  0.27395933866500854


Train loss: 0.10632932186126709 at step: 273
Iter time:  0.2739517121087937


Train loss: 0.05050421878695488 at step: 274
Iter time:  0.27394672205848414


Train loss: 0.04300597310066223 at step: 275
Iter time:  0.27393846771933816


Train loss: 0.06218415126204491 at step: 276
Iter time:  0.2739326807035916


Train loss: 0.034401968121528625 at step: 277
Iter time:  0.2739273718548165


Train loss: 0.04007861390709877 at step: 278
Iter time:  0.273922733265719


Train loss: 0.0977439135313034 at step: 279
Iter time:  0.2739164803617744


Train loss: 0.033162377774715424 at step: 280
Iter time:  0.2739095764500754


Train loss: 0.0814957320690155 at step: 281
Iter time:  0.2739054376120245


Train loss: 0.07346968352794647 at step: 282
Iter time:  0.2738999145250794


Train loss: 0.14958706498146057 at step: 283
Iter time:  0.273896941869082


Train loss: 0.07946697622537613 at step: 284
Iter time:  0.2738929676337981


Train loss: 0.13622689247131348 at step: 285
Iter time:  0.2738866864589223


Train loss: 0.1148088276386261 at step: 286
Iter time:  0.2738822957018872


Train loss: 0.04968647286295891 at step: 287
Iter time:  0.2738767966160791


Train loss: 0.08416035026311874 at step: 288
Iter time:  0.2738727471894688


Train loss: 0.08991682529449463 at step: 289
Iter time:  0.2738681887260358


Train loss: 0.1449701189994812 at step: 290
Iter time:  0.27386390834019103


Train loss: 0.04668940603733063 at step: 291
Iter time:  0.273857759036559


Train loss: 0.10821601003408432 at step: 292
Iter time:  0.2738534114132189


Train loss: 0.17566385865211487 at step: 293
Iter time:  0.27385124492970747


Train loss: 0.12895555794239044 at step: 294
Iter time:  0.27384592805589947


Train loss: 0.11507175117731094 at step: 295
Iter time:  0.27384139238777805


Train loss: 0.0315573513507843 at step: 296
Iter time:  0.27383506620252457


Train loss: 0.018031049519777298 at step: 297
Iter time:  0.27383177529280434


Train loss: 0.036987803876399994 at step: 298
Iter time:  0.27382851847066175


Train loss: 0.10299375653266907 at step: 299
Iter time:  0.27382364400653136


Train loss: 0.06606143712997437 at step: 300
Iter time:  0.2738172777493795


Train loss: 0.05546495318412781 at step: 301
Iter time:  0.2738139066981319


Train loss: 0.03031323105096817 at step: 302
Iter time:  0.27381124006991353


Train loss: 0.021172640845179558 at step: 303
Iter time:  0.2738131304385245


Train loss: 0.11001640558242798 at step: 304
Iter time:  0.2738117222723208


Train loss: 0.009347759187221527 at step: 305
Iter time:  0.27381053596246435


Train loss: 0.15097008645534515 at step: 306
Iter time:  0.27380870759876724


Train loss: 0.08969617635011673 at step: 307
Iter time:  0.2738074875809859


Train loss: 0.043773699551820755 at step: 308
Iter time:  0.2738089066047173


Train loss: 0.034521959722042084 at step: 309
Iter time:  0.2738088936481661


Train loss: 0.0846518725156784 at step: 310
Iter time:  0.2738073472053774


Train loss: 0.03962453082203865 at step: 311
Iter time:  0.2738075501665808


Train loss: 0.11921049654483795 at step: 312
Iter time:  0.2738089378063495


Train loss: 0.08527237176895142 at step: 313
Iter time:  0.2738100111294097


Train loss: 0.03197371959686279 at step: 314
Iter time:  0.2738071437094622


Train loss: 0.08495102822780609 at step: 315
Iter time:  0.2738066665709965


Train loss: 0.04564807936549187 at step: 316
Iter time:  0.27380809301062475


Train loss: 0.06313023716211319 at step: 317
Iter time:  0.2738102851229887


Train loss: 0.07307862490415573 at step: 318
Iter time:  0.2738085055501206


Train loss: 0.020257730036973953 at step: 319
Iter time:  0.27380741427310956


Train loss: 0.08653345704078674 at step: 320
Iter time:  0.27380712032318116


Train loss: 0.07709701359272003 at step: 321
Iter time:  0.27380529593827196


Train loss: 0.14610159397125244 at step: 322
Iter time:  0.27380781514304026


Train loss: 0.04832470044493675 at step: 323
Iter time:  0.2738070635603677


Train loss: 0.08053405582904816 at step: 324
Iter time:  0.27380632765499163


Train loss: 0.14817315340042114 at step: 325
Iter time:  0.27380678837115946


Train loss: 0.04673750698566437 at step: 326
Iter time:  0.2738054998081886


Train loss: 0.052576709538698196 at step: 327
Iter time:  0.27380468356864535


Train loss: 0.03885260224342346 at step: 328
Iter time:  0.27380651453646215


Train loss: 0.09306025505065918 at step: 329
Iter time:  0.2738054581326192


Train loss: 0.04052535071969032 at step: 330
Iter time:  0.27380587693416714


Train loss: 0.08761750906705856 at step: 331
Iter time:  0.2738044989433173


Train loss: 0.05783204734325409 at step: 332
Iter time:  0.2738056829176753


Train loss: 0.05746770650148392 at step: 333
Iter time:  0.2738057042027379


Train loss: 0.046260371804237366 at step: 334
Iter time:  0.27380763699194627


Train loss: 0.08506941050291061 at step: 335
Iter time:  0.27380747723935256


Train loss: 0.08924265950918198 at step: 336
Iter time:  0.27380620156015667


Train loss: 0.05926911532878876 at step: 337
Iter time:  0.273805747046315


Train loss: 0.02917255088686943 at step: 338
Iter time:  0.27380524725603633


Train loss: 0.03305305168032646 at step: 339
Iter time:  0.27380629556368935


Train loss: 0.0412215031683445 at step: 340
Iter time:  0.2738082563175875


Train loss: 0.03832816705107689 at step: 341
Iter time:  0.27380871423178754


Train loss: 0.014389749616384506 at step: 342
Iter time:  0.2738079453072353


Train loss: 0.03155219182372093 at step: 343
Iter time:  0.27380878098156985


Train loss: 0.03406821936368942 at step: 344
Iter time:  0.27380826445512996


Train loss: 0.05133778229355812 at step: 345
Iter time:  0.27380966380022576


Train loss: 0.06847819685935974 at step: 346
Iter time:  0.27381015444077506


Train loss: 0.0369001105427742 at step: 347
Iter time:  0.27380855557554395


Train loss: 0.06591323018074036 at step: 348
Iter time:  0.2738102304524389


Train loss: 0.02855123020708561 at step: 349
Iter time:  0.2738096140175631


Train loss: 0.01485125720500946 at step: 350
Iter time:  0.2738115508215768


Train loss: 0.026934638619422913 at step: 351
Iter time:  0.2738138841427969


Train loss: 0.0320730060338974 at step: 352
Iter time:  0.27381506765430624


Train loss: 0.035136085003614426 at step: 353
Iter time:  0.2738151347670947


Train loss: 0.03575107082724571 at step: 354
Iter time:  0.2738166475026621


Train loss: 0.07387269288301468 at step: 355
Iter time:  0.2738183384210291


Train loss: 0.035294726490974426 at step: 356
Iter time:  0.2738208958272184


Train loss: 0.02550971880555153 at step: 357
Iter time:  0.27382467774783864


Train loss: 0.02484985440969467 at step: 358
Iter time:  0.2738248043220136


Train loss: 0.023779500275850296 at step: 359
Iter time:  0.2738247528713726


Train loss: 0.08631531894207001 at step: 360
Iter time:  0.2738269183370802


Train loss: 0.01706043630838394 at step: 361
Iter time:  0.2738302942788502


Train loss: 0.036466628313064575 at step: 362
Iter time:  0.27382953654336667


Train loss: 0.033837951719760895 at step: 363
Iter time:  0.2738302417366301


Train loss: 0.028972279280424118 at step: 364
Iter time:  0.27382973524240345


Train loss: 0.1314631998538971 at step: 365
Iter time:  0.27383003561464075


Train loss: 0.025511398911476135 at step: 366
Iter time:  0.27383251138072195


Train loss: 0.025699404999613762 at step: 367
Iter time:  0.2738320132367293


Train loss: 0.047243088483810425 at step: 368
Iter time:  0.2738302427789439


Train loss: 0.039357349276542664 at step: 369
Iter time:  0.27383134229396416


Train loss: 0.11261976510286331 at step: 370
Iter time:  0.2738318005123654


Train loss: 0.02230720967054367 at step: 371
Iter time:  0.27383397981484303


Train loss: 0.02745305746793747 at step: 372
Iter time:  0.27383388626960015


Train loss: 0.01972053200006485 at step: 373
Iter time:  0.27383389997098784


Train loss: 0.0298630278557539 at step: 374
Iter time:  0.27383463650463735


Train loss: 0.08493383973836899 at step: 375
Iter time:  0.273834592183431


Found 4699 trainable_data in total.
