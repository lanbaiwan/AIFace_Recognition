Model loaded..
Use LinearProbe head: pretrained_weights/10_1_TTO_copy.pth
Choose layer: 23 for cls embedding
Not add Gaussian noise to the feature embedding.
Not use random erasing.
data mode: ours
[{'data_path': '/home/data/szk/face/face', 'data_mode': 'ours'}]
total_list_len: 6000
Fix the backbone.
Length of dataset: 375
Directory ./TTO_checkpoints/2024-10-01-21-58-49 is created.
Train loss: 0.04592341184616089 at step: 1
Iter time:  1.0116426944732666


Train loss: 0.09027931094169617 at step: 2
Iter time:  0.6425869464874268


Train loss: 0.011892621405422688 at step: 3
Iter time:  0.517744223276774


Train loss: 0.0840841680765152 at step: 4
Iter time:  0.4550020098686218


Train loss: 0.025045398622751236 at step: 5
Iter time:  0.4178787708282471


Train loss: 0.08736251294612885 at step: 6
Iter time:  0.3927786747614543


Train loss: 0.11827947944402695 at step: 7
Iter time:  0.37492755481175016


Train loss: 0.1153397411108017 at step: 8
Iter time:  0.36173704266548157


Train loss: 0.18015071749687195 at step: 9
Iter time:  0.3513956599765354


Train loss: 0.06279151886701584 at step: 10
Iter time:  0.34310598373413087


Train loss: 0.07895004004240036 at step: 11
Iter time:  0.33628370545127173


Train loss: 0.03824204206466675 at step: 12
Iter time:  0.33066389958063763


Train loss: 0.011902587488293648 at step: 13
Iter time:  0.3259579585148738


Train loss: 0.08750062435865402 at step: 14
Iter time:  0.3219002825873239


Train loss: 0.11483331024646759 at step: 15
Iter time:  0.31834565798441566


Train loss: 0.07948023080825806 at step: 16
Iter time:  0.31520576775074005


Train loss: 0.028331242501735687 at step: 17
Iter time:  0.31249523162841797


Train loss: 0.020472712814807892 at step: 18
Iter time:  0.31006227599249947


Train loss: 0.023732826113700867 at step: 19
Iter time:  0.30784608188428375


Train loss: 0.14836817979812622 at step: 20
Iter time:  0.3058883547782898


Train loss: 0.09545908868312836 at step: 21
Iter time:  0.3040947459992908


Train loss: 0.06545070558786392 at step: 22
Iter time:  0.3024721254001964


Train loss: 0.12205703556537628 at step: 23
Iter time:  0.300984061282614


Train loss: 0.06456564366817474 at step: 24
Iter time:  0.2996316154797872


Train loss: 0.1392531394958496 at step: 25
Iter time:  0.29843615531921386


Train loss: 0.03729061037302017 at step: 26
Iter time:  0.29733097553253174


Train loss: 0.1496739238500595 at step: 27
Iter time:  0.29631065439294885


Train loss: 0.06742632389068604 at step: 28
Iter time:  0.2953567590032305


Train loss: 0.09403710812330246 at step: 29
Iter time:  0.2944606254840719


Train loss: 0.04060724377632141 at step: 30
Iter time:  0.29363503456115725


Train loss: 0.07931697368621826 at step: 31
Iter time:  0.29285154035014493


Train loss: 0.07959228754043579 at step: 32
Iter time:  0.2921278327703476


Train loss: 0.03894888609647751 at step: 33
Iter time:  0.2915444229588364


Train loss: 0.012797126546502113 at step: 34
Iter time:  0.2908947888542624


Train loss: 0.11490796506404877 at step: 35
Iter time:  0.2902852330889021


Train loss: 0.07066062092781067 at step: 36
Iter time:  0.2897251380814446


Train loss: 0.03722745552659035 at step: 37
Iter time:  0.28919172286987305


Train loss: 0.041401658207178116 at step: 38
Iter time:  0.28867615524091217


Train loss: 0.09902146458625793 at step: 39
Iter time:  0.2881959829574976


Train loss: 0.04032164067029953 at step: 40
Iter time:  0.2877282738685608


Train loss: 0.08431336283683777 at step: 41
Iter time:  0.287305581860426


Train loss: 0.016811475157737732 at step: 42
Iter time:  0.28688812255859375


Train loss: 0.17475540935993195 at step: 43
Iter time:  0.2864966115286184


Train loss: 0.09357786923646927 at step: 44
Iter time:  0.2861306288025596


Train loss: 0.017131131142377853 at step: 45
Iter time:  0.28577544424268936


Train loss: 0.04232923686504364 at step: 46
Iter time:  0.28546911218891974


Train loss: 0.024003122001886368 at step: 47
Iter time:  0.2851375975507371


Train loss: 0.18002796173095703 at step: 48
Iter time:  0.2848255783319473


Train loss: 0.023395199328660965 at step: 49
Iter time:  0.2845302893190968


Train loss: 0.09364969283342361 at step: 50
Iter time:  0.28425896167755127


Train loss: 0.07635291665792465 at step: 51
Iter time:  0.2839858859193091


Train loss: 0.11188116669654846 at step: 52
Iter time:  0.2837174809896029


Train loss: 0.06320314109325409 at step: 53
Iter time:  0.2836992830600379


Train loss: 0.05446964129805565 at step: 54
Iter time:  0.2834781938129001


Train loss: 0.10698319971561432 at step: 55
Iter time:  0.28324464451182974


Train loss: 0.017064522951841354 at step: 56
Iter time:  0.2830525721822466


Train loss: 0.11543658375740051 at step: 57
Iter time:  0.282854251694261


Train loss: 0.060469094663858414 at step: 58
Iter time:  0.2826563736488079


Train loss: 0.07850977033376694 at step: 59
Iter time:  0.2824593196480961


Train loss: 0.07140517979860306 at step: 60
Iter time:  0.2822745323181152


Train loss: 0.09151512384414673 at step: 61
Iter time:  0.2821203333432557


Train loss: 0.034650713205337524 at step: 62
Iter time:  0.2819392181211902


Train loss: 0.0420977883040905 at step: 63
Iter time:  0.28176678173125735


Train loss: 0.11728619039058685 at step: 64
Iter time:  0.28159745782613754


Train loss: 0.04925830662250519 at step: 65
Iter time:  0.28146654275747446


Train loss: 0.03924468904733658 at step: 66
Iter time:  0.2813042293895375


Train loss: 0.1871964931488037 at step: 67
Iter time:  0.281150988678434


Train loss: 0.13670706748962402 at step: 68
Iter time:  0.2810102035017574


Train loss: 0.09328654408454895 at step: 69
Iter time:  0.28088608686474786


Train loss: 0.030954260379076004 at step: 70
Iter time:  0.28075288023267475


Train loss: 0.05739397555589676 at step: 71
Iter time:  0.2806298229056345


Train loss: 0.03848687931895256 at step: 72
Iter time:  0.28053298261430526


Train loss: 0.11888425052165985 at step: 73
Iter time:  0.2804237424510799


Train loss: 0.08137758076190948 at step: 74
Iter time:  0.28031312774967504


Train loss: 0.06993182748556137 at step: 75
Iter time:  0.2802112674713135


Train loss: 0.042433001101017 at step: 76
Iter time:  0.2801284162621749


Train loss: 0.06873548775911331 at step: 77
Iter time:  0.2800286776059634


Train loss: 0.09630933403968811 at step: 78
Iter time:  0.27994008858998615


Train loss: 0.07508859783411026 at step: 79
Iter time:  0.2798475675945041


Train loss: 0.12890107929706573 at step: 80
Iter time:  0.2797573864459991


Train loss: 0.11267603933811188 at step: 81
Iter time:  0.27966513162777745


Train loss: 0.03417402133345604 at step: 82
Iter time:  0.2795750658686568


Train loss: 0.08855360746383667 at step: 83
Iter time:  0.27948417433773176


Train loss: 0.06300365179777145 at step: 84
Iter time:  0.2794068966593061


Train loss: 0.07174482941627502 at step: 85
Iter time:  0.27933667126823875


Train loss: 0.04672811180353165 at step: 86
Iter time:  0.279259160507557


Train loss: 0.0248602032661438 at step: 87
Iter time:  0.2791743936209843


Train loss: 0.11430050432682037 at step: 88
Iter time:  0.2790936827659607


Train loss: 0.11424130201339722 at step: 89
Iter time:  0.2790144614959031


Train loss: 0.0805359035730362 at step: 90
Iter time:  0.2789622730678982


Train loss: 0.015191784128546715 at step: 91
Iter time:  0.27889244373028094


Train loss: 0.043268270790576935 at step: 92
Iter time:  0.2788284420967102


Train loss: 0.031366195529699326 at step: 93
Iter time:  0.2787630404195478


Train loss: 0.04328026622533798 at step: 94
Iter time:  0.2786974196738385


Train loss: 0.0969117283821106 at step: 95
Iter time:  0.27863136592664217


Train loss: 0.08682563900947571 at step: 96
Iter time:  0.27856162190437317


Train loss: 0.08003775030374527 at step: 97
Iter time:  0.2785101895479812


Train loss: 0.07957449555397034 at step: 98
Iter time:  0.27845030901383383


Train loss: 0.030841778963804245 at step: 99
Iter time:  0.2783874502085676


Train loss: 0.02486535906791687 at step: 100
Iter time:  0.27833237409591677


Train loss: 0.06376071274280548 at step: 101
Iter time:  0.2782729710682784


Train loss: 0.09116818010807037 at step: 102
Iter time:  0.27821549948524027


Train loss: 0.13080254197120667 at step: 103
Iter time:  0.2781581600892891


Train loss: 0.010510657913982868 at step: 104
Iter time:  0.2781189794723804


Train loss: 0.049003854393959045 at step: 105
Iter time:  0.27806840397062754


Train loss: 0.03396657481789589 at step: 106
Iter time:  0.2780209329893004


Train loss: 0.02338174544274807 at step: 107
Iter time:  0.27797110058436886


Train loss: 0.10688923299312592 at step: 108
Iter time:  0.2779230276743571


Train loss: 0.035099826753139496 at step: 109
Iter time:  0.27787382668311444


Train loss: 0.12313269823789597 at step: 110
Iter time:  0.2778250802646984


Train loss: 0.061857208609580994 at step: 111
Iter time:  0.2777892598160752


Train loss: 0.11458340287208557 at step: 112
Iter time:  0.2777386818613325


Train loss: 0.07254908233880997 at step: 113
Iter time:  0.2777417043669034


Train loss: 0.028548888862133026 at step: 114
Iter time:  0.2776957415697867


Train loss: 0.016393326222896576 at step: 115
Iter time:  0.2776489382204802


Train loss: 0.06434760987758636 at step: 116
Iter time:  0.27762095270485715


Train loss: 0.0462273545563221 at step: 117
Iter time:  0.2775773981697539


Train loss: 0.0883249044418335 at step: 118
Iter time:  0.27753707716020487


Train loss: 0.025118431076407433 at step: 119
Iter time:  0.2775000143451851


Train loss: 0.01156434416770935 at step: 120
Iter time:  0.2774669826030731


Train loss: 0.07026665657758713 at step: 121
Iter time:  0.27742614233789364


Train loss: 0.07800757884979248 at step: 122
Iter time:  0.2773903745119689


Train loss: 0.06253749132156372 at step: 123
Iter time:  0.27735669438431904


Train loss: 0.07835902273654938 at step: 124
Iter time:  0.2773264819575894


Train loss: 0.09893299639225006 at step: 125
Iter time:  0.27729484939575194


Train loss: 0.023154666647315025 at step: 126
Iter time:  0.27725982287573436


Train loss: 0.12072357535362244 at step: 127
Iter time:  0.27722592241182104


Train loss: 0.03171326965093613 at step: 128
Iter time:  0.2771927956491709


Train loss: 0.03194400668144226 at step: 129
Iter time:  0.27715391521306


Train loss: 0.021057959645986557 at step: 130
Iter time:  0.27712192902198207


Train loss: 0.03759501874446869 at step: 131
Iter time:  0.2770980623842196


Train loss: 0.068192258477211 at step: 132
Iter time:  0.27705887411579944


Train loss: 0.06613823771476746 at step: 133
Iter time:  0.2770256010213293


Train loss: 0.11407119035720825 at step: 134
Iter time:  0.27699510908838526


Train loss: 0.0700768455862999 at step: 135
Iter time:  0.27696458322030526


Train loss: 0.02547607012093067 at step: 136
Iter time:  0.27693002890138063


Train loss: 0.12787511944770813 at step: 137
Iter time:  0.2769023971836062


Train loss: 0.008165484294295311 at step: 138
Iter time:  0.27688161704851233


Train loss: 0.08330859243869781 at step: 139
Iter time:  0.2768511240430873


Train loss: 0.053389497101306915 at step: 140
Iter time:  0.27681937388011385


Train loss: 0.09204933792352676 at step: 141
Iter time:  0.2767965320154285


Train loss: 0.05365530401468277 at step: 142
Iter time:  0.2767831103902468


Train loss: 0.09062398970127106 at step: 143
Iter time:  0.27675421087891905


Train loss: 0.11024533212184906 at step: 144
Iter time:  0.27672740154796177


Train loss: 0.06901265680789948 at step: 145
Iter time:  0.27671277276400863


Train loss: 0.09907856583595276 at step: 146
Iter time:  0.2766979263253408


Train loss: 0.08447441458702087 at step: 147
Iter time:  0.2766688875600594


Train loss: 0.02856670878827572 at step: 148
Iter time:  0.27664245946987254


Train loss: 0.07311240583658218 at step: 149
Iter time:  0.27662398831156276


Train loss: 0.13580244779586792 at step: 150
Iter time:  0.27659993489583334


Train loss: 0.11277523636817932 at step: 151
Iter time:  0.27657403377507694


Train loss: 0.06420186907052994 at step: 152
Iter time:  0.27654799975846944


Train loss: 0.09141753613948822 at step: 153
Iter time:  0.276528810363969


Train loss: 0.03269919380545616 at step: 154
Iter time:  0.2765079535447158


Train loss: 0.09857326745986938 at step: 155
Iter time:  0.27647957032726656


Train loss: 0.10405518859624863 at step: 156
Iter time:  0.27645452053118974


Train loss: 0.0134409349411726 at step: 157
Iter time:  0.2764356090764331


Train loss: 0.07780061662197113 at step: 158
Iter time:  0.27642066116574443


Train loss: 0.06309988349676132 at step: 159
Iter time:  0.2763978955130907


Train loss: 0.13045784831047058 at step: 160
Iter time:  0.2763742938637733


Train loss: 0.03165050968527794 at step: 161
Iter time:  0.2763574597258005


Train loss: 0.06144896522164345 at step: 162
Iter time:  0.2763584322399563


Train loss: 0.07327111810445786 at step: 163
Iter time:  0.2763485806119954


Train loss: 0.13764260709285736 at step: 164
Iter time:  0.27632716225414744


Train loss: 0.040046535432338715 at step: 165
Iter time:  0.2763169548728249


Train loss: 0.07943950593471527 at step: 166
Iter time:  0.27629754342228535


Train loss: 0.0187186561524868 at step: 167
Iter time:  0.27628040599251935


Train loss: 0.11431960761547089 at step: 168
Iter time:  0.27627230825878324


Train loss: 0.1280713528394699 at step: 169
Iter time:  0.27627499145868967


Train loss: 0.00949956476688385 at step: 170
Iter time:  0.2762624474132762


Train loss: 0.025416534394025803 at step: 171
Iter time:  0.2762474079578244


Train loss: 0.12085535377264023 at step: 172
Iter time:  0.27623182257940604


Train loss: 0.12382395565509796 at step: 173
Iter time:  0.2762167178137454


Train loss: 0.0616832934319973 at step: 174
Iter time:  0.2761999546796426


Train loss: 0.043217726051807404 at step: 175
Iter time:  0.27618263244628904


Train loss: 0.07159192860126495 at step: 176
Iter time:  0.2761679156260057


Train loss: 0.07240747660398483 at step: 177
Iter time:  0.27615072094114484


Train loss: 0.07178817689418793 at step: 178
Iter time:  0.2761361478419786


Train loss: 0.02725369855761528 at step: 179
Iter time:  0.2761223196317364


Train loss: 0.04417501762509346 at step: 180
Iter time:  0.27611502276526556


Train loss: 0.07271485775709152 at step: 181
Iter time:  0.27609571567556473


Train loss: 0.09811140596866608 at step: 182
Iter time:  0.2760816445717445


Train loss: 0.0791144073009491 at step: 183
Iter time:  0.2760645222794163


Train loss: 0.056115929037332535 at step: 184
Iter time:  0.27605293237644696


Train loss: 0.02202795073390007 at step: 185
Iter time:  0.2760614524016509


Train loss: 0.05563441663980484 at step: 186
Iter time:  0.27604656706574143


Train loss: 0.07574166357517242 at step: 187
Iter time:  0.2760302293746867


Train loss: 0.025964878499507904 at step: 188
Iter time:  0.2760153463546266


Train loss: 0.055379074066877365 at step: 189
Iter time:  0.275999939630902


Train loss: 0.06911841034889221 at step: 190
Iter time:  0.27598649200640224


Train loss: 0.054052188992500305 at step: 191
Iter time:  0.27597653678574485


Train loss: 0.04337790980935097 at step: 192
Iter time:  0.2759799448152383


Train loss: 0.06273825466632843 at step: 193
Iter time:  0.27596856028304817


Train loss: 0.022661782801151276 at step: 194
Iter time:  0.2759549445712689


Train loss: 0.02115359902381897 at step: 195
Iter time:  0.27594099167065744


Train loss: 0.06192168965935707 at step: 196
Iter time:  0.2759334019252232


Train loss: 0.09753815829753876 at step: 197
Iter time:  0.27592621842011583


Train loss: 0.06463561952114105 at step: 198
Iter time:  0.2759129230422203


Train loss: 0.057059966027736664 at step: 199
Iter time:  0.275901158251355


Train loss: 0.12742161750793457 at step: 200
Iter time:  0.27588711977005004


Train loss: 0.06480108946561813 at step: 201
Iter time:  0.27587398960815734


Train loss: 0.05094991624355316 at step: 202
Iter time:  0.2758623939929622


Train loss: 0.10993185639381409 at step: 203
Iter time:  0.2758535199564666


Train loss: 0.09079208970069885 at step: 204
Iter time:  0.27584018426782947


Train loss: 0.06237422674894333 at step: 205
Iter time:  0.2758306910352009


Train loss: 0.06652192771434784 at step: 206
Iter time:  0.27581759332453165


Train loss: 0.08794903010129929 at step: 207
Iter time:  0.2758052049627627


Train loss: 0.04260336235165596 at step: 208
Iter time:  0.2757938355207443


Train loss: 0.037606380879879 at step: 209
Iter time:  0.2757876820541455


Train loss: 0.07819555699825287 at step: 210
Iter time:  0.275774537949335


Train loss: 0.06905198842287064 at step: 211
Iter time:  0.2757635297368488


Train loss: 0.039305657148361206 at step: 212
Iter time:  0.27575323041879907


Train loss: 0.041765425354242325 at step: 213
Iter time:  0.27574872298979425


Train loss: 0.02858922630548477 at step: 214
Iter time:  0.27573628848958237


Train loss: 0.06592686474323273 at step: 215
Iter time:  0.275725018700888


Train loss: 0.07147801667451859 at step: 216
Iter time:  0.27571551225803514


Train loss: 0.029284022748470306 at step: 217
Iter time:  0.2757236210431921


Train loss: 0.05416503921151161 at step: 218
Iter time:  0.2757159723054378


Train loss: 0.10008227080106735 at step: 219
Iter time:  0.275708635103757


Train loss: 0.04914072901010513 at step: 220
Iter time:  0.27570091160860927


Train loss: 0.009627865627408028 at step: 221
Iter time:  0.27570008907922255


Train loss: 0.2201751172542572 at step: 222
Iter time:  0.2756940255293975


Train loss: 0.03939357399940491 at step: 223
Iter time:  0.2756889518600943


Train loss: 0.07521884143352509 at step: 224
Iter time:  0.2756805941462517


Train loss: 0.07403076440095901 at step: 225
Iter time:  0.2756750477684869


Train loss: 0.0569811686873436 at step: 226
Iter time:  0.2756702435755097


Train loss: 0.0878797397017479 at step: 227
Iter time:  0.2756670193525138


Train loss: 0.12995119392871857 at step: 228
Iter time:  0.27566577049723845


Train loss: 0.07192361354827881 at step: 229
Iter time:  0.27566015355972223


Train loss: 0.05642756074666977 at step: 230
Iter time:  0.2756543905838676


Train loss: 0.034895215183496475 at step: 231
Iter time:  0.2756536574590774


Train loss: 0.09849704802036285 at step: 232
Iter time:  0.27565382677933264


Train loss: 0.05167986825108528 at step: 233
Iter time:  0.2756470927864697


Train loss: 0.018161583691835403 at step: 234
Iter time:  0.2756432590321598


Train loss: 0.035009510815143585 at step: 235
Iter time:  0.2756414210542719


Train loss: 0.09077619016170502 at step: 236
Iter time:  0.27563357050135984


Train loss: 0.014506906270980835 at step: 237
Iter time:  0.27562735754729323


Train loss: 0.02141222357749939 at step: 238
Iter time:  0.27562778637188823


Train loss: 0.07846149802207947 at step: 239
Iter time:  0.2756291952093276


Train loss: 0.11479797959327698 at step: 240
Iter time:  0.2756248156229655


Train loss: 0.015395007096230984 at step: 241
Iter time:  0.27562248855210936


Train loss: 0.03745662420988083 at step: 242
Iter time:  0.27562235209567487


Train loss: 0.06048301234841347 at step: 243
Iter time:  0.27561910162246767


Train loss: 0.037920985370874405 at step: 244
Iter time:  0.2756147511669847


Train loss: 0.015724483877420425 at step: 245
Iter time:  0.27561047223149515


Train loss: 0.013527189381420612 at step: 246
Iter time:  0.2756137208240788


Train loss: 0.10880771279335022 at step: 247
Iter time:  0.27560978669386643


Train loss: 0.015488928183913231 at step: 248
Iter time:  0.2756083050081807


Train loss: 0.08740448206663132 at step: 249
Iter time:  0.27560536736944113


Train loss: 0.02510353922843933 at step: 250
Iter time:  0.27560715103149414


Train loss: 0.06872761994600296 at step: 251
Iter time:  0.27560409701677907


Train loss: 0.03798391669988632 at step: 252
Iter time:  0.2755995506332034


Train loss: 0.02739509381353855 at step: 253
Iter time:  0.27559571680815326


Train loss: 0.011381409130990505 at step: 254
Iter time:  0.27559386745212583


Train loss: 0.03172506392002106 at step: 255
Iter time:  0.2755891463335823


Train loss: 0.07756999880075455 at step: 256
Iter time:  0.27558742091059685


Train loss: 0.08374883234500885 at step: 257
Iter time:  0.27558334513860916


Train loss: 0.0248137004673481 at step: 258
Iter time:  0.27557907825292544


Train loss: 0.0660448893904686 at step: 259
Iter time:  0.27557608980009457


Train loss: 0.15791097283363342 at step: 260
Iter time:  0.27557234947498027


Train loss: 0.049681827425956726 at step: 261
Iter time:  0.2756043010287815


Train loss: 0.10706436634063721 at step: 262
Iter time:  0.27559790447468063


Train loss: 0.05124768987298012 at step: 263
Iter time:  0.2755942217750694


Train loss: 0.04921461641788483 at step: 264
Iter time:  0.2755904152537837


Train loss: 0.09668189287185669 at step: 265
Iter time:  0.27558900545228204


Train loss: 0.14928185939788818 at step: 266
Iter time:  0.27558575626602744


Train loss: 0.07997994124889374 at step: 267
Iter time:  0.2755830127201723


Train loss: 0.10134676843881607 at step: 268
Iter time:  0.27558179488822593


Train loss: 0.07036556303501129 at step: 269
Iter time:  0.2755816824817303


Train loss: 0.010349320247769356 at step: 270
Iter time:  0.275583878269902


Train loss: 0.08400426805019379 at step: 271
Iter time:  0.2755809208563773


Train loss: 0.05613410472869873 at step: 272
Iter time:  0.27557896340594573


Train loss: 0.017262756824493408 at step: 273
Iter time:  0.2755772875342177


Train loss: 0.03555155545473099 at step: 274
Iter time:  0.2755766202063456


Train loss: 0.03714413940906525 at step: 275
Iter time:  0.27557578693736684


Train loss: 0.12392698973417282 at step: 276
Iter time:  0.27557457529980206


Train loss: 0.04209180921316147 at step: 277
Iter time:  0.275574192673721


Train loss: 0.06815791130065918 at step: 278
Iter time:  0.2755715821286757


Train loss: 0.013048505410552025 at step: 279
Iter time:  0.27557042593597086


Train loss: 0.05845697596669197 at step: 280
Iter time:  0.2755708421979632


Train loss: 0.07990346848964691 at step: 281
Iter time:  0.2755696773529053


Train loss: 0.022612128406763077 at step: 282
Iter time:  0.2755674808583361


Train loss: 0.036900170147418976 at step: 283
Iter time:  0.27557028561514596


Train loss: 0.08268610388040543 at step: 284
Iter time:  0.2755694867859424


Train loss: 0.09277671575546265 at step: 285
Iter time:  0.2755701650652969


Train loss: 0.11581314355134964 at step: 286
Iter time:  0.27556894625817147


Train loss: 0.053004004061222076 at step: 287
Iter time:  0.27556478271085627


Train loss: 0.0671486109495163 at step: 288
Iter time:  0.27556386093298596


Train loss: 0.07870131731033325 at step: 289
Iter time:  0.27556240682370936


Train loss: 0.1152115985751152 at step: 290
Iter time:  0.275561077841397


Train loss: 0.09503796696662903 at step: 291
Iter time:  0.27555834632558923


Train loss: 0.10826389491558075 at step: 292
Iter time:  0.27555649411188415


Train loss: 0.07464008033275604 at step: 293
Iter time:  0.27556376652506026


Train loss: 0.05966120958328247 at step: 294
Iter time:  0.2755622636704218


Train loss: 0.017725402489304543 at step: 295
Iter time:  0.27556122278763073


Train loss: 0.09233029931783676 at step: 296
Iter time:  0.27555849262186


Train loss: 0.03127521649003029 at step: 297
Iter time:  0.2755569922000872


Train loss: 0.02182898297905922 at step: 298
Iter time:  0.2755547457893423


Train loss: 0.0628521591424942 at step: 299
Iter time:  0.27555269620889006


Train loss: 0.048371974378824234 at step: 300
Iter time:  0.2755529586474101


Train loss: 0.049832046031951904 at step: 301
Iter time:  0.27555151714439013


Train loss: 0.12740784883499146 at step: 302
Iter time:  0.2755554125008994


Train loss: 0.057332031428813934 at step: 303
Iter time:  0.2755555288232986


Train loss: 0.014237598516047001 at step: 304
Iter time:  0.27555711567401886


Train loss: 0.04962417110800743 at step: 305
Iter time:  0.27555504079724924


Train loss: 0.11037582159042358 at step: 306
Iter time:  0.27556201289681825


Train loss: 0.05895371735095978 at step: 307
Iter time:  0.27556447874063


Train loss: 0.07421982288360596 at step: 308
Iter time:  0.2755627245097965


Train loss: 0.11101134866476059 at step: 309
Iter time:  0.275560829631719


Train loss: 0.07866284251213074 at step: 310
Iter time:  0.2755579394678916


Train loss: 0.04289061576128006 at step: 311
Iter time:  0.2755600401826227


Train loss: 0.13434819877147675 at step: 312
Iter time:  0.2755608245348319


Train loss: 0.11754210293292999 at step: 313
Iter time:  0.2755602480123599


Train loss: 0.026287725195288658 at step: 314
Iter time:  0.2755606311142065


Train loss: 0.08906689286231995 at step: 315
Iter time:  0.27555919526115297


Train loss: 0.013390712440013885 at step: 316
Iter time:  0.2755573505087744


Train loss: 0.02246752381324768 at step: 317
Iter time:  0.275557014844395


Train loss: 0.04761672765016556 at step: 318
Iter time:  0.27555872434340184


Train loss: 0.126186341047287 at step: 319
Iter time:  0.2755566039429189


Train loss: 0.04437744617462158 at step: 320
Iter time:  0.2755554012954235


Train loss: 0.08322034031152725 at step: 321
Iter time:  0.275552172527135


Train loss: 0.12416400015354156 at step: 322
Iter time:  0.27554963538365335


Train loss: 0.046380218118429184 at step: 323
Iter time:  0.27554863746690306


Train loss: 0.08191104233264923 at step: 324
Iter time:  0.27554803277239387


Train loss: 0.06730447709560394 at step: 325
Iter time:  0.27554644878094015


Train loss: 0.035420697182416916 at step: 326
Iter time:  0.27554464998420763


Train loss: 0.10484018176794052 at step: 327
Iter time:  0.2755427870910831


Train loss: 0.05533263832330704 at step: 328
Iter time:  0.27554216472114007


Train loss: 0.011323977261781693 at step: 329
Iter time:  0.27554031128579


Train loss: 0.12670907378196716 at step: 330
Iter time:  0.2755448160749493


Train loss: 0.05183374136686325 at step: 331
Iter time:  0.27554355287119703


Train loss: 0.08837535977363586 at step: 332
Iter time:  0.2755417170294796


Train loss: 0.0371236614882946 at step: 333
Iter time:  0.27553933518784895


Train loss: 0.06357838213443756 at step: 334
Iter time:  0.27553756722433126


Train loss: 0.0574866347014904 at step: 335
Iter time:  0.27553581266260857


Train loss: 0.05913558229804039 at step: 336
Iter time:  0.2755340692542848


Train loss: 0.09701403230428696 at step: 337
Iter time:  0.27553235812427734


Train loss: 0.03311743214726448 at step: 338
Iter time:  0.2755310577753733


Train loss: 0.03605852276086807 at step: 339
Iter time:  0.2755288086106292


Train loss: 0.07061918824911118 at step: 340
Iter time:  0.27552735805511475


Train loss: 0.007609263528138399 at step: 341
Iter time:  0.2755285686761403


Train loss: 0.0877046212553978 at step: 342
Iter time:  0.27552661839981524


Train loss: 0.02359769120812416 at step: 343
Iter time:  0.27552530786386387


Train loss: 0.032589931041002274 at step: 344
Iter time:  0.2755244658436886


Train loss: 0.039827607572078705 at step: 345
Iter time:  0.2755237807398257


Train loss: 0.037924427539110184 at step: 346
Iter time:  0.27552299968080024


Train loss: 0.029582925140857697 at step: 347
Iter time:  0.27552086956562843


Train loss: 0.0067596435546875 at step: 348
Iter time:  0.2755221196974831


Train loss: 0.015267494134604931 at step: 349
Iter time:  0.2755208910365501


Train loss: 0.06183253973722458 at step: 350
Iter time:  0.2755180549621582


Train loss: 0.07545921951532364 at step: 351
Iter time:  0.27551570441308526


Train loss: 0.06482081115245819 at step: 352
Iter time:  0.27551373365250503


Train loss: 0.05043601244688034 at step: 353
Iter time:  0.2755118578081428


Train loss: 0.024386290460824966 at step: 354
Iter time:  0.2755098949044438


Train loss: 0.033975422382354736 at step: 355
Iter time:  0.2755078369462994


Train loss: 0.008544627577066422 at step: 356
Iter time:  0.27550623055254475


Train loss: 0.021900203078985214 at step: 357
Iter time:  0.2755050124908362


Train loss: 0.12148978561162949 at step: 358
Iter time:  0.2755034848964414


Train loss: 0.02030767686665058 at step: 359
Iter time:  0.27550242206180325


Train loss: 0.10258974134922028 at step: 360
Iter time:  0.2755008598168691


Train loss: 0.025924986228346825 at step: 361
Iter time:  0.27549916753478326


Train loss: 0.02939791977405548 at step: 362
Iter time:  0.27549678844641584


Train loss: 0.07861676812171936 at step: 363
Iter time:  0.27549546218115434


Train loss: 0.05268220603466034 at step: 364
Iter time:  0.27549292556532134


Train loss: 0.08678674697875977 at step: 365
Iter time:  0.27549172100955494


Train loss: 0.06325652450323105 at step: 366
Iter time:  0.27548983774549973


Train loss: 0.016898028552532196 at step: 367
Iter time:  0.27548738916173615


Train loss: 0.03910677880048752 at step: 368
Iter time:  0.2754885476568471


Train loss: 0.05659341812133789 at step: 369
Iter time:  0.27548677100721736


Train loss: 0.040899477899074554 at step: 370
Iter time:  0.275484181094814


Train loss: 0.042414192110300064 at step: 371
Iter time:  0.27548247527562064


Train loss: 0.11223442107439041 at step: 372
Iter time:  0.27548273788985383


Train loss: 0.06597159057855606 at step: 373
Iter time:  0.27548035859422454


Train loss: 0.013658342882990837 at step: 374
Iter time:  0.27547897119573095


Train loss: 0.015582529827952385 at step: 375
Iter time:  0.27548130162556966


Found 5773 trainable_data in total.
