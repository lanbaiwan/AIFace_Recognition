Model loaded..
Use LinearProbe head: pretrained_weights/10_1_TTO_epoch4.pth
Choose layer: 23 for cls embedding
Not add Gaussian noise to the feature embedding.
Not use random erasing.
data mode: ours
[{'data_path': '/home/data/szk/face/face', 'data_mode': 'ours'}]
total_list_len: 6000
Fix the backbone.
Length of dataset: 375
Directory ./TTO_checkpoints/2024-10-05-18-59-46 is created.
Train loss: 0.007040700875222683 at step: 1
Iter time:  0.8740963935852051


Train loss: 0.05477333813905716 at step: 2
Iter time:  0.5726256370544434


Train loss: 0.003534349612891674 at step: 3
Iter time:  0.47124679883321124


Train loss: 0.01490074023604393 at step: 4
Iter time:  0.4205141067504883


Train loss: 0.0035034283064305782 at step: 5
Iter time:  0.3903634548187256


Train loss: 0.012423882260918617 at step: 6
Iter time:  0.36975876490275067


Train loss: 0.06297418475151062 at step: 7
Iter time:  0.3550439902714321


Train loss: 0.022620635107159615 at step: 8
Iter time:  0.34421592950820923


Train loss: 0.020805904641747475 at step: 9
Iter time:  0.3355783091651069


Train loss: 0.014255489222705364 at step: 10
Iter time:  0.32872762680053713


Train loss: 0.01628940925002098 at step: 11
Iter time:  0.32310440323569556


Train loss: 0.015160346403717995 at step: 12
Iter time:  0.31841981410980225


Train loss: 0.0037077227607369423 at step: 13
Iter time:  0.31444111237159145


Train loss: 0.01503389049321413 at step: 14
Iter time:  0.3110642433166504


Train loss: 0.030935270711779594 at step: 15
Iter time:  0.30811591148376466


Train loss: 0.012508301064372063 at step: 16
Iter time:  0.30555129051208496


Train loss: 0.04801382124423981 at step: 17
Iter time:  0.30330592043259563


Train loss: 0.004704383201897144 at step: 18
Iter time:  0.3013195859061347


Train loss: 0.008450871333479881 at step: 19
Iter time:  0.2995404695209704


Train loss: 0.08247823268175125 at step: 20
Iter time:  0.29793170690536497


Train loss: 0.028027113527059555 at step: 21
Iter time:  0.29646011761256624


Train loss: 0.008551288396120071 at step: 22
Iter time:  0.29512093283913354


Train loss: 0.03174905478954315 at step: 23
Iter time:  0.29390629478122876


Train loss: 0.007664051838219166 at step: 24
Iter time:  0.29281581441561383


Train loss: 0.03997074440121651 at step: 25
Iter time:  0.2917855167388916


Train loss: 0.007055011577904224 at step: 26
Iter time:  0.29085293182959926


Train loss: 0.06167466938495636 at step: 27
Iter time:  0.2900120770489728


Train loss: 0.01734653115272522 at step: 28
Iter time:  0.28923007420131136


Train loss: 0.011790065094828606 at step: 29
Iter time:  0.2884963545305976


Train loss: 0.010712306015193462 at step: 30
Iter time:  0.28781758149464926


Train loss: 0.054750096052885056 at step: 31
Iter time:  0.2871910833543347


Train loss: 0.051515255123376846 at step: 32
Iter time:  0.2865910530090332


Train loss: 0.008057985454797745 at step: 33
Iter time:  0.2860197081710353


Train loss: 0.0034351744689047337 at step: 34
Iter time:  0.285505498156828


Train loss: 0.03175113722681999 at step: 35
Iter time:  0.28504606655665804


Train loss: 0.10133582353591919 at step: 36
Iter time:  0.28460427125295


Train loss: 0.016922634094953537 at step: 37
Iter time:  0.2841815239674336


Train loss: 0.015524012967944145 at step: 38
Iter time:  0.28378598940999883


Train loss: 0.03599284589290619 at step: 39
Iter time:  0.2834155315007919


Train loss: 0.050226662307977676 at step: 40
Iter time:  0.2830628931522369


Train loss: 0.07635680586099625 at step: 41
Iter time:  0.2827188096395353


Train loss: 0.003609037259593606 at step: 42
Iter time:  0.2824011870792934


Train loss: 0.07335886359214783 at step: 43
Iter time:  0.28210280107897384


Train loss: 0.021622080355882645 at step: 44
Iter time:  0.281837674704465


Train loss: 0.006491473410278559 at step: 45
Iter time:  0.2815718862745497


Train loss: 0.007513931952416897 at step: 46
Iter time:  0.28131756056909973


Train loss: 0.009705912321805954 at step: 47
Iter time:  0.28107442247106673


Train loss: 0.07508151233196259 at step: 48
Iter time:  0.28084327777226764


Train loss: 0.006847510114312172 at step: 49
Iter time:  0.2806301408884477


Train loss: 0.053505029529333115 at step: 50
Iter time:  0.28040797233581544


Train loss: 0.03409111499786377 at step: 51
Iter time:  0.2802095600202972


Train loss: 0.03686888888478279 at step: 52
Iter time:  0.28001309358156645


Train loss: 0.014861240983009338 at step: 53
Iter time:  0.27982181872961653


Train loss: 0.034904155880212784 at step: 54
Iter time:  0.27963100539313424


Train loss: 0.060173340141773224 at step: 55
Iter time:  0.2794517300345681


Train loss: 0.004292882978916168 at step: 56
Iter time:  0.27926923973219736


Train loss: 0.0553109310567379 at step: 57
Iter time:  0.2791033753177576


Train loss: 0.024270927533507347 at step: 58
Iter time:  0.2789435181124457


Train loss: 0.09789560735225677 at step: 59
Iter time:  0.2787877422268108


Train loss: 0.014183195307850838 at step: 60
Iter time:  0.2786361575126648


Train loss: 0.07224270701408386 at step: 61
Iter time:  0.27849542117509685


Train loss: 0.048028506338596344 at step: 62
Iter time:  0.27835550615864413


Train loss: 0.09134712815284729 at step: 63
Iter time:  0.2782219099620032


Train loss: 0.03538452088832855 at step: 64
Iter time:  0.27808770537376404


Train loss: 0.015075630508363247 at step: 65
Iter time:  0.27796107805692233


Train loss: 0.010585564188659191 at step: 66
Iter time:  0.27783543413335626


Train loss: 0.06710439920425415 at step: 67
Iter time:  0.2777135336577003


Train loss: 0.06091248244047165 at step: 68
Iter time:  0.2775955936487983


Train loss: 0.051098037511110306 at step: 69
Iter time:  0.2774810549141704


Train loss: 0.00918303057551384 at step: 70
Iter time:  0.2773742267063686


Train loss: 0.026270287111401558 at step: 71
Iter time:  0.277271975933666


Train loss: 0.005680623929947615 at step: 72
Iter time:  0.277171575360828


Train loss: 0.048889920115470886 at step: 73
Iter time:  0.2770738569024491


Train loss: 0.022141776978969574 at step: 74
Iter time:  0.27697502922367406


Train loss: 0.011981844902038574 at step: 75
Iter time:  0.27689268430074054


Train loss: 0.015844348818063736 at step: 76
Iter time:  0.27681023196170207


Train loss: 0.03854816034436226 at step: 77
Iter time:  0.27673377309526714


Train loss: 0.07246623933315277 at step: 78
Iter time:  0.2766547630994748


Train loss: 0.03751901164650917 at step: 79
Iter time:  0.2765785289716117


Train loss: 0.03634301573038101 at step: 80
Iter time:  0.2765052914619446


Train loss: 0.02168240025639534 at step: 81
Iter time:  0.2764407558205687


Train loss: 0.014310669153928757 at step: 82
Iter time:  0.2763710719783132


Train loss: 0.052630867809057236 at step: 83
Iter time:  0.27630372219775096


Train loss: 0.01907839998602867 at step: 84
Iter time:  0.2762419411114284


Train loss: 0.019025398418307304 at step: 85
Iter time:  0.2761847411884981


Train loss: 0.026059897616505623 at step: 86
Iter time:  0.2761253506638283


Train loss: 0.0035178731195628643 at step: 87
Iter time:  0.2760608333280717


Train loss: 0.09719903022050858 at step: 88
Iter time:  0.27600372379476373


Train loss: 0.026505395770072937 at step: 89
Iter time:  0.27594265509187504


Train loss: 0.04339829832315445 at step: 90
Iter time:  0.27588708135816786


Train loss: 0.0036217416636645794 at step: 91
Iter time:  0.27583457087422464


Train loss: 0.04972202703356743 at step: 92
Iter time:  0.2757781562597855


Train loss: 0.04591633379459381 at step: 93
Iter time:  0.27572630810481247


Train loss: 0.02447143755853176 at step: 94
Iter time:  0.2756777342329634


Train loss: 0.08069118857383728 at step: 95
Iter time:  0.27562682754115053


Train loss: 0.017666978761553764 at step: 96
Iter time:  0.27557861308256787


Train loss: 0.033100761473178864 at step: 97
Iter time:  0.27553458557915445


Train loss: 0.028493637219071388 at step: 98
Iter time:  0.27548696556869817


Train loss: 0.006671322043985128 at step: 99
Iter time:  0.27544542033262925


Train loss: 0.0032544410787522793 at step: 100
Iter time:  0.2754036259651184


Train loss: 0.009790075942873955 at step: 101
Iter time:  0.2753625104923059


Train loss: 0.05999066308140755 at step: 102
Iter time:  0.2753210652108286


Train loss: 0.08072040975093842 at step: 103
Iter time:  0.2752832996035085


Train loss: 0.001556621864438057 at step: 104
Iter time:  0.27524274358382594


Train loss: 0.04847898334264755 at step: 105
Iter time:  0.27520459038870676


Train loss: 0.01990271359682083 at step: 106
Iter time:  0.2751660976769789


Train loss: 0.004497959744185209 at step: 107
Iter time:  0.2751281796214737


Train loss: 0.06283208727836609 at step: 108
Iter time:  0.27509007409766867


Train loss: 0.005661909468472004 at step: 109
Iter time:  0.2750583854290323


Train loss: 0.0165107324719429 at step: 110
Iter time:  0.2750228144905784


Train loss: 0.014976082369685173 at step: 111
Iter time:  0.27499170775886056


Train loss: 0.09231135994195938 at step: 112
Iter time:  0.27496046679360525


Train loss: 0.040213171392679214 at step: 113
Iter time:  0.274933283307911


Train loss: 0.008475281298160553 at step: 114
Iter time:  0.2749060538777134


Train loss: 0.009838751517236233 at step: 115
Iter time:  0.2748730597288712


Train loss: 0.029285287484526634 at step: 116
Iter time:  0.274848080914596


Train loss: 0.02505781129002571 at step: 117
Iter time:  0.2748206415746966


Train loss: 0.03381901979446411 at step: 118
Iter time:  0.2747974900876061


Train loss: 0.007133015431463718 at step: 119
Iter time:  0.27477450130366476


Train loss: 0.0018636772874742746 at step: 120
Iter time:  0.27474963863690693


Train loss: 0.029402997344732285 at step: 121
Iter time:  0.2747266036419829


Train loss: 0.04055406153202057 at step: 122
Iter time:  0.2747062425144383


Train loss: 0.05149630457162857 at step: 123
Iter time:  0.2746803082101713


Train loss: 0.05099502205848694 at step: 124
Iter time:  0.2746595682636384


Train loss: 0.08829009532928467 at step: 125
Iter time:  0.27464056396484376


Train loss: 0.0071811978705227375 at step: 126
Iter time:  0.27462052352844724


Train loss: 0.056825168430805206 at step: 127
Iter time:  0.2745976879840761


Train loss: 0.011927414685487747 at step: 128
Iter time:  0.2745816111564636


Train loss: 0.020094046369194984 at step: 129
Iter time:  0.27456738782483475


Train loss: 0.005209317430853844 at step: 130
Iter time:  0.27455313755915717


Train loss: 0.012806632556021214 at step: 131
Iter time:  0.27453942335288944


Train loss: 0.015430614352226257 at step: 132
Iter time:  0.27452203360470856


Train loss: 0.02262507751584053 at step: 133
Iter time:  0.27450427973180785


Train loss: 0.024440627545118332 at step: 134
Iter time:  0.27449394695794405


Train loss: 0.05108211562037468 at step: 135
Iter time:  0.2744776301913791


Train loss: 0.03199797496199608 at step: 136
Iter time:  0.2744620407328886


Train loss: 0.06357291340827942 at step: 137
Iter time:  0.2744487219483313


Train loss: 0.0015279267681762576 at step: 138
Iter time:  0.2744361594103385


Train loss: 0.06000504642724991 at step: 139
Iter time:  0.2744248119189585


Train loss: 0.0193624384701252 at step: 140
Iter time:  0.2744153039796012


Train loss: 0.08943964540958405 at step: 141
Iter time:  0.27440206548000906


Train loss: 0.013837708160281181 at step: 142
Iter time:  0.27439061352904415


Train loss: 0.06496717035770416 at step: 143
Iter time:  0.27437883990627904


Train loss: 0.06438873708248138 at step: 144
Iter time:  0.27436548305882347


Train loss: 0.01034480705857277 at step: 145
Iter time:  0.2743573599848254


Train loss: 0.11739932745695114 at step: 146
Iter time:  0.2743452722079133


Train loss: 0.0617380365729332 at step: 147
Iter time:  0.27433487347194124


Train loss: 0.004218225367367268 at step: 148
Iter time:  0.2743240417660894


Train loss: 0.00938017200678587 at step: 149
Iter time:  0.2743126353961509


Train loss: 0.04485226422548294 at step: 150
Iter time:  0.2743020343780518


Train loss: 0.06605623662471771 at step: 151
Iter time:  0.2742927200746852


Train loss: 0.04782912880182266 at step: 152
Iter time:  0.27428368361372696


Train loss: 0.1005227267742157 at step: 153
Iter time:  0.2742770029828439


Train loss: 0.05123276263475418 at step: 154
Iter time:  0.27426850176476814


Train loss: 0.015247680246829987 at step: 155
Iter time:  0.27426029328377016


Train loss: 0.02932870388031006 at step: 156
Iter time:  0.2742529129370665


Train loss: 0.0027160141617059708 at step: 157
Iter time:  0.27424592728827407


Train loss: 0.03282652795314789 at step: 158
Iter time:  0.2742376372783999


Train loss: 0.01690320298075676 at step: 159
Iter time:  0.27422976193937865


Train loss: 0.1364462673664093 at step: 160
Iter time:  0.2742229774594307


Train loss: 0.012637767940759659 at step: 161
Iter time:  0.27421144669100367


Train loss: 0.0470067597925663 at step: 162
Iter time:  0.2742044116243904


Train loss: 0.019009701907634735 at step: 163
Iter time:  0.2741970109061961


Train loss: 0.03664412349462509 at step: 164
Iter time:  0.27418973533118646


Train loss: 0.0258033350110054 at step: 165
Iter time:  0.2741836099913626


Train loss: 0.04983562231063843 at step: 166
Iter time:  0.2741759656423546


Train loss: 0.00324554112739861 at step: 167
Iter time:  0.27417041727168834


Train loss: 0.008905807510018349 at step: 168
Iter time:  0.2741645517803374


Train loss: 0.022991972044110298 at step: 169
Iter time:  0.27415686528358235


Train loss: 0.0024825516156852245 at step: 170
Iter time:  0.2741504571017097


Train loss: 0.0062998817302286625 at step: 171
Iter time:  0.2741442312274063


Train loss: 0.06633758544921875 at step: 172
Iter time:  0.2741359804951867


Train loss: 0.05459687486290932 at step: 173
Iter time:  0.27412964980726295


Train loss: 0.06084102764725685 at step: 174
Iter time:  0.27412324664236487


Train loss: 0.02754881978034973 at step: 175
Iter time:  0.27411530358450753


Train loss: 0.016974441707134247 at step: 176
Iter time:  0.2741096087477424


Train loss: 0.015589695423841476 at step: 177
Iter time:  0.2741016708524887


Train loss: 0.015172268263995647 at step: 178
Iter time:  0.2740956946705165


Train loss: 0.005664686672389507 at step: 179
Iter time:  0.27408805506189443


Train loss: 0.029974743723869324 at step: 180
Iter time:  0.2740820646286011


Train loss: 0.024391060695052147 at step: 181
Iter time:  0.27407890525312056


Train loss: 0.06137466058135033 at step: 182
Iter time:  0.2740733453205654


Train loss: 0.023623671382665634 at step: 183
Iter time:  0.2740670097330229


Train loss: 0.023425033316016197 at step: 184
Iter time:  0.2740630688874618


Train loss: 0.006005209870636463 at step: 185
Iter time:  0.2740564037013698


Train loss: 0.03030206263065338 at step: 186
Iter time:  0.27405008064803255


Train loss: 0.03386659920215607 at step: 187
Iter time:  0.2740448311688428


Train loss: 0.0033480669371783733 at step: 188
Iter time:  0.2740392507390773


Train loss: 0.054972853511571884 at step: 189
Iter time:  0.27403927480102214


Train loss: 0.02950715459883213 at step: 190
Iter time:  0.27403806761691446


Train loss: 0.05533098429441452 at step: 191
Iter time:  0.2740361865278314


Train loss: 0.05953959748148918 at step: 192
Iter time:  0.27403460815548897


Train loss: 0.06638645380735397 at step: 193
Iter time:  0.27403459400710667


Train loss: 0.013390171341598034 at step: 194
Iter time:  0.2740330646947487


Train loss: 0.003227291163057089 at step: 195
Iter time:  0.2740304213303786


Train loss: 0.02305501140654087 at step: 196
Iter time:  0.2740304980959211


Train loss: 0.028674647212028503 at step: 197
Iter time:  0.27402977773985887


Train loss: 0.052507489919662476 at step: 198
Iter time:  0.27402607118240513


Train loss: 0.014889482408761978 at step: 199
Iter time:  0.27402726489694873


Train loss: 0.015469102188944817 at step: 200
Iter time:  0.27402721881866454


Train loss: 0.020403951406478882 at step: 201
Iter time:  0.27402723725162337


Train loss: 0.025382528081536293 at step: 202
Iter time:  0.2740238161370306


Train loss: 0.039917245507240295 at step: 203
Iter time:  0.27402569860073145


Train loss: 0.04374058544635773 at step: 204
Iter time:  0.2740258293993333


Train loss: 0.006082866340875626 at step: 205
Iter time:  0.274025084332722


Train loss: 0.05797721818089485 at step: 206
Iter time:  0.27402609991795807


Train loss: 0.053769830614328384 at step: 207
Iter time:  0.2740246662195178


Train loss: 0.02646181732416153 at step: 208
Iter time:  0.27402599499775815


Train loss: 0.005269366316497326 at step: 209
Iter time:  0.27402616573863053


Train loss: 0.013255717232823372 at step: 210
Iter time:  0.2740273532413301


Train loss: 0.018835213035345078 at step: 211
Iter time:  0.27402873400828287


Train loss: 0.01694849319756031 at step: 212
Iter time:  0.27402814041893436


Train loss: 0.012989852577447891 at step: 213
Iter time:  0.27402771246825025


Train loss: 0.04818876087665558 at step: 214
Iter time:  0.27402706569600327


Train loss: 0.051740776747465134 at step: 215
Iter time:  0.2740271379781324


Train loss: 0.012753010727465153 at step: 216
Iter time:  0.2740274049617626


Train loss: 0.009211057797074318 at step: 217
Iter time:  0.27402628182266164


Train loss: 0.039587363600730896 at step: 218
Iter time:  0.2740248496379327


Train loss: 0.04129644110798836 at step: 219
Iter time:  0.2740256949646832


Train loss: 0.051788464188575745 at step: 220
Iter time:  0.27402694550427525


Train loss: 0.0019078270997852087 at step: 221
Iter time:  0.27402492993557614


Train loss: 0.09813486039638519 at step: 222
Iter time:  0.27402508795798364


Train loss: 0.030437765643000603 at step: 223
Iter time:  0.2740272791396342


Train loss: 0.02660362422466278 at step: 224
Iter time:  0.2740274412291391


Train loss: 0.008525609970092773 at step: 225
Iter time:  0.27402801619635686


Train loss: 0.0306123998016119 at step: 226
Iter time:  0.27402652153926615


Train loss: 0.09344401955604553 at step: 227
Iter time:  0.2740281951585005


Train loss: 0.022047249600291252 at step: 228
Iter time:  0.27402997435184945


Train loss: 0.012302478775382042 at step: 229
Iter time:  0.27402952768917166


Train loss: 0.05965099111199379 at step: 230
Iter time:  0.27403023035629936


Train loss: 0.011027869768440723 at step: 231
Iter time:  0.2740311849684942


Train loss: 0.05520784854888916 at step: 232
Iter time:  0.274031702814431


Train loss: 0.009824322536587715 at step: 233
Iter time:  0.2740315684944775


Train loss: 0.0037088801618665457 at step: 234
Iter time:  0.27403240631788206


Train loss: 0.01198726985603571 at step: 235
Iter time:  0.27403397052846057


Train loss: 0.02184228040277958 at step: 236
Iter time:  0.27403331712140877


Train loss: 0.003135936800390482 at step: 237
Iter time:  0.27403467315158764


Train loss: 0.0050879293121397495 at step: 238
Iter time:  0.27403548785618376


Train loss: 0.021276861429214478 at step: 239
Iter time:  0.2740367915341046


Train loss: 0.059414491057395935 at step: 240
Iter time:  0.2740371972322464


Train loss: 0.007688666693866253 at step: 241
Iter time:  0.2740383880267005


Train loss: 0.050112247467041016 at step: 242
Iter time:  0.27403996601577635


Train loss: 0.0201091468334198 at step: 243
Iter time:  0.2740406107019495


Train loss: 0.0075571611523628235 at step: 244
Iter time:  0.2740404615636732


Train loss: 0.0055909352377057076 at step: 245
Iter time:  0.2740427688676484


Train loss: 0.0056481207720935345 at step: 246
Iter time:  0.274042706179425


Train loss: 0.050951115787029266 at step: 247
Iter time:  0.274043097669779


Train loss: 0.0018445253372192383 at step: 248
Iter time:  0.27404476846418074


Train loss: 0.06516694277524948 at step: 249
Iter time:  0.2740466709596565


Train loss: 0.005835526157170534 at step: 250
Iter time:  0.2740479536056519


Train loss: 0.05099719017744064 at step: 251
Iter time:  0.27404999258033785


Train loss: 0.04640178754925728 at step: 252
Iter time:  0.27404915908026317


Train loss: 0.0046305665746331215 at step: 253
Iter time:  0.2740505203428005


Train loss: 0.0030183163471519947 at step: 254
Iter time:  0.2740518755800142


Train loss: 0.030633166432380676 at step: 255
Iter time:  0.27405293034572226


Train loss: 0.06041991710662842 at step: 256
Iter time:  0.2740548485890031


Train loss: 0.03190794214606285 at step: 257
Iter time:  0.27405753395436805


Train loss: 0.00630164286121726 at step: 258
Iter time:  0.2740580730660017


Train loss: 0.048505205661058426 at step: 259
Iter time:  0.2740591336401273


Train loss: 0.11613866686820984 at step: 260
Iter time:  0.2740599834001981


Train loss: 0.03805352374911308 at step: 261
Iter time:  0.2740590919480013


Train loss: 0.1006278246641159 at step: 262
Iter time:  0.2740612785324796


Train loss: 0.010897627100348473 at step: 263
Iter time:  0.27406274955082305


Train loss: 0.018489887937903404 at step: 264
Iter time:  0.2740636811111913


Train loss: 0.025346193462610245 at step: 265
Iter time:  0.2740654072671566


Train loss: 0.03663734346628189 at step: 266
Iter time:  0.27406687844068484


Train loss: 0.05977347493171692 at step: 267
Iter time:  0.2740686734517415


Train loss: 0.1189393550157547 at step: 268
Iter time:  0.2740710164184001


Train loss: 0.049750518053770065 at step: 269
Iter time:  0.27407140270928027


Train loss: 0.002070584800094366 at step: 270
Iter time:  0.27407195214872004


Train loss: 0.014957494102418423 at step: 271
Iter time:  0.2740731793576061


Train loss: 0.02125966176390648 at step: 272
Iter time:  0.27407365160829883


Train loss: 0.003617508104071021 at step: 273
Iter time:  0.27407563038361377


Train loss: 0.006005176808685064 at step: 274
Iter time:  0.27407747811644617


Train loss: 0.020504139363765717 at step: 275
Iter time:  0.27407877055081453


Train loss: 0.05776449292898178 at step: 276
Iter time:  0.27407970722170844


Train loss: 0.017042938619852066 at step: 277
Iter time:  0.2740817655294811


Train loss: 0.051891423761844635 at step: 278
Iter time:  0.27408355517353084


Train loss: 0.0019708829931914806 at step: 279
Iter time:  0.2740842227867427


Train loss: 0.010711893439292908 at step: 280
Iter time:  0.2740844999040876


Train loss: 0.06029307842254639 at step: 281
Iter time:  0.27408621828751206


Train loss: 0.013092124834656715 at step: 282
Iter time:  0.274087463710325


Train loss: 0.016391821205615997 at step: 283
Iter time:  0.27408905079844986


Train loss: 0.024623628705739975 at step: 284
Iter time:  0.27409008103357235


Train loss: 0.05203043669462204 at step: 285
Iter time:  0.2740914922011526


Train loss: 0.059075042605400085 at step: 286
Iter time:  0.274092950187363


Train loss: 0.019659943878650665 at step: 287
Iter time:  0.2740943606306867


Train loss: 0.01544973161071539 at step: 288
Iter time:  0.274094598988692


Train loss: 0.01911773346364498 at step: 289
Iter time:  0.27409682966846083


Train loss: 0.03159516304731369 at step: 290
Iter time:  0.2740959323685745


Train loss: 0.03296155855059624 at step: 291
Iter time:  0.27409614484334727


Train loss: 0.05526070296764374 at step: 292
Iter time:  0.2740973724077826


Train loss: 0.03587312251329422 at step: 293
Iter time:  0.2740980407076891


Train loss: 0.048335619270801544 at step: 294
Iter time:  0.2740988366457881


Train loss: 0.0049278754740953445 at step: 295
Iter time:  0.2741002260628393


Train loss: 0.034741371870040894 at step: 296
Iter time:  0.2741004615216642


Train loss: 0.005557662341743708 at step: 297
Iter time:  0.27410081500557537


Train loss: 0.004008349496871233 at step: 298
Iter time:  0.27410157414890773


Train loss: 0.009482727386057377 at step: 299
Iter time:  0.2741021623579555


Train loss: 0.035498108714818954 at step: 300
Iter time:  0.27410194555918377


Train loss: 0.021651843562722206 at step: 301
Iter time:  0.2741036327970384


Train loss: 0.025102976709604263 at step: 302
Iter time:  0.2741053057032705


Train loss: 0.049949392676353455 at step: 303
Iter time:  0.2741069951073171


Train loss: 0.005737177561968565 at step: 304
Iter time:  0.2741068083988993


Train loss: 0.03348376601934433 at step: 305
Iter time:  0.2741058068197282


Train loss: 0.06100839748978615 at step: 306
Iter time:  0.2741081465303508


Train loss: 0.032707199454307556 at step: 307
Iter time:  0.2741085512242022


Train loss: 0.01380965393036604 at step: 308
Iter time:  0.27410884027357224


Train loss: 0.01928180642426014 at step: 309
Iter time:  0.274108401394199


Train loss: 0.027532951906323433 at step: 310
Iter time:  0.27410748697096304


Train loss: 0.05387556552886963 at step: 311
Iter time:  0.2741077015254275


Train loss: 0.017945442348718643 at step: 312
Iter time:  0.274105857580136


Train loss: 0.019506707787513733 at step: 313
Iter time:  0.27410529520564947


Train loss: 0.0068045565858483315 at step: 314
Iter time:  0.2741039452279449


Train loss: 0.0620797760784626 at step: 315
Iter time:  0.2741032093290299


Train loss: 0.005373943131417036 at step: 316
Iter time:  0.2741021000886265


Train loss: 0.004964022897183895 at step: 317
Iter time:  0.2741023147895885


Train loss: 0.025627514347434044 at step: 318
Iter time:  0.27410046784382947


Train loss: 0.061609312891960144 at step: 319
Iter time:  0.2740993828609072


Train loss: 0.025500601157546043 at step: 320
Iter time:  0.2740990176796913


Train loss: 0.05518367886543274 at step: 321
Iter time:  0.2740976104855166


Train loss: 0.04246532917022705 at step: 322
Iter time:  0.2740974774271805


Train loss: 0.018531976267695427 at step: 323
Iter time:  0.27409906948313995


Train loss: 0.01726274937391281 at step: 324
Iter time:  0.27409959575276316


Train loss: 0.09390321373939514 at step: 325
Iter time:  0.2740970362149752


Train loss: 0.008691994473338127 at step: 326
Iter time:  0.2740963763254552


Train loss: 0.024664457887411118 at step: 327
Iter time:  0.2740947383623969


Train loss: 0.014959696680307388 at step: 328
Iter time:  0.27409415128754405


Train loss: 0.00429101288318634 at step: 329
Iter time:  0.2740931315262629


Train loss: 0.02409336529672146 at step: 330
Iter time:  0.27409299648169316


Train loss: 0.008989447727799416 at step: 331
Iter time:  0.27409654873735595


Train loss: 0.03339303657412529 at step: 332
Iter time:  0.2740957356361021


Train loss: 0.023199601098895073 at step: 333
Iter time:  0.2740964331068434


Train loss: 0.04891669750213623 at step: 334
Iter time:  0.2740963183477253


Train loss: 0.008293417282402515 at step: 335
Iter time:  0.27410460443639045


Train loss: 0.013513808138668537 at step: 336
Iter time:  0.2741049655846187


Train loss: 0.01213071309030056 at step: 337
Iter time:  0.2741055693753749


Train loss: 0.007804028689861298 at step: 338
Iter time:  0.2741062655251407


Train loss: 0.0085993567481637 at step: 339
Iter time:  0.2741131648904806


Train loss: 0.03149492293596268 at step: 340
Iter time:  0.27411297349368824


Train loss: 0.0011322852224111557 at step: 341
Iter time:  0.2741146975598377


Train loss: 0.012051325291395187 at step: 342
Iter time:  0.27411557080452903


Train loss: 0.004020602907985449 at step: 343
Iter time:  0.27412504287919914


Train loss: 0.011360532604157925 at step: 344
Iter time:  0.2741251172021378


Train loss: 0.02223297208547592 at step: 345
Iter time:  0.2741250743036685


Train loss: 0.010391205549240112 at step: 346
Iter time:  0.27412518531600866


Train loss: 0.00540503952652216 at step: 347
Iter time:  0.27413131111980515


Train loss: 0.002875484526157379 at step: 348
Iter time:  0.27413040331040306


Train loss: 0.0027606883086264133 at step: 349
Iter time:  0.2741306647871832


Train loss: 0.04862452670931816 at step: 350
Iter time:  0.2741318089621408


Train loss: 0.011929105035960674 at step: 351
Iter time:  0.27413302337342177


Train loss: 0.015044169500470161 at step: 352
Iter time:  0.2741343236782334


Train loss: 0.018115878105163574 at step: 353
Iter time:  0.27413573413665165


Train loss: 0.008443867787718773 at step: 354
Iter time:  0.2741360516197937


Train loss: 0.007113235536962748 at step: 355
Iter time:  0.2741409489806269


Train loss: 0.002992963418364525 at step: 356
Iter time:  0.27414238988683465


Train loss: 0.00611167773604393 at step: 357
Iter time:  0.2741432537217768


Train loss: 0.06171979382634163 at step: 358
Iter time:  0.2741441566850886


Train loss: 0.004953732714056969 at step: 359
Iter time:  0.27415071822142534


Train loss: 0.01629122719168663 at step: 360
Iter time:  0.2741517292128669


Train loss: 0.00929165631532669 at step: 361
Iter time:  0.27415275507686543


Train loss: 0.009256512857973576 at step: 362
Iter time:  0.27415263982108945


Train loss: 0.02778991311788559 at step: 363
Iter time:  0.2741616310823719


Train loss: 0.026613838970661163 at step: 364
Iter time:  0.2741625721638019


Train loss: 0.020282406359910965 at step: 365
Iter time:  0.2741631318445075


Train loss: 0.007816423662006855 at step: 366
Iter time:  0.2741639868157809


Train loss: 0.01072760485112667 at step: 367
Iter time:  0.2741636749184424


Train loss: 0.010739926248788834 at step: 368
Iter time:  0.27416372493557306


Train loss: 0.008907729759812355 at step: 369
Iter time:  0.2741654061366549


Train loss: 0.009934583678841591 at step: 370
Iter time:  0.27416400200611835


Train loss: 0.05050703138113022 at step: 371
Iter time:  0.27416381745968227


Train loss: 0.05379164218902588 at step: 372
Iter time:  0.27416422482459774


Train loss: 0.01608474925160408 at step: 373
Iter time:  0.27416453924000106


Train loss: 0.005958212073892355 at step: 374
Iter time:  0.2741636037826538


Train loss: 0.004218223039060831 at step: 375
Iter time:  0.27416442171732586


Found 5891 trainable_data in total.
