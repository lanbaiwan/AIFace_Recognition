Model loaded..
Use LinearProbe head: pretrained_weights/10_16.pth
Choose layer: 23 for cls embedding
Not add Gaussian noise to the feature embedding.
Not use random erasing.
data mode: ours
[{'data_path': '/home/data/szk/face_B', 'data_mode': 'ours'}]
total_list_len: 6000
Fix the backbone.
Length of dataset: 375
Directory ./TTO_checkpoints/2024-10-16-20-27-33 is created.
Train loss: 0.13924184441566467 at step: 1
Iter time:  2.552706718444824


Train loss: 0.2527153193950653 at step: 2
Iter time:  1.416722297668457


Train loss: 0.12108485400676727 at step: 3
Iter time:  1.0364507834116619


Train loss: 0.14365406334400177 at step: 4
Iter time:  0.8457275032997131


Train loss: 0.2023591697216034 at step: 5
Iter time:  0.7326609134674072


Train loss: 0.1391812264919281 at step: 6
Iter time:  0.6581274271011353


Train loss: 0.1886850893497467 at step: 7
Iter time:  0.603916985648019


Train loss: 0.14240191876888275 at step: 8
Iter time:  0.5626225769519806


Train loss: 0.12837238609790802 at step: 9
Iter time:  0.5319810178544786


Train loss: 0.25426238775253296 at step: 10
Iter time:  0.5063745260238648


Train loss: 0.13110429048538208 at step: 11
Iter time:  0.4851162216880105


Train loss: 0.2891142666339874 at step: 12
Iter time:  0.4676621158917745


Train loss: 0.10324516147375107 at step: 13
Iter time:  0.45462589997511643


Train loss: 0.1898735612630844 at step: 14
Iter time:  0.4421490090233939


Train loss: 0.16608723998069763 at step: 15
Iter time:  0.4309166113535563


Train loss: 0.2802045941352844 at step: 16
Iter time:  0.4213734120130539


Train loss: 0.08452597260475159 at step: 17
Iter time:  0.4134533685796401


Train loss: 0.22821113467216492 at step: 18
Iter time:  0.40592341952853733


Train loss: 0.1580384224653244 at step: 19
Iter time:  0.39930954732392965


Train loss: 0.1010543629527092 at step: 20
Iter time:  0.3936197876930237


Train loss: 0.24754977226257324 at step: 21
Iter time:  0.3884678114028204


Train loss: 0.06526389718055725 at step: 22
Iter time:  0.38333379138599744


Train loss: 0.11589398235082626 at step: 23
Iter time:  0.37891059336454974


Train loss: 0.18089808523654938 at step: 24
Iter time:  0.3751931885878245


Train loss: 0.09526737779378891 at step: 25
Iter time:  0.371989860534668


Train loss: 0.2383013367652893 at step: 26
Iter time:  0.36959000734182507


Train loss: 0.0742882639169693 at step: 27
Iter time:  0.36632345340870043


Train loss: 0.12190022319555283 at step: 28
Iter time:  0.3631646973746164


Train loss: 0.2782418727874756 at step: 29
Iter time:  0.36063966257818814


Train loss: 0.24870805442333221 at step: 30
Iter time:  0.3580264329910278


Train loss: 0.28592124581336975 at step: 31
Iter time:  0.35577854802531583


Train loss: 0.1053350642323494 at step: 32
Iter time:  0.3533724173903465


Train loss: 0.13982954621315002 at step: 33
Iter time:  0.35126465739625873


Train loss: 0.34578847885131836 at step: 34
Iter time:  0.34910380139070396


Train loss: 0.10537976771593094 at step: 35
Iter time:  0.3471472876412528


Train loss: 0.30485594272613525 at step: 36
Iter time:  0.3452443281809489


Train loss: 0.12472233921289444 at step: 37
Iter time:  0.3438981223750759


Train loss: 0.10208697617053986 at step: 38
Iter time:  0.34233570726294266


Train loss: 0.18301799893379211 at step: 39
Iter time:  0.34105363258948695


Train loss: 0.31283244490623474 at step: 40
Iter time:  0.33981642723083494


Train loss: 0.12415757775306702 at step: 41
Iter time:  0.3385329072068377


Train loss: 0.18278437852859497 at step: 42
Iter time:  0.33714833713713144


Train loss: 0.21181419491767883 at step: 43
Iter time:  0.3358814494554387


Train loss: 0.11536350846290588 at step: 44
Iter time:  0.3345223665237427


Train loss: 0.19553843140602112 at step: 45
Iter time:  0.33339741494920516


Train loss: 0.23462694883346558 at step: 46
Iter time:  0.33214616775512695


Train loss: 0.1802135407924652 at step: 47
Iter time:  0.3309647884774715


Train loss: 0.0811200737953186 at step: 48
Iter time:  0.3298718233903249


Train loss: 0.17930781841278076 at step: 49
Iter time:  0.329789400100708


Train loss: 0.35185161232948303 at step: 50
Iter time:  0.32896004676818846


Train loss: 0.11500291526317596 at step: 51
Iter time:  0.3279087543487549


Train loss: 0.1170969232916832 at step: 52
Iter time:  0.3270876636871925


Train loss: 0.25131756067276 at step: 53
Iter time:  0.3264241533459358


Train loss: 0.17177143692970276 at step: 54
Iter time:  0.3255628833064326


Train loss: 0.14724303781986237 at step: 55
Iter time:  0.324755707654086


Train loss: 0.27088576555252075 at step: 56
Iter time:  0.3244050017424992


Train loss: 0.15993323922157288 at step: 57
Iter time:  0.32392537384702447


Train loss: 0.11970360577106476 at step: 58
Iter time:  0.3233195995462352


Train loss: 0.16583001613616943 at step: 59
Iter time:  0.3225619227199231


Train loss: 0.10468247532844543 at step: 60
Iter time:  0.3218196670214335


Train loss: 0.14809304475784302 at step: 61
Iter time:  0.3212880971001797


Train loss: 0.11671379208564758 at step: 62
Iter time:  0.32070022629153344


Train loss: 0.08381393551826477 at step: 63
Iter time:  0.3200620091150677


Train loss: 0.1826370358467102 at step: 64
Iter time:  0.31957001611590385


Train loss: 0.1924133002758026 at step: 65
Iter time:  0.3193517098060021


Train loss: 0.1319684237241745 at step: 66
Iter time:  0.31892872940410266


Train loss: 0.1814688891172409 at step: 67
Iter time:  0.31839911261601234


Train loss: 0.23565348982810974 at step: 68
Iter time:  0.3177935200579026


Train loss: 0.15876741707324982 at step: 69
Iter time:  0.3173634142115496


Train loss: 0.24090398848056793 at step: 70
Iter time:  0.3168390921183995


Train loss: 0.2726898491382599 at step: 71
Iter time:  0.31629991195571255


Train loss: 0.14833706617355347 at step: 72
Iter time:  0.3159864909119076


Train loss: 0.1544802337884903 at step: 73
Iter time:  0.3158813568010722


Train loss: 0.15399964153766632 at step: 74
Iter time:  0.3154438089680027


Train loss: 0.14157286286354065 at step: 75
Iter time:  0.315108855565389


Train loss: 0.08204643428325653 at step: 76
Iter time:  0.3146515896445827


Train loss: 0.10704606771469116 at step: 77
Iter time:  0.31452987101170926


Train loss: 0.34555962681770325 at step: 78
Iter time:  0.3143218022126418


Train loss: 0.15209347009658813 at step: 79
Iter time:  0.3139788048176826


Train loss: 0.24916449189186096 at step: 80
Iter time:  0.3138356417417526


Train loss: 0.18766146898269653 at step: 81
Iter time:  0.31354672820479784


Train loss: 0.09916982799768448 at step: 82
Iter time:  0.3133311126290298


Train loss: 0.21059772372245789 at step: 83
Iter time:  0.3129019162741052


Train loss: 0.2668731212615967 at step: 84
Iter time:  0.3125580662772769


Train loss: 0.254504531621933 at step: 85
Iter time:  0.3122243656831629


Train loss: 0.12270678579807281 at step: 86
Iter time:  0.31186135425124056


Train loss: 0.0864129289984703 at step: 87
Iter time:  0.31153440475463867


Train loss: 0.2210339605808258 at step: 88
Iter time:  0.3113754960623654


Train loss: 0.1897495836019516 at step: 89
Iter time:  0.31139690956372895


Train loss: 0.052845221012830734 at step: 90
Iter time:  0.3110837989383274


Train loss: 0.04607386142015457 at step: 91
Iter time:  0.3108586400419801


Train loss: 0.24922867119312286 at step: 92
Iter time:  0.31053772957428644


Train loss: 0.09560298919677734 at step: 93
Iter time:  0.31027456765533773


Train loss: 0.15095803141593933 at step: 94
Iter time:  0.30995431098532167


Train loss: 0.1838454008102417 at step: 95
Iter time:  0.30993320314507733


Train loss: 0.276084303855896 at step: 96
Iter time:  0.30985357364018756


Train loss: 0.22680389881134033 at step: 97
Iter time:  0.30952655654592615


Train loss: 0.18667560815811157 at step: 98
Iter time:  0.30927686302029356


Train loss: 0.26690542697906494 at step: 99
Iter time:  0.30899362612252285


Train loss: 0.17924174666404724 at step: 100
Iter time:  0.30875311374664305


Train loss: 0.11064095050096512 at step: 101
Iter time:  0.3084675628359955


Train loss: 0.09998036175966263 at step: 102
Iter time:  0.30819274631201055


Train loss: 0.18240323662757874 at step: 103
Iter time:  0.3079105881811346


Train loss: 0.18612538278102875 at step: 104
Iter time:  0.30774529163654035


Train loss: 0.2178613245487213 at step: 105
Iter time:  0.3075598852975028


Train loss: 0.06898542493581772 at step: 106
Iter time:  0.3073636495842124


Train loss: 0.2002037763595581 at step: 107
Iter time:  0.30714430541635673


Train loss: 0.18162620067596436 at step: 108
Iter time:  0.3069173406671595


Train loss: 0.24326080083847046 at step: 109
Iter time:  0.3067878714395226


Train loss: 0.10067808628082275 at step: 110
Iter time:  0.30658561099659315


Train loss: 0.1289755403995514 at step: 111
Iter time:  0.3063396956469562


Train loss: 0.13387328386306763 at step: 112
Iter time:  0.30613366833754946


Train loss: 0.19237327575683594 at step: 113
Iter time:  0.30602750103030585


Train loss: 0.22686591744422913 at step: 114
Iter time:  0.3058048089345296


Train loss: 0.13695839047431946 at step: 115
Iter time:  0.3056498589723007


Train loss: 0.24531809985637665 at step: 116
Iter time:  0.30543396185184346


Train loss: 0.1804649829864502 at step: 117
Iter time:  0.30549651333409494


Train loss: 0.13617831468582153 at step: 118
Iter time:  0.30531612493224064


Train loss: 0.13314560055732727 at step: 119
Iter time:  0.30514147702385397


Train loss: 0.21822717785835266 at step: 120
Iter time:  0.30497181216875713


Train loss: 0.1274951696395874 at step: 121
Iter time:  0.30478473734264533


Train loss: 0.2551281750202179 at step: 122
Iter time:  0.3046170551268781


Train loss: 0.28380364179611206 at step: 123
Iter time:  0.30440996526702635


Train loss: 0.14038661122322083 at step: 124
Iter time:  0.3042228914076282


Train loss: 0.2581275701522827 at step: 125
Iter time:  0.3040241985321045


Train loss: 0.15971317887306213 at step: 126
Iter time:  0.3038563804020957


Train loss: 0.15354245901107788 at step: 127
Iter time:  0.3036804030260702


Train loss: 0.16277050971984863 at step: 128
Iter time:  0.30362880043685436


Train loss: 0.21469444036483765 at step: 129
Iter time:  0.30347737046175227


Train loss: 0.2283431589603424 at step: 130
Iter time:  0.3033816906122061


Train loss: 0.18228557705879211 at step: 131
Iter time:  0.30327011064718695


Train loss: 0.16100355982780457 at step: 132
Iter time:  0.30310139330950653


Train loss: 0.04702902212738991 at step: 133
Iter time:  0.30293612014082144


Train loss: 0.20443132519721985 at step: 134
Iter time:  0.30277424783849005


Train loss: 0.16731388866901398 at step: 135
Iter time:  0.30262638021398475


Train loss: 0.16908350586891174 at step: 136
Iter time:  0.30247654984979067


Train loss: 0.29673144221305847 at step: 137
Iter time:  0.30230191676286017


Train loss: 0.18014201521873474 at step: 138
Iter time:  0.3021169296209363


Train loss: 0.2571011185646057 at step: 139
Iter time:  0.3019643618906145


Train loss: 0.22688725590705872 at step: 140
Iter time:  0.301805009160723


Train loss: 0.11132293939590454 at step: 141
Iter time:  0.30170248755326506


Train loss: 0.1662578582763672 at step: 142
Iter time:  0.3015476515595342


Train loss: 0.18872596323490143 at step: 143
Iter time:  0.30138955082926716


Train loss: 0.15448829531669617 at step: 144
Iter time:  0.3012365268336402


Train loss: 0.25056028366088867 at step: 145
Iter time:  0.30110704487767714


Train loss: 0.1977824568748474 at step: 146
Iter time:  0.3010360459758811


Train loss: 0.28787481784820557 at step: 147
Iter time:  0.3009162987170576


Train loss: 0.3566884398460388 at step: 148
Iter time:  0.30080390943063273


Train loss: 0.1390526443719864 at step: 149
Iter time:  0.3007002820904623


Train loss: 0.257719486951828 at step: 150
Iter time:  0.3005868434906006


Train loss: 0.19112074375152588 at step: 151
Iter time:  0.30048348729973595


Train loss: 0.2403256893157959 at step: 152
Iter time:  0.3004011386319211


Train loss: 0.17779111862182617 at step: 153
Iter time:  0.30029726028442383


Train loss: 0.19694454967975616 at step: 154
Iter time:  0.3001744096929377


Train loss: 0.18598347902297974 at step: 155
Iter time:  0.30006089825784005


Train loss: 0.16716346144676208 at step: 156
Iter time:  0.2999541759490967


Train loss: 0.18509045243263245 at step: 157
Iter time:  0.29986843182023165


Train loss: 0.22494524717330933 at step: 158
Iter time:  0.299765909774394


Train loss: 0.24605432152748108 at step: 159
Iter time:  0.29967077873038045


Train loss: 0.037262462079524994 at step: 160
Iter time:  0.29958803206682205


Train loss: 0.2924308180809021 at step: 161
Iter time:  0.29949542158138676


Train loss: 0.14888432621955872 at step: 162
Iter time:  0.29938599356898554


Train loss: 0.2255166471004486 at step: 163
Iter time:  0.2992917262703363


Train loss: 0.16626712679862976 at step: 164
Iter time:  0.2991907073230278


Train loss: 0.20206788182258606 at step: 165
Iter time:  0.29909458593888716


Train loss: 0.1788485050201416 at step: 166
Iter time:  0.29900179857231046


Train loss: 0.3135322332382202 at step: 167
Iter time:  0.29888935860045657


Train loss: 0.1460830718278885 at step: 168
Iter time:  0.2987876690569378


Train loss: 0.13138845562934875 at step: 169
Iter time:  0.2987590978836872


Train loss: 0.26456838846206665 at step: 170
Iter time:  0.29869637349072625


Train loss: 0.2565767467021942 at step: 171
Iter time:  0.29858651774668554


Train loss: 0.25968223810195923 at step: 172
Iter time:  0.2985567159430925


Train loss: 0.1937316656112671 at step: 173
Iter time:  0.29855187917720377


Train loss: 0.3351432681083679 at step: 174
Iter time:  0.2984815287864071


Train loss: 0.14805591106414795 at step: 175
Iter time:  0.29839375904628207


Train loss: 0.21224018931388855 at step: 176
Iter time:  0.2982835390351035


Train loss: 0.14665137231349945 at step: 177
Iter time:  0.2982082137953764


Train loss: 0.14888505637645721 at step: 178
Iter time:  0.2981035963872845


Train loss: 0.32953307032585144 at step: 179
Iter time:  0.29800127205236


Train loss: 0.23611801862716675 at step: 180
Iter time:  0.29790619214375813


Train loss: 0.15816184878349304 at step: 181
Iter time:  0.29778720133871006


Train loss: 0.2338554859161377 at step: 182
Iter time:  0.2976809451868246


Train loss: 0.22820362448692322 at step: 183
Iter time:  0.2975732276999885


Train loss: 0.16494405269622803 at step: 184
Iter time:  0.29746058453684265


Train loss: 0.40016821026802063 at step: 185
Iter time:  0.29734743350260967


Train loss: 0.25613242387771606 at step: 186
Iter time:  0.2972229116706438


Train loss: 0.17953385412693024 at step: 187
Iter time:  0.2971008767418683


Train loss: 0.3307749032974243 at step: 188
Iter time:  0.29697808052631136


Train loss: 0.47393253445625305 at step: 189
Iter time:  0.2968583901723226


Train loss: 0.15855157375335693 at step: 190
Iter time:  0.2967403211091694


Train loss: 0.2877575159072876 at step: 191
Iter time:  0.29662736423352626


Train loss: 0.27332425117492676 at step: 192
Iter time:  0.2965216251711051


Train loss: 0.18738408386707306 at step: 193
Iter time:  0.2964129855595722


Train loss: 0.277394562959671 at step: 194
Iter time:  0.296298910662071


Train loss: 0.022396007552742958 at step: 195
Iter time:  0.29622261952131224


Train loss: 0.1782056987285614 at step: 196
Iter time:  0.29617575966582005


Train loss: 0.39706099033355713 at step: 197
Iter time:  0.2961817562277547


Train loss: 0.18090122938156128 at step: 198
Iter time:  0.2961156825826626


Train loss: 0.1397707313299179 at step: 199
Iter time:  0.29605168194028003


Train loss: 0.2568154036998749 at step: 200
Iter time:  0.2959989762306213


Train loss: 0.19700109958648682 at step: 201
Iter time:  0.29602980613708496


Train loss: 0.3773776888847351 at step: 202
Iter time:  0.29595964143771936


Train loss: 0.14254114031791687 at step: 203
Iter time:  0.29588944336463663


Train loss: 0.21945348381996155 at step: 204
Iter time:  0.2958208930258657


Train loss: 0.2582516074180603 at step: 205
Iter time:  0.2957552653987233


Train loss: 0.07526116818189621 at step: 206
Iter time:  0.2956876395975502


Train loss: 0.1811104714870453 at step: 207
Iter time:  0.29561280743511403


Train loss: 0.04634566977620125 at step: 208
Iter time:  0.29553543718961567


Train loss: 0.21365457773208618 at step: 209
Iter time:  0.29569573037361985


Train loss: 0.18957209587097168 at step: 210
Iter time:  0.29562825929550895


Train loss: 0.04793660342693329 at step: 211
Iter time:  0.29558116338829293


Train loss: 0.1931106448173523 at step: 212
Iter time:  0.29552312954416815


Train loss: 0.20128867030143738 at step: 213
Iter time:  0.2955036051396473


Train loss: 0.17510779201984406 at step: 214
Iter time:  0.2954490073373385


Train loss: 0.0920039713382721 at step: 215
Iter time:  0.2953987487526827


Train loss: 0.12610071897506714 at step: 216
Iter time:  0.29536436553354617


Train loss: 0.16228386759757996 at step: 217
Iter time:  0.2953138878817932


Train loss: 0.11737142503261566 at step: 218
Iter time:  0.29526659545548467


Train loss: 0.16137784719467163 at step: 219
Iter time:  0.2952179277324241


Train loss: 0.0837349146604538 at step: 220
Iter time:  0.2951788447119973


Train loss: 0.07921983301639557 at step: 221
Iter time:  0.2951487513149486


Train loss: 0.15179526805877686 at step: 222
Iter time:  0.29508248427966693


Train loss: 0.17018704116344452 at step: 223
Iter time:  0.29502547696032333


Train loss: 0.1480388045310974 at step: 224
Iter time:  0.29498955820287975


Train loss: 0.15709716081619263 at step: 225
Iter time:  0.29492584546407064


Train loss: 0.02935628592967987 at step: 226
Iter time:  0.29498027278258737


Train loss: 0.055018022656440735 at step: 227
Iter time:  0.2949459059122901


Train loss: 0.06011729687452316 at step: 228
Iter time:  0.2949429750442505


Train loss: 0.09642203897237778 at step: 229
Iter time:  0.29498602625584497


Train loss: 0.07980667054653168 at step: 230
Iter time:  0.29495453005251676


Train loss: 0.0846543237566948 at step: 231
Iter time:  0.29490956599578194


Train loss: 0.21125364303588867 at step: 232
Iter time:  0.294848031011121


Train loss: 0.12830320000648499 at step: 233
Iter time:  0.29478748264230886


Train loss: 0.02294291742146015 at step: 234
Iter time:  0.294731716824393


Train loss: 0.19830027222633362 at step: 235
Iter time:  0.2946952373423475


Train loss: 0.10957624763250351 at step: 236
Iter time:  0.29464696423482084


Train loss: 0.01927841454744339 at step: 237
Iter time:  0.2946235107470162


Train loss: 0.02556338533759117 at step: 238
Iter time:  0.29462051091073943


Train loss: 0.0646129697561264 at step: 239
Iter time:  0.29462217785823297


Train loss: 0.030829790979623795 at step: 240
Iter time:  0.2945900231599808


Train loss: 0.10486526042222977 at step: 241
Iter time:  0.294538763054179


Train loss: 0.0337916761636734 at step: 242
Iter time:  0.2944787060918887


Train loss: 0.07458053529262543 at step: 243
Iter time:  0.2944464467680503


Train loss: 0.0805705338716507 at step: 244
Iter time:  0.294469419072886


Train loss: 0.10516154021024704 at step: 245
Iter time:  0.2944938134173958


Train loss: 0.021435528993606567 at step: 246
Iter time:  0.29443904539433924


Train loss: 0.00831765215843916 at step: 247
Iter time:  0.29443010337922254


Train loss: 0.05849452689290047 at step: 248
Iter time:  0.2943776326794778


Train loss: 0.02982521802186966 at step: 249
Iter time:  0.2943745396702165


Train loss: 0.03132171556353569 at step: 250
Iter time:  0.29433173847198485


Train loss: 0.013507959432899952 at step: 251
Iter time:  0.29428168122036996


Train loss: 0.02266291342675686 at step: 252
Iter time:  0.2942458826398093


Train loss: 0.07352089881896973 at step: 253
Iter time:  0.2941945447280944


Train loss: 0.06686646491289139 at step: 254
Iter time:  0.2941373971503551


Train loss: 0.09375861287117004 at step: 255
Iter time:  0.29409056644813686


Train loss: 0.14538100361824036 at step: 256
Iter time:  0.29405132681131363


Train loss: 0.09374932944774628 at step: 257
Iter time:  0.2940216676734301


Train loss: 0.004001088440418243 at step: 258
Iter time:  0.29397999316222906


Train loss: 0.05663130059838295 at step: 259
Iter time:  0.2939727794249546


Train loss: 0.14877104759216309 at step: 260
Iter time:  0.29392896065345175


Train loss: 0.023130211979150772 at step: 261
Iter time:  0.2938909421021911


Train loss: 0.029485300183296204 at step: 262
Iter time:  0.2938551438673762


Train loss: 0.050260789692401886 at step: 263
Iter time:  0.29382119251294736


Train loss: 0.06328260153532028 at step: 264
Iter time:  0.293784600315672


Train loss: 0.012204166501760483 at step: 265
Iter time:  0.2937543140267426


Train loss: 0.014732692390680313 at step: 266
Iter time:  0.29372552283724446


Train loss: 0.05932077765464783 at step: 267
Iter time:  0.2936837932143765


Train loss: 0.017218083143234253 at step: 268
Iter time:  0.2936490533956841


Train loss: 0.060266196727752686 at step: 269
Iter time:  0.2936117205921159


Train loss: 0.05183257907629013 at step: 270
Iter time:  0.29357329739464655


Train loss: 0.08326641470193863 at step: 271
Iter time:  0.2935203872483595


Train loss: 0.013637336902320385 at step: 272
Iter time:  0.29347944785566893


Train loss: 0.05370156094431877 at step: 273
Iter time:  0.29343060783414177


Train loss: 0.1027572751045227 at step: 274
Iter time:  0.29338828577612436


Train loss: 0.02483396977186203 at step: 275
Iter time:  0.2933670321377841


Train loss: 0.025836823508143425 at step: 276
Iter time:  0.2933192797329115


Train loss: 0.13550129532814026 at step: 277
Iter time:  0.29327435355754533


Train loss: 0.0637756884098053 at step: 278
Iter time:  0.29324246482025806


Train loss: 0.0029334567952901125 at step: 279
Iter time:  0.29323091643685506


Train loss: 0.02485182136297226 at step: 280
Iter time:  0.2931846022605896


Train loss: 0.05619785934686661 at step: 281
Iter time:  0.29314910304928166


Train loss: 0.09760583192110062 at step: 282
Iter time:  0.2931048041539835


Train loss: 0.09403757750988007 at step: 283
Iter time:  0.29307267522643393


Train loss: 0.02417743019759655 at step: 284
Iter time:  0.2930281766703431


Train loss: 0.00596793694421649 at step: 285
Iter time:  0.29299130105135734


Train loss: 0.07374274730682373 at step: 286
Iter time:  0.29294601353732025


Train loss: 0.044612668454647064 at step: 287
Iter time:  0.2928980028172403


Train loss: 0.06802035868167877 at step: 288
Iter time:  0.2928605377674103


Train loss: 0.021820157766342163 at step: 289
Iter time:  0.2928241701687084


Train loss: 0.003693574108183384 at step: 290
Iter time:  0.29279577567659576


Train loss: 0.006652637384831905 at step: 291
Iter time:  0.2928276021046327


Train loss: 0.056651897728443146 at step: 292
Iter time:  0.29281239721873037


Train loss: 0.01194610632956028 at step: 293
Iter time:  0.2928233805776863


Train loss: 0.04712696000933647 at step: 294
Iter time:  0.29278978441848236


Train loss: 0.06047062575817108 at step: 295
Iter time:  0.29276951531232415


Train loss: 0.05348363518714905 at step: 296
Iter time:  0.2927298843860626


Train loss: 0.0760897696018219 at step: 297
Iter time:  0.29269169075320467


Train loss: 0.033287256956100464 at step: 298
Iter time:  0.292651364467288


Train loss: 0.05637703090906143 at step: 299
Iter time:  0.29261122419682634


Train loss: 0.04700137674808502 at step: 300
Iter time:  0.29257599751154584


Train loss: 0.009086267091333866 at step: 301
Iter time:  0.29255377889867634


Train loss: 0.014979490078985691 at step: 302
Iter time:  0.2925643470903106


Train loss: 0.063510462641716 at step: 303
Iter time:  0.29258534931900476


Train loss: 0.020819898694753647 at step: 304
Iter time:  0.2925725563576347


Train loss: 0.007402140647172928 at step: 305
Iter time:  0.2925486939852355


Train loss: 0.03209443390369415 at step: 306
Iter time:  0.2925228496002995


Train loss: 0.07681742310523987 at step: 307
Iter time:  0.29248229999107334


Train loss: 0.0037567373365163803 at step: 308
Iter time:  0.29244587251118254


Train loss: 0.025834478437900543 at step: 309
Iter time:  0.2924215307513487


Train loss: 0.058210257440805435 at step: 310
Iter time:  0.2924224538187827


Train loss: 0.004112510941922665 at step: 311
Iter time:  0.29239600724346


Train loss: 0.004334907978773117 at step: 312
Iter time:  0.29237369772715444


Train loss: 0.01012059673666954 at step: 313
Iter time:  0.29234064653658637


Train loss: 0.07610342651605606 at step: 314
Iter time:  0.29230723487343757


Train loss: 0.0529366172850132 at step: 315
Iter time:  0.29229723612467445


Train loss: 0.002802071627229452 at step: 316
Iter time:  0.2922657350950603


Train loss: 0.001685299794189632 at step: 317
Iter time:  0.292240548209061


Train loss: 0.016812952235341072 at step: 318
Iter time:  0.29221447458807026


Train loss: 0.011347012594342232 at step: 319
Iter time:  0.2921869762265196


Train loss: 0.001502129714936018 at step: 320
Iter time:  0.2921700321137905


Train loss: 0.013478005304932594 at step: 321
Iter time:  0.2921764642650093


Train loss: 0.003660602727904916 at step: 322
Iter time:  0.29214350407167994


Train loss: 0.018735326826572418 at step: 323
Iter time:  0.2921145006599072


Train loss: 0.016087017953395844 at step: 324
Iter time:  0.2920752896202935


Train loss: 0.002411450957879424 at step: 325
Iter time:  0.2920451435675988


Train loss: 0.05072483792901039 at step: 326
Iter time:  0.2920238401260844


Train loss: 0.022972866892814636 at step: 327
Iter time:  0.2919913118403257


Train loss: 0.021390508860349655 at step: 328
Iter time:  0.2919545319022202


Train loss: 0.004481417126953602 at step: 329
Iter time:  0.29193387640283464


Train loss: 0.04725472629070282 at step: 330
Iter time:  0.2919978076761419


Train loss: 0.006071646232157946 at step: 331
Iter time:  0.2920209677197782


Train loss: 0.002078430727124214 at step: 332
Iter time:  0.291987559881555


Train loss: 0.004420874174684286 at step: 333
Iter time:  0.2919526057200389


Train loss: 0.06466558575630188 at step: 334
Iter time:  0.29192385273779226


Train loss: 0.0007489660056307912 at step: 335
Iter time:  0.2918886718465321


Train loss: 0.0017330111004412174 at step: 336
Iter time:  0.29185659686724347


Train loss: 0.06262101233005524 at step: 337
Iter time:  0.29182393402303364


Train loss: 0.06676619499921799 at step: 338
Iter time:  0.2917931079864502


Train loss: 0.002028112532570958 at step: 339
Iter time:  0.2917779371098431


Train loss: 0.04689377173781395 at step: 340
Iter time:  0.29175617274116067


Train loss: 0.0043983315117657185 at step: 341
Iter time:  0.29172927473297566


Train loss: 0.05065199360251427 at step: 342
Iter time:  0.29170349676009505


Train loss: 0.06010248139500618 at step: 343
Iter time:  0.2917224248713724


Train loss: 0.04579728841781616 at step: 344
Iter time:  0.2916976407516834


Train loss: 0.0034041067119687796 at step: 345
Iter time:  0.2916672250498896


Train loss: 0.0009632271248847246 at step: 346
Iter time:  0.29164209117779155


Train loss: 0.0007156029460020363 at step: 347
Iter time:  0.29163043918114917


Train loss: 0.002988917985931039 at step: 348
Iter time:  0.2916048676118083


Train loss: 0.003460379783064127 at step: 349
Iter time:  0.2915724731106471


Train loss: 0.004608926363289356 at step: 350
Iter time:  0.29154301370893204


Train loss: 0.0014538471587002277 at step: 351
Iter time:  0.29151845929289816


Train loss: 0.001045796787366271 at step: 352
Iter time:  0.2915005318143151


Train loss: 0.016074974089860916 at step: 353
Iter time:  0.2915004907181175


Train loss: 0.012149568647146225 at step: 354
Iter time:  0.29150795532485185


Train loss: 0.0023007229901850224 at step: 355
Iter time:  0.2914846715792804


Train loss: 0.0071224914863705635 at step: 356
Iter time:  0.29146312528781676


Train loss: 0.04934215545654297 at step: 357
Iter time:  0.2914394591034961


Train loss: 0.005308182910084724 at step: 358
Iter time:  0.2914176413466811


Train loss: 0.00563453696668148 at step: 359
Iter time:  0.2913895735833638


Train loss: 0.002300827531144023 at step: 360
Iter time:  0.2913604431682163


Train loss: 0.0019392849644646049 at step: 361
Iter time:  0.2913379411618135


Train loss: 0.019743679091334343 at step: 362
Iter time:  0.29132077904695963


Train loss: 0.059850458055734634 at step: 363
Iter time:  0.2912992997602983


Train loss: 0.001596795511431992 at step: 364
Iter time:  0.2912956102863773


Train loss: 0.010745774023234844 at step: 365
Iter time:  0.2912782002801764


Train loss: 0.0008081021369434893 at step: 366
Iter time:  0.29125636457745496


Train loss: 0.0274713896214962 at step: 367
Iter time:  0.29122974307400656


Train loss: 0.0033058938570320606 at step: 368
Iter time:  0.2912016945040744


Train loss: 0.018543686717748642 at step: 369
Iter time:  0.2911965698407594


Train loss: 0.014075553975999355 at step: 370
Iter time:  0.2911775621207985


Train loss: 0.001601984491571784 at step: 371
Iter time:  0.2911491381190215


Train loss: 0.0005781432264484465 at step: 372
Iter time:  0.29113039662761075


Train loss: 0.0010690012713894248 at step: 373
Iter time:  0.2911171516847994


Train loss: 0.0006155744194984436 at step: 374
Iter time:  0.29109606513365066


Train loss: 0.09163886308670044 at step: 375
Iter time:  0.2910873699188232


Found 5273 trainable_data in total.
