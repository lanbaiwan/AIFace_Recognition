Set Seed: 0
Training options:
----------------- Options ---------------
            GaussianNoise: False                         
            RandomErasing: False                         
                     arch: CLIP:ViT-L/14                 	[default: res50]
               batch_size: 16                            	[default: 256]
                    beta1: 0.9                           
                blur_prob: 0.5                           
                 blur_sig: 0.0, 2.0                      
          checkpoints_dir: ./checkpoints                 
                class_bal: None                          
                 cropSize: 224                           
                 data_aug: True                          
               data_label: train                         
                data_mode: ours                          
          earlystop_epoch: 3                             
              epoch_count: 1                             
           fake_list_path: /home/data/szk/home/data/szk/our_dataset_10_21/1_fake	[default: None]
             fix_backbone: True                          	[default: False]
                focalloss: False                         
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                  isTrain: True                          
               jpg_method: cv2,pil                       
                 jpg_prob: 0.5                           
                 jpg_qual: 30, 100                       
               last_epoch: -1                            
                 loadSize: 224                           
                loss_freq: 400                           
                       lr: 0.0001                        
                     mode: binary                        
                     name: clip_vitl14-2024-10-25-11-56-48	[default: experiment_name]
                    niter: 100                           
                  no_crop: True                          
                  no_flip: False                         
              num_threads: 4                             
                    optim: adam                          
           real_list_path: /home/data/szk/home/data/szk/our_dataset_10_21/0_real	[default: None]
                rz_interp: bilinear                      
          save_epoch_freq: 1                             
           serial_batches: False                         
                   suffix: time                          	[default: ]
              train_split: train                         
                val_split: val                           
       wang2020_data_path: None                          
             weight_decay: 0.0                           
----------------- End -------------------
Directory ./checkpoints/clip_vitl14-2024-10-25-11-56-48 is created.
-----------------------------------------
Validation options:
GaussianNoise: False
RandomErasing: False
arch: CLIP:ViT-L/14
batch_size: 16
beta1: 0.9
blur_prob: 0.5
blur_sig: [0.0, 2.0]
checkpoints_dir: ./checkpoints
class_bal: None
cropSize: 224
data_aug: False
data_label: val
data_mode: ours
earlystop_epoch: 3
epoch_count: 1
fake_list_path: /home/data/szk/home/data/szk/our_dataset_10_21/1_fake
fix_backbone: True
focalloss: False
gpu_ids: [0]
init_gain: 0.02
init_type: normal
isTrain: False
jpg_method: ['cv2', 'pil']
jpg_prob: 0.5
jpg_qual: [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]
last_epoch: -1
loadSize: 224
loss_freq: 400
lr: 0.0001
mode: binary
name: clip_vitl14-2024-10-25-11-56-48
niter: 100
no_crop: True
no_flip: True
no_resize: False
num_threads: 4
optim: adam
randomErasing: False
real_list_path: /home/data/szk/home/data/szk/our_dataset_10_21/0_real
rz_interp: ['bilinear']
save_epoch_freq: 1
serial_batches: True
suffix: time
train_split: train
val_split: val
wang2020_data_path: None
weight_decay: 0.0
----------------- End -------------------
Choose layer: 23 for cls embedding
Not add Gaussian noise to the feature embedding.
Not use random erasing.
Use BCELoss!
-----------------------------------------
Train Dataset:
Shuffle the dataset.
Not use crop.
Use RandomHorizontalFlip.
Resize image to (224,224)  using  ['bilinear']  method.
Use cut func
Using blur and jpeg augment.
mean and std stats are from:  clip
using Official CLIP's normalization
-----------------------------------------
Valid Dataset:
Not shuffle the dataset.
Not use crop.
Not use RandomHorizontalFlip.
Resize image to (224,224)  using  ['bilinear']  method.
Use cut func
Do not use blur and jpeg augment.
mean and std stats are from:  clip
using Official CLIP's normalization
----------------- End -------------------
Length of data loader: 422
Train loss: 0.47600048780441284 at step: 400
Iter time:  0.13659043729305267
saving the model at the end of epoch 0
Length of dataset: 60

(Val @ epoch 0) acc: 0.85068349106204; ap: 0.9252562687883386
Validation accuracy increased (-inf --> 0.850683).  Saving model ...
Train loss: 0.594823956489563 at step: 800
Iter time:  0.14893558382987976
saving the model at the end of epoch 1
Length of dataset: 60

(Val @ epoch 1) acc: 0.882229232386961; ap: 0.9474297836143049
Validation accuracy increased (0.850683 --> 0.882229).  Saving model ...
Train loss: 0.18362067639827728 at step: 1200
Iter time:  0.1533581566810608
saving the model at the end of epoch 2
Length of dataset: 60

(Val @ epoch 2) acc: 0.8916929547844374; ap: 0.9566432441676618
Validation accuracy increased (0.882229 --> 0.891693).  Saving model ...
Train loss: 0.13489583134651184 at step: 1600
Iter time:  0.15555335387587546
saving the model at the end of epoch 3
Length of dataset: 60

(Val @ epoch 3) acc: 0.8990536277602523; ap: 0.9654516171136164
Validation accuracy increased (0.891693 --> 0.899054).  Saving model ...
Train loss: 0.36000949144363403 at step: 2000
Iter time:  0.1569726060628891
saving the model at the end of epoch 4
Length of dataset: 60

(Val @ epoch 4) acc: 0.9106203995793901; ap: 0.9707437537607425
Validation accuracy increased (0.899054 --> 0.910620).  Saving model ...
Train loss: 0.19009363651275635 at step: 2400
Iter time:  0.1578416652480761
saving the model at the end of epoch 5
Length of dataset: 60

(Val @ epoch 5) acc: 0.9148264984227129; ap: 0.9730640785400583
Validation accuracy increased (0.910620 --> 0.914826).  Saving model ...
Train loss: 0.14349140226840973 at step: 2800
Iter time:  0.158496105160032
saving the model at the end of epoch 6
Length of dataset: 60

(Val @ epoch 6) acc: 0.9200841219768665; ap: 0.9747312236824491
Validation accuracy increased (0.914826 --> 0.920084).  Saving model ...
Train loss: 0.3040865659713745 at step: 3200
Iter time:  0.159010713621974
saving the model at the end of epoch 7
Length of dataset: 60

(Val @ epoch 7) acc: 0.9242902208201893; ap: 0.976047166705157
Validation accuracy increased (0.920084 --> 0.924290).  Saving model ...
Train loss: 0.307187557220459 at step: 3600
Iter time:  0.159594754046864
saving the model at the end of epoch 8
Length of dataset: 60

(Val @ epoch 8) acc: 0.9232386961093586; ap: 0.9775820663047013
EarlyStopping counter: 1 out of 3
Train loss: 0.3886238634586334 at step: 4000
Iter time:  0.16011050474643707
saving the model at the end of epoch 9
Length of dataset: 60

(Val @ epoch 9) acc: 0.9200841219768665; ap: 0.9782397470392912
EarlyStopping counter: 2 out of 3
Train loss: 0.39966848492622375 at step: 4400
Iter time:  0.16056097355755894
saving the model at the end of epoch 10
Length of dataset: 60

(Val @ epoch 10) acc: 0.9263932702418507; ap: 0.9793661229928934
Validation accuracy increased (0.924290 --> 0.926393).  Saving model ...
Train loss: 0.09038382768630981 at step: 4800
Iter time:  0.16091923922300339
saving the model at the end of epoch 11
Length of dataset: 60

(Val @ epoch 11) acc: 0.9295478443743428; ap: 0.9802586982808752
Validation accuracy increased (0.926393 --> 0.929548).  Saving model ...
Train loss: 0.23975953459739685 at step: 5200
Iter time:  0.16122807319347676
saving the model at the end of epoch 12
Length of dataset: 60

(Val @ epoch 12) acc: 0.9348054679284963; ap: 0.9804076780949484
Validation accuracy increased (0.929548 --> 0.934805).  Saving model ...
Train loss: 0.10616183280944824 at step: 5600
Iter time:  0.16142577516181128
saving the model at the end of epoch 13
Length of dataset: 60

(Val @ epoch 13) acc: 0.9295478443743428; ap: 0.9811352418621974
EarlyStopping counter: 1 out of 3
Train loss: 0.09762082993984222 at step: 6000
Iter time:  0.16171196500460308
saving the model at the end of epoch 14
Length of dataset: 60

(Val @ epoch 14) acc: 0.9284963196635121; ap: 0.9813159392271835
EarlyStopping counter: 2 out of 3
Train loss: 0.30925601720809937 at step: 6400
Iter time:  0.16215940542519092
saving the model at the end of epoch 15
Length of dataset: 60

(Val @ epoch 15) acc: 0.9327024185068349; ap: 0.982017422343772
EarlyStopping counter: 3 out of 3
Learning rate dropped by 10, continue training...
Train loss: 0.1858675479888916 at step: 6800
Iter time:  0.1623455241497825
saving the model at the end of epoch 16
Length of dataset: 60

(Val @ epoch 16) acc: 0.9327024185068349; ap: 0.9819724771697169
Validation accuracy increased (-inf --> 0.932702).  Saving model ...
Train loss: 0.256317675113678 at step: 7200
Iter time:  0.1624642492002911
saving the model at the end of epoch 17
Length of dataset: 60

(Val @ epoch 17) acc: 0.9327024185068349; ap: 0.9819354181001634
EarlyStopping counter: 1 out of 3
Train loss: 0.18145817518234253 at step: 7600
Iter time:  0.16250334814975137
Train loss: 0.09318879246711731 at step: 8000
Iter time:  0.16122788637876512
saving the model at the end of epoch 18
Length of dataset: 60

(Val @ epoch 18) acc: 0.9337539432176656; ap: 0.9818651687686664
EarlyStopping counter: 2 out of 3
Train loss: 0.1303185224533081 at step: 8400
Iter time:  0.1613398001307533
saving the model at the end of epoch 19
Length of dataset: 60

(Val @ epoch 19) acc: 0.9316508937960042; ap: 0.9819310733275494
EarlyStopping counter: 3 out of 3
Learning rate dropped by 10, continue training...
Train loss: 0.404856413602829 at step: 8800
Iter time:  0.16139322711662812
saving the model at the end of epoch 20
Length of dataset: 60

(Val @ epoch 20) acc: 0.9316508937960042; ap: 0.981941821329927
Validation accuracy increased (-inf --> 0.931651).  Saving model ...
Train loss: 0.2102264165878296 at step: 9200
Iter time:  0.16148065326006517
saving the model at the end of epoch 21
Length of dataset: 60

(Val @ epoch 21) acc: 0.9327024185068349; ap: 0.9819161717603478
EarlyStopping counter: 1 out of 3
Train loss: 0.06993254274129868 at step: 9600
Iter time:  0.16156422843535742
saving the model at the end of epoch 22
Length of dataset: 60

(Val @ epoch 22) acc: 0.9316508937960042; ap: 0.9819031270772519
EarlyStopping counter: 2 out of 3
Train loss: 0.17494679987430573 at step: 10000
Iter time:  0.1616361692428589
saving the model at the end of epoch 23
Length of dataset: 60

(Val @ epoch 23) acc: 0.9337539432176656; ap: 0.9819243195755001
Validation accuracy increased (0.931651 --> 0.933754).  Saving model ...
Train loss: 0.17619816958904266 at step: 10400
Iter time:  0.1616792883322789
saving the model at the end of epoch 24
Length of dataset: 60

(Val @ epoch 24) acc: 0.9337539432176656; ap: 0.9819209356451031
EarlyStopping counter: 1 out of 3
Train loss: 0.3395211100578308 at step: 10800
Iter time:  0.16171792935442042
saving the model at the end of epoch 25
Length of dataset: 60

(Val @ epoch 25) acc: 0.9327024185068349; ap: 0.981932347663074
EarlyStopping counter: 2 out of 3
Train loss: 0.36401867866516113 at step: 11200
Iter time:  0.16176461002656392
saving the model at the end of epoch 26
Length of dataset: 60

(Val @ epoch 26) acc: 0.9327024185068349; ap: 0.9819479319036449
EarlyStopping counter: 3 out of 3
Early stopping.
Training completed in 30 minutes and 47 seconds.
