Set Seed: 0
Training options:
----------------- Options ---------------
            GaussianNoise: True                          	[default: False]
                     arch: CLIP:ViT-L/14                 	[default: res50]
               batch_size: 16                            	[default: 256]
                    beta1: 0.9                           
                blur_prob: 0.5                           
                 blur_sig: 0.0, 2.0                      
          checkpoints_dir: ./checkpoints                 
                class_bal: None                          
                 cropSize: 224                           
                 data_aug: True                          
               data_label: train                         
                data_mode: ours                          
          earlystop_epoch: 3                             
              epoch_count: 1                             
           fake_list_path: /home/data/szk/our_dataset/1_fake	[default: None]
             fix_backbone: True                          	[default: False]
                focalloss: True                          	[default: False]
                  gpu_ids: 7                             	[default: 0]
                init_gain: 0.02                          
                init_type: normal                        
                  isTrain: True                          
               jpg_method: cv2,pil                       
                 jpg_prob: 0.5                           
                 jpg_qual: 30, 100                       
               last_epoch: -1                            
                 loadSize: 224                           
                loss_freq: 400                           
                       lr: 0.0001                        
                     mode: binary                        
                     name: clip_vitl14-2024-09-28-16-48-42	[default: experiment_name]
                    niter: 100                           
                  no_crop: True                          
                  no_flip: False                         
              num_threads: 4                             
                    optim: adam                          
           real_list_path: /home/data/szk/our_dataset/0_real	[default: None]
                rz_interp: bilinear                      
          save_epoch_freq: 1                             
           serial_batches: False                         
                   suffix: time                          	[default: ]
              train_split: train                         
                val_split: val                           
       wang2020_data_path: None                          
             weight_decay: 0.0                           
----------------- End -------------------
Directory ./checkpoints/clip_vitl14-2024-09-28-16-48-42 is created.
-----------------------------------------
Validation options:
GaussianNoise: False
arch: CLIP:ViT-L/14
batch_size: 16
beta1: 0.9
blur_prob: 0.5
blur_sig: [0.0, 2.0]
checkpoints_dir: ./checkpoints
class_bal: None
cropSize: 224
data_aug: False
data_label: val
data_mode: ours
earlystop_epoch: 3
epoch_count: 1
fake_list_path: /home/data/szk/our_dataset/1_fake
fix_backbone: True
focalloss: True
gpu_ids: [7]
init_gain: 0.02
init_type: normal
isTrain: False
jpg_method: ['cv2', 'pil']
jpg_prob: 0.5
jpg_qual: [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]
last_epoch: -1
loadSize: 224
loss_freq: 400
lr: 0.0001
mode: binary
name: clip_vitl14-2024-09-28-16-48-42
niter: 100
no_crop: True
no_flip: True
no_resize: False
num_threads: 4
optim: adam
real_list_path: /home/data/szk/our_dataset/0_real
rz_interp: ['bilinear']
save_epoch_freq: 1
serial_batches: True
suffix: time
train_split: train
val_split: val
wang2020_data_path: None
weight_decay: 0.0
----------------- End -------------------
Choose layer: 23 for cls embedding
Add Gaussian noise to the feature embedding when training with std: 0.01
Use FocalLoss!
-----------------------------------------
Train Dataset:
Shuffle the dataset.
Not use crop.
Use RandomHorizontalFlip.
Resize image to (224,224)  using  ['bilinear']  method.
Using blur and jpeg augment.
mean and std stats are from:  clip
using Official CLIP's normalization
-----------------------------------------
Valid Dataset:
Not shuffle the dataset.
Not use crop.
Not use RandomHorizontalFlip.
Resize image to (224,224)  using  ['bilinear']  method.
Do not use blur and jpeg augment.
mean and std stats are from:  clip
using Official CLIP's normalization
----------------- End -------------------
Length of data loader: 492
Train loss: 0.029760880395770073 at step: 400
Iter time:  0.13571090757846832
saving the model at the end of epoch 0
Length of dataset: 55

(Val @ epoch 0) acc: 0.8401826484018264; ap: 0.9392919647991644
Validation accuracy increased (-inf --> 0.840183).  Saving model ...
Train loss: 0.038897573947906494 at step: 800
Iter time:  0.1474437591433525
saving the model at the end of epoch 1
Length of dataset: 55

(Val @ epoch 1) acc: 0.8698630136986302; ap: 0.9596604248034756
Validation accuracy increased (0.840183 --> 0.869863).  Saving model ...
Train loss: 0.02330295741558075 at step: 1200
Iter time:  0.1516271126270294
saving the model at the end of epoch 2
Length of dataset: 55

(Val @ epoch 2) acc: 0.8961187214611872; ap: 0.967058452795064
Validation accuracy increased (0.869863 --> 0.896119).  Saving model ...
Train loss: 0.024380939081311226 at step: 1600
Iter time:  0.15364652752876282
saving the model at the end of epoch 3
Length of dataset: 55

(Val @ epoch 3) acc: 0.9121004566210046; ap: 0.9708802879642711
Validation accuracy increased (0.896119 --> 0.912100).  Saving model ...
Train loss: 0.023040592670440674 at step: 2000
Iter time:  0.1548721228837967
Train loss: 0.01347269769757986 at step: 2400
Iter time:  0.15177829871575038
saving the model at the end of epoch 4
Length of dataset: 55

(Val @ epoch 4) acc: 0.9178082191780822; ap: 0.9734482894630268
Validation accuracy increased (0.912100 --> 0.917808).  Saving model ...
Train loss: 0.035267215222120285 at step: 2800
Iter time:  0.1529389147247587
saving the model at the end of epoch 5
Length of dataset: 55

(Val @ epoch 5) acc: 0.9223744292237442; ap: 0.9746562317034226
Validation accuracy increased (0.917808 --> 0.922374).  Saving model ...
Train loss: 0.012251628562808037 at step: 3200
Iter time:  0.15378482930362225
saving the model at the end of epoch 6
Length of dataset: 55

(Val @ epoch 6) acc: 0.9223744292237442; ap: 0.9766630929060309
EarlyStopping counter: 1 out of 3
Train loss: 0.019848037511110306 at step: 3600
Iter time:  0.15455065687497457
saving the model at the end of epoch 7
Length of dataset: 55

(Val @ epoch 7) acc: 0.9189497716894978; ap: 0.9776806159792801
EarlyStopping counter: 2 out of 3
Train loss: 0.009771397337317467 at step: 4000
Iter time:  0.15513308185338975
Train loss: 0.021782921627163887 at step: 4400
Iter time:  0.15338687165216966
saving the model at the end of epoch 8
Length of dataset: 55

(Val @ epoch 8) acc: 0.9315068493150684; ap: 0.9787184850210863
Validation accuracy increased (0.922374 --> 0.931507).  Saving model ...
Train loss: 0.04286740720272064 at step: 4800
Iter time:  0.15393138999740283
saving the model at the end of epoch 9
Length of dataset: 55

(Val @ epoch 9) acc: 0.9315068493150684; ap: 0.979577348102682
EarlyStopping counter: 1 out of 3
Train loss: 0.06131461635231972 at step: 5200
Iter time:  0.15439066093701584
saving the model at the end of epoch 10
Length of dataset: 55

(Val @ epoch 10) acc: 0.9315068493150684; ap: 0.9795919754041299
EarlyStopping counter: 2 out of 3
Train loss: 0.020620353519916534 at step: 5600
Iter time:  0.15483958610466547
saving the model at the end of epoch 11
Length of dataset: 55

(Val @ epoch 11) acc: 0.9360730593607306; ap: 0.9801834023192386
Validation accuracy increased (0.931507 --> 0.936073).  Saving model ...
Train loss: 0.00803820788860321 at step: 6000
Iter time:  0.15522726464271547
saving the model at the end of epoch 12
Length of dataset: 55

(Val @ epoch 12) acc: 0.932648401826484; ap: 0.9809460758298824
EarlyStopping counter: 1 out of 3
Train loss: 0.016036463901400566 at step: 6400
Iter time:  0.15558011375367642
Train loss: 0.012677133083343506 at step: 6800
Iter time:  0.15441757440567017
saving the model at the end of epoch 13
Length of dataset: 55

(Val @ epoch 13) acc: 0.934931506849315; ap: 0.9812818234955508
EarlyStopping counter: 2 out of 3
Train loss: 0.0203983336687088 at step: 7200
Iter time:  0.15477472450998095
saving the model at the end of epoch 14
Length of dataset: 55

(Val @ epoch 14) acc: 0.932648401826484; ap: 0.9814951785938364
EarlyStopping counter: 3 out of 3
Learning rate dropped by 10, continue training...
Train loss: 0.018523048609495163 at step: 7600
Iter time:  0.1550478677686892
saving the model at the end of epoch 15
Length of dataset: 55

(Val @ epoch 15) acc: 0.9360730593607306; ap: 0.9814379663365782
Validation accuracy increased (-inf --> 0.936073).  Saving model ...
Train loss: 0.015244808048009872 at step: 8000
Iter time:  0.15531726145744323
saving the model at the end of epoch 16
Length of dataset: 55

(Val @ epoch 16) acc: 0.9372146118721462; ap: 0.9815824895178195
EarlyStopping counter: 1 out of 3
Train loss: 0.02849278412759304 at step: 8400
Iter time:  0.15555279158410573
Train loss: 0.009248418733477592 at step: 8800
Iter time:  0.15468203276395798
saving the model at the end of epoch 17
Length of dataset: 55

(Val @ epoch 17) acc: 0.9383561643835616; ap: 0.981595478295902
Validation accuracy increased (0.936073 --> 0.938356).  Saving model ...
Train loss: 0.011004544794559479 at step: 9200
Iter time:  0.15490754272626794
saving the model at the end of epoch 18
Length of dataset: 55

(Val @ epoch 18) acc: 0.9383561643835616; ap: 0.9815189941576062
EarlyStopping counter: 1 out of 3
Train loss: 0.006610821932554245 at step: 9600
Iter time:  0.1551046094795068
saving the model at the end of epoch 19
Length of dataset: 55

(Val @ epoch 19) acc: 0.9383561643835616; ap: 0.9815326573446753
EarlyStopping counter: 2 out of 3
Train loss: 0.016604643315076828 at step: 10000
Iter time:  0.15530420846939086
saving the model at the end of epoch 20
Length of dataset: 55

(Val @ epoch 20) acc: 0.9383561643835616; ap: 0.9815481159085432
EarlyStopping counter: 3 out of 3
Learning rate dropped by 10, continue training...
Train loss: 0.015418175607919693 at step: 10400
Iter time:  0.15549923472679578
Train loss: 0.029951274394989014 at step: 10800
Iter time:  0.15479096520830085
saving the model at the end of epoch 21
Length of dataset: 55

(Val @ epoch 21) acc: 0.9394977168949772; ap: 0.9815787981472944
Validation accuracy increased (-inf --> 0.939498).  Saving model ...
Train loss: 0.0187919270247221 at step: 11200
Iter time:  0.15496983506849835
saving the model at the end of epoch 22
Length of dataset: 55

(Val @ epoch 22) acc: 0.9394977168949772; ap: 0.9815853827299809
EarlyStopping counter: 1 out of 3
Train loss: 0.0211118645966053 at step: 11600
Iter time:  0.1551706556205092
saving the model at the end of epoch 23
Length of dataset: 55

(Val @ epoch 23) acc: 0.9394977168949772; ap: 0.9815768733106435
EarlyStopping counter: 2 out of 3
Train loss: 0.02332622930407524 at step: 12000
Iter time:  0.15533217527468998
saving the model at the end of epoch 24
Length of dataset: 55

(Val @ epoch 24) acc: 0.9383561643835616; ap: 0.9815801152664264
EarlyStopping counter: 3 out of 3
Early stopping.
Training completed in 31 minutes and 53 seconds.
