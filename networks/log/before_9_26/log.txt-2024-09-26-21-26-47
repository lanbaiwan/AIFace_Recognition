layer 23 cls embedding+batchsize=16+no fc bias

Set Seed: 0
----------------- Options ---------------
                     arch: CLIP:ViT-L/14                 	[default: res50]
               batch_size: 16                            	[default: 256]
                    beta1: 0.9                           
                blur_prob: 0.5                           
                 blur_sig: 0.0, 2.0                      
          checkpoints_dir: ./checkpoints                 
                class_bal: None                          
                 cropSize: 224                           
                 data_aug: False                         
               data_label: train                         
                data_mode: ours                          
          earlystop_epoch: 3                             
              epoch_count: 1                             
           fake_list_path: /home/data/szk/our_dataset/1_fake	[default: None]
             fix_backbone: True                          	[default: False]
                focalloss: False                         
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                  isTrain: True                          	[default: None]
               jpg_method: cv2,pil                       
                 jpg_prob: 0.5                           
                 jpg_qual: 30, 100                       
               last_epoch: -1                            
                 loadSize: 224                           
                loss_freq: 400                           
                       lr: 0.0001                        
                     mode: binary                        
                     name: clip_vitl14-2024-09-26-21-26-47	[default: experiment_name]
                    niter: 100                           
                  no_crop: False                         
                  no_flip: False                         
              num_threads: 4                             
                    optim: adam                          
           real_list_path: /home/data/szk/our_dataset/0_real	[default: None]
           resize_or_crop: scale_and_crop                
                rz_interp: bilinear                      
          save_epoch_freq: 1                             
           serial_batches: False                         
                   suffix: time                          	[default: ]
              train_split: train                         
                val_split: val                           
       wang2020_data_path: None                          
             weight_decay: 0.0                           
----------------- End -------------------
Directory ./checkpoints/clip_vitl14-2024-09-26-21-26-47 is created.
Choose layer: 23 for cls embedding
Use BCELoss!
Use RandomHorizontalFlip
mean and std stats are from:  clip
using Official CLIP's normalization
Resize image to (224,224)
mean and std stats are from:  clip
using Official CLIP's normalization
Length of data loader: 178
saving the model at the end of epoch 0
Length of dataset: 20

(Val @ epoch 0) acc: 0.7619047619047619; ap: 0.7915450357692315
Validation accuracy increased (-inf --> 0.761905).  Saving model ...
saving the model at the end of epoch 1
Length of dataset: 20

(Val @ epoch 1) acc: 0.8031746031746032; ap: 0.8579834407699475
Validation accuracy increased (0.761905 --> 0.803175).  Saving model ...
Train loss: 0.5131755471229553 at step: 400
Iter time:  0.15778377771377564
saving the model at the end of epoch 2
Length of dataset: 20

(Val @ epoch 2) acc: 0.8063492063492064; ap: 0.8711855058239549
Validation accuracy increased (0.803175 --> 0.806349).  Saving model ...
saving the model at the end of epoch 3
Length of dataset: 20

(Val @ epoch 3) acc: 0.8476190476190476; ap: 0.9156006964250493
Validation accuracy increased (0.806349 --> 0.847619).  Saving model ...
Train loss: 0.33101770281791687 at step: 800
Iter time:  0.15718701362609863
saving the model at the end of epoch 4
Length of dataset: 20

(Val @ epoch 4) acc: 0.8412698412698413; ap: 0.8988095692894424
EarlyStopping counter: 1 out of 3
saving the model at the end of epoch 5
Length of dataset: 20

(Val @ epoch 5) acc: 0.8444444444444444; ap: 0.9014207397078887
EarlyStopping counter: 2 out of 3
Train loss: 0.4524698853492737 at step: 1200
Iter time:  0.157425594329834
saving the model at the end of epoch 6
Length of dataset: 20

(Val @ epoch 6) acc: 0.8317460317460318; ap: 0.8991782397486459
EarlyStopping counter: 3 out of 3
Learning rate dropped by 10, continue training...
saving the model at the end of epoch 7
Length of dataset: 20

(Val @ epoch 7) acc: 0.8507936507936508; ap: 0.9009642960343592
Validation accuracy increased (-inf --> 0.850794).  Saving model ...
Train loss: 0.4120687246322632 at step: 1600
Iter time:  0.15734870225191117
saving the model at the end of epoch 8
Length of dataset: 20

(Val @ epoch 8) acc: 0.8539682539682539; ap: 0.9087446846279063
Validation accuracy increased (0.850794 --> 0.853968).  Saving model ...
saving the model at the end of epoch 9
Length of dataset: 20

(Val @ epoch 9) acc: 0.8539682539682539; ap: 0.917400530556357
EarlyStopping counter: 1 out of 3
saving the model at the end of epoch 10
Length of dataset: 20

(Val @ epoch 10) acc: 0.8412698412698413; ap: 0.8972348664202441
EarlyStopping counter: 2 out of 3
Train loss: 0.2622181475162506 at step: 2000
Iter time:  0.15945513343811035
saving the model at the end of epoch 11
Length of dataset: 20

(Val @ epoch 11) acc: 0.8761904761904762; ap: 0.9039239565062195
Validation accuracy increased (0.853968 --> 0.876190).  Saving model ...
saving the model at the end of epoch 12
Length of dataset: 20

(Val @ epoch 12) acc: 0.8476190476190476; ap: 0.9093296888666543
EarlyStopping counter: 1 out of 3
Train loss: 0.3863529860973358 at step: 2400
Iter time:  0.15912371178468068
saving the model at the end of epoch 13
Length of dataset: 20

(Val @ epoch 13) acc: 0.8412698412698413; ap: 0.8986273114874689
EarlyStopping counter: 2 out of 3
saving the model at the end of epoch 14
Length of dataset: 20

(Val @ epoch 14) acc: 0.8539682539682539; ap: 0.9171044722949967
EarlyStopping counter: 3 out of 3
Learning rate dropped by 10, continue training...
Train loss: 0.3989628553390503 at step: 2800
Iter time:  0.15893228369099754
saving the model at the end of epoch 15
Length of dataset: 20

(Val @ epoch 15) acc: 0.8571428571428571; ap: 0.9078605715494955
Validation accuracy increased (-inf --> 0.857143).  Saving model ...
saving the model at the end of epoch 16
Length of dataset: 20

(Val @ epoch 16) acc: 0.8444444444444444; ap: 0.8964652726493355
EarlyStopping counter: 1 out of 3
Train loss: 0.4745405316352844 at step: 3200
Iter time:  0.15875706978142262
saving the model at the end of epoch 17
Length of dataset: 20

(Val @ epoch 17) acc: 0.8603174603174604; ap: 0.9120386180820903
Validation accuracy increased (0.857143 --> 0.860317).  Saving model ...
saving the model at the end of epoch 18
Length of dataset: 20

(Val @ epoch 18) acc: 0.8253968253968254; ap: 0.9047389579852168
EarlyStopping counter: 1 out of 3
saving the model at the end of epoch 19
Length of dataset: 20

(Val @ epoch 19) acc: 0.8444444444444444; ap: 0.9061382862333136
EarlyStopping counter: 2 out of 3
Train loss: 0.3530363440513611 at step: 3600
Iter time:  0.16000317712624867
saving the model at the end of epoch 20
Length of dataset: 20

(Val @ epoch 20) acc: 0.8444444444444444; ap: 0.916783713357373
EarlyStopping counter: 3 out of 3
Early stopping.
